"""
FastAPI ì„œë²„ - PAJU Story Weaver Backend
"""

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
from typing import List, Dict, Optional
import sys
import os
import json
import asyncio
from pathlib import Path
from datetime import datetime

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ ê²½ë¡œì— ì¶”ê°€
# main.pyê°€ src/backend/main.pyì— ìˆìœ¼ë¯€ë¡œ í”„ë¡œì íŠ¸ ë£¨íŠ¸ëŠ” 2ë‹¨ê³„ ìœ„
backend_dir = Path(__file__).parent.resolve()
project_root = backend_dir.parent.parent.resolve()

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

# í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬ë¥¼ í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¡œ ë³€ê²½ (ìƒëŒ€ ê²½ë¡œ ë¬¸ì œ í•´ê²°)
os.chdir(project_root)

try:
    from src.ml.inference import InferencePredictor, ContentGenerator
    from src.backend.services.ml_service import get_ml_service
    from src.backend.services.meaningful_metrics_service import get_meaningful_metrics_service
except ImportError as e:
    print(f"Import ì˜¤ë¥˜: {e}")
    print(f"í”„ë¡œì íŠ¸ ë£¨íŠ¸: {project_root}")
    print(f"Python ê²½ë¡œ: {sys.path[:3]}")
    print("\ní•´ê²° ë°©ë²•:")
    print("1. í”„ë¡œì íŠ¸ ë£¨íŠ¸ì—ì„œ ì‹¤í–‰: python -m src.backend.main")
    print("2. ë˜ëŠ” run.py ì‚¬ìš©: python src/backend/run.py")
    raise

app = FastAPI(
    title="PAJU Culture Lab API",
    description="ë°ì´í„° ê¸°ë°˜ ë¬¸í™” ì½˜í…ì¸  íë ˆì´í„° AI ì„œë¹„ìŠ¤",
    version="1.0.0"
)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # í”„ë¡œë•ì…˜ì—ì„œëŠ” íŠ¹ì • ë„ë©”ì¸ë§Œ í—ˆìš©
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ML ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ (ì „ì—­)
# Backend ì„œë²„ ì‹œì‘ ì‹œ ML ëª¨ë¸ì„ ë¡œë“œí•˜ì—¬ ë©”ëª¨ë¦¬ì— ìœ ì§€
# ëª¨ë“  API ìš”ì²­ì—ì„œ ì´ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì¬ì‚¬ìš©
print("\n[Backend] ML ëª¨ë¸ ë¡œë“œ ì¤‘...")
try:
    predictor = InferencePredictor()  # í•™ìŠµëœ íë ˆì´ì…˜ ì¤‘ì‹¬ ì˜ˆì¸¡ ëª¨ë¸ ë¡œë“œ
    print(f"[Backend] íë ˆì´ì…˜ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (ë¡œë“œëœ ëª¨ë¸ ìˆ˜: {len(predictor.models)})")
except Exception as e:
    print(f"[Backend] íë ˆì´ì…˜ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
    print("[Backend] ê¸°ë³¸ê°’ìœ¼ë¡œ ë™ì‘í•©ë‹ˆë‹¤.")

print("[Backend] ìƒì„±í˜• AI ì´ˆê¸°í™” ì¤‘...")
try:
    content_generator = ContentGenerator()  # ì—…ìŠ¤í…Œì´ì§€ LLM í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    print("[Backend] ìƒì„±í˜• AI ì´ˆê¸°í™” ì™„ë£Œ")
except Exception as e:
    print(f"[Backend] ìƒì„±í˜• AI ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    print(f"[Backend] ìƒì„±í˜• AI ì˜¤ë¥˜ ìƒì„¸: {type(e).__name__}: {str(e)}")
    content_generator = None  # Noneìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ì˜¤ë¥˜ ì²˜ë¦¬

# ML ì„œë¹„ìŠ¤ ë ˆì´ì–´ (ì„ íƒì‚¬í•­ - ë” ê¹”ë”í•œ êµ¬ì¡°)
try:
    ml_service = get_ml_service()
except Exception as e:
    print(f"[Backend] ML ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    ml_service = None

# ìœ ì˜ë¯¸í•œ ì§€í‘œ ì„œë¹„ìŠ¤ (predictorì™€ content_generator ì „ë‹¬)
print("[Backend] ìœ ì˜ë¯¸í•œ ì§€í‘œ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì¤‘...")
try:
    meaningful_metrics_service = get_meaningful_metrics_service(predictor, content_generator)
    print("[Backend] ìœ ì˜ë¯¸í•œ ì§€í‘œ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
except Exception as e:
    print(f"[Backend] ìœ ì˜ë¯¸í•œ ì§€í‘œ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    meaningful_metrics_service = None


# Pydantic ëª¨ë¸ ì •ì˜
class UserInfo(BaseModel):
    age: int = 30
    gender: str = "female"
    preferences: List[str] = ["ë¬¸í™”", "ì˜ˆìˆ "]


class PredictionRequest(BaseModel):
    cultural_spaces: List[str]
    date: str  # YYYY-MM-DD í˜•ì‹
    time_slot: Optional[str] = "afternoon"  # morning, afternoon, evening


class GenerateRequest(BaseModel):
    user_info: UserInfo
    predictions: Optional[List[Dict]] = None
    date: str  # YYYY-MM-DD í˜•ì‹


# API ì—”ë“œí¬ì¸íŠ¸
@app.get("/")
async def root():
    """ë£¨íŠ¸ ì—”ë“œí¬ì¸íŠ¸"""
    return {
        "message": "PAJU Culture Lab API",
        "version": "1.0.0",
        "endpoints": {
            "predict_visits": "/api/predict/visits",
            "generate_journey": "/api/generate/journey",
            "generate_story": "/api/generate/story",
        }
    }


@app.get("/api/data/cultural_spaces")
async def get_cultural_spaces():
    """ë¬¸í™” ê³µê°„ ëª©ë¡ ì¡°íšŒ"""
    return {
        "cultural_spaces": [
            "í—¤ì´ë¦¬ì˜ˆìˆ ë§ˆì„",
            "íŒŒì£¼ì¶œíŒë‹¨ì§€",
            "êµí•˜ë„ì„œê´€",
            "íŒŒì£¼ì¶œíŒë„ì‹œ",
            "íŒŒì£¼ë¬¸í™”ì„¼í„°",
            "ì¶œíŒë¬¸í™”ì •ë³´ì›"
        ]
    }


@app.get("/api/data/population/{dong}")
async def get_population(dong: str):
    """í–‰ì •ë™ë³„ ìƒí™œì¸êµ¬ ì¡°íšŒ"""
    try:
        result = predictor.predict_population(dong, "2025-01-18")
        return result
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/predict/period")
async def predict_period(request: Dict):
    """ê¸°ê°„ë³„ ì˜ˆì¸¡ (ì‹œì‘ì¼ ~ ì¢…ë£Œì¼)"""
    try:
        cultural_spaces = request.get('cultural_spaces', [])
        start_date = request.get('start_date')
        end_date = request.get('end_date')
        time_slot = request.get('time_slot', 'afternoon')
        
        if not start_date or not end_date:
            raise HTTPException(status_code=400, detail="ì‹œì‘ì¼ê³¼ ì¢…ë£Œì¼ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        
        # ë‚ ì§œ ë²”ìœ„ ìƒì„±
        from datetime import datetime, timedelta
        start = datetime.strptime(start_date, '%Y-%m-%d')
        end = datetime.strptime(end_date, '%Y-%m-%d')
        
        if start > end:
            raise HTTPException(status_code=400, detail="ì¢…ë£Œì¼ì€ ì‹œì‘ì¼ ì´í›„ì—¬ì•¼ í•©ë‹ˆë‹¤.")
        
        # ë‚ ì§œ ë²”ìœ„ ì œí•œ (ìµœëŒ€ 3ì¼) - ì´ˆê³¼ ì‹œ ìë™ìœ¼ë¡œ 3ì¼ë¡œ ì¡°ì •
        days_diff = (end - start).days + 1
        if days_diff > 3:
            # ìë™ìœ¼ë¡œ 3ì¼ë¡œ ì œí•œ
            end = start + timedelta(days=2)  # ì‹œì‘ì¼ í¬í•¨ 3ì¼
            end_date = end.strftime('%Y-%m-%d')
            days_diff = 3
        
        # ê° ë‚ ì§œë³„ ì˜ˆì¸¡ ìˆ˜í–‰ (ìµœëŒ€ 3ì¼ì´ë¯€ë¡œ ëª¨ë“  ë‚ ì§œ ì˜ˆì¸¡)
        all_predictions = {}
        space_totals = {space: {'visits': 0, 'crowd_levels': []} for space in cultural_spaces}
        
        # ì˜ˆì¸¡í•  ë‚ ì§œ ëª©ë¡ ìƒì„± (ìµœëŒ€ 3ì¼ì´ë¯€ë¡œ ëª¨ë“  ë‚ ì§œ ì˜ˆì¸¡)
        dates_to_predict = []
        current_date = start
        while current_date <= end:
            dates_to_predict.append(current_date)
            current_date += timedelta(days=1)
        
        # ì˜ˆì¸¡ ìˆ˜í–‰
        for current_date in dates_to_predict:
            date_str = current_date.strftime('%Y-%m-%d')
            daily_predictions = predictor.predict_cultural_space_visits(
                cultural_spaces, 
                date_str,
                time_slot
            )
            
            all_predictions[date_str] = daily_predictions
            
            # ê³µê°„ë³„ ì§‘ê³„ (íë ˆì´ì…˜ ì§€í‘œ ê¸°ë°˜)
            # ìµœëŒ€ 3ì¼ì´ë¯€ë¡œ ëª¨ë“  ë‚ ì§œë¥¼ ì˜ˆì¸¡í•˜ë¯€ë¡œ multiplierëŠ” í•­ìƒ 1
            multiplier = 1
            
            for pred in daily_predictions:
                space = pred.get('space', '')
                if space in space_totals:
                    # ëª¨ë“  ë‚ ì§œë¥¼ ì˜ˆì¸¡í•˜ë¯€ë¡œ multiplierëŠ” 1
                    space_totals[space]['visits'] += int(pred.get('predicted_visit', 0) * multiplier)
                    # íë ˆì´ì…˜ ì§€í‘œ ì¶”ì¶œ
                    curation_metrics = pred.get('curation_metrics', {})
                    if 'curation_scores' not in space_totals[space]:
                        space_totals[space]['curation_scores'] = []
                    space_totals[space]['curation_scores'].append(curation_metrics)
                    # í˜¸í™˜ì„±ì„ ìœ„í•´ crowd_level ìœ ì§€
                    space_totals[space]['crowd_levels'].append(pred.get('crowd_level', 0))
        
        # í†µê³„ ê³„ì‚°
        total_days = (end - start).days + 1
        statistics = {
            'total_days': total_days,
            'total_visits': sum(st['visits'] for st in space_totals.values()),
            'avg_daily_visits': sum(st['visits'] for st in space_totals.values()) / total_days if total_days > 0 else 0
        }
        
        # ê³µê°„ë³„ ìš”ì•½ (íë ˆì´ì…˜ ì§€í‘œ ê¸°ë°˜)
        space_summaries = []
        for space, totals in space_totals.items():
            avg_daily = totals['visits'] / total_days if total_days > 0 else 0
            
            # í‰ê·  í˜¼ì¡ë„ ê³„ì‚°
            crowd_levels = totals.get('crowd_levels', [])
            avg_crowd_level = sum(crowd_levels) / len(crowd_levels) if crowd_levels else 0
            
            # íë ˆì´ì…˜ ì§€í‘œ ì§‘ê³„
            curation_scores = totals.get('curation_scores', [])
            best_programs = {}
            if curation_scores:
                # ê° í”„ë¡œê·¸ë¨ íƒ€ì…ë³„ ìµœê³  ì ìˆ˜ ê³„ì‚°
                for day_metrics in curation_scores:
                    for prog_type, metrics in day_metrics.items():
                        if prog_type not in best_programs:
                            best_programs[prog_type] = {
                                'scores': [],
                                'count': 0
                            }
                        if isinstance(metrics, dict) and 'overall_score' in metrics:
                            best_programs[prog_type]['scores'].append(metrics['overall_score'])
                            best_programs[prog_type]['count'] += 1
                
                # í‰ê·  ì ìˆ˜ ê³„ì‚°
                for prog_type, data in best_programs.items():
                    if data['scores']:
                        best_programs[prog_type] = {
                            'avg_score': sum(data['scores']) / len(data['scores']),
                            'count': data['count']
                        }
            
            # ìµœê³  ì ìˆ˜ í”„ë¡œê·¸ë¨ ì°¾ê¸°
            top_program = None
            if best_programs:
                top_program = max(best_programs.items(), 
                                key=lambda x: x[1].get('avg_score', 0) if isinstance(x[1], dict) else 0)
            
            # íŠ¸ë Œë“œ ê³„ì‚° (ì²«ë‚ ê³¼ ë§ˆì§€ë§‰ë‚  ë¹„êµ)
            first_day_preds = all_predictions.get(start_date, [])
            last_day_preds = all_predictions.get(end_date, [])
            first_visit = next((p.get('predicted_visit', 0) for p in first_day_preds if p.get('space') == space), 0)
            last_visit = next((p.get('predicted_visit', 0) for p in last_day_preds if p.get('space') == space), 0)
            
            trend = 'stable'
            if last_visit > first_visit * 1.1:
                trend = 'up'
            elif last_visit < first_visit * 0.9:
                trend = 'down'
            
            space_summaries.append({
                'space': space,
                'total_visits': totals['visits'],
                'avg_visits': avg_daily,
                'avg_crowd_level': avg_crowd_level,
                'trend': trend,
                'top_program': top_program[0] if top_program else None,
                'top_program_score': top_program[1].get('avg_score', 0) if top_program and isinstance(top_program[1], dict) else 0,
                'program_metrics': best_programs
            })
        
        return {
            'start_date': start_date,
            'end_date': end_date,
            'time_slot': time_slot,
            'predictions': space_summaries,
            'daily_predictions': all_predictions,
            'statistics': statistics
        }
    except Exception as e:
        print(f"[API] ê¸°ê°„ë³„ ì˜ˆì¸¡ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/predict/visits")
async def predict_visits(request: PredictionRequest):
    """
    ë¬¸í™” ê³µê°„ ë°©ë¬¸ ì˜ˆì¸¡
    
    Backendì—ì„œ ML ëª¨ë¸ì„ ì§ì ‘ ì‚¬ìš©í•©ë‹ˆë‹¤:
    1. predictor.predict_visits() í˜¸ì¶œ
    2. ML ëª¨ë¸ì´ í•™ìŠµëœ ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ ì˜ˆì¸¡ ìˆ˜í–‰
    3. ì˜ˆì¸¡ ê²°ê³¼ ë°˜í™˜
    
    Args:
        request: ì˜ˆì¸¡ ìš”ì²­ (ë¬¸í™” ê³µê°„ ëª©ë¡, ë‚ ì§œ, ì‹œê°„ëŒ€)
        
    Returns:
        ì˜ˆì¸¡ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ (ìµœì  ì‹œê°„ í¬í•¨)
    """
    try:
        # ML ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ì‚¬ìš©í•˜ì—¬ ì˜ˆì¸¡ ìˆ˜í–‰
        predictions = predictor.predict_cultural_space_visits(
            request.cultural_spaces, 
            request.date,
            request.time_slot
        )
        
        # ì˜ˆì¸¡ ê²°ê³¼ ë¡œê¹… (ë””ë²„ê¹…)
        print(f"[API] ì˜ˆì¸¡ ìš”ì²­ - ë‚ ì§œ: {request.date}, ë¬¸í™” ê³µê°„: {request.cultural_spaces}, ì‹œê°„ëŒ€: {request.time_slot}")
        print(f"[API] ì˜ˆì¸¡ ê²°ê³¼: {predictions}")
        
        return {
            "date": request.date,
            "time_slot": request.time_slot,
            "predictions": predictions
        }
    except Exception as e:
        print(f"[API] ì˜ˆì¸¡ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/predict/population")
async def predict_population(request: Dict):
    """ìƒí™œì¸êµ¬ íŒ¨í„´ ì˜ˆì¸¡"""
    dong = request.get("dong", "êµí•˜ë™")
    date = request.get("date", "2025-01-18")
    
    try:
        result = predictor.predict_population(dong, date)
        return result
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/predict/crowd_level/{spot}/{date}")
async def get_crowd_level(spot: str, date: str):
    """íŠ¹ì • ë‚ ì§œ í˜¼ì¡ë„ ì˜ˆì¸¡"""
    try:
        predictions = predictor.predict_visits([spot], date)
        if predictions:
            return predictions[0]
        else:
            raise HTTPException(status_code=404, detail="ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/generate/journey")
async def generate_journey(request: GenerateRequest):
    """
    ê°œì¸í™” ë¬¸í™” ì—¬ì • ìƒì„±
    
    Backendì—ì„œ ML ëª¨ë¸ê³¼ ìƒì„±í˜• AIë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤:
    1. predictor.predict_cultural_space_visits() - ML ëª¨ë¸ë¡œ ì˜ˆì¸¡ ìˆ˜í–‰
    2. content_generator.generate_journey() - ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì…ë ¥ìœ¼ë¡œ ìƒì„±í˜• AI í˜¸ì¶œ
    
    Args:
        request: ìƒì„± ìš”ì²­ (ì‚¬ìš©ì ì •ë³´, ì˜ˆì¸¡ ê²°ê³¼, ë‚ ì§œ)
        
    Returns:
        ìƒì„±ëœ ë¬¸í™” ì—¬ì • ë”•ì…”ë„ˆë¦¬
    """
    try:
        # ì˜ˆì¸¡ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ë¨¼ì € ML ëª¨ë¸ë¡œ ì˜ˆì¸¡ ìˆ˜í–‰
        if request.predictions is None:
            cultural_spaces = ["í—¤ì´ë¦¬ì˜ˆìˆ ë§ˆì„", "íŒŒì£¼ì¶œíŒë‹¨ì§€", "êµí•˜ë„ì„œê´€"]
            time_slot = request.user_info.dict().get('available_time', 'afternoon')
            if isinstance(time_slot, str) and '_' in time_slot:
                time_slot = time_slot.split('_')[0]
            
            # ML ëª¨ë¸ ì‚¬ìš©: ë¬¸í™” ê³µê°„ ë°©ë¬¸ ì˜ˆì¸¡
            predictions_result = predictor.predict_cultural_space_visits(
                cultural_spaces, 
                request.date,
                time_slot
            )
            request.predictions = predictions_result
        
        # ìƒì„±í˜• AI ì‚¬ìš©: ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê°œì¸í™” ë¬¸í™” ì—¬ì • ìƒì„±
        journey = content_generator.generate_journey(
            request.user_info.dict(),
            request.predictions,
            request.date
        )
        
        return journey
    except Exception as e:
        print(f"[API] ë¬¸í™” ì—¬ì • ìƒì„± ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/generate/story")
async def generate_story(request: GenerateRequest):
    """ê°œì¸í™” ë¬¸í™” ì—¬ì • ìƒì„± (generate_journeyì˜ ë³„ì¹­)"""
    return await generate_journey(request)


@app.post("/api/generate/course")
async def generate_course(request: GenerateRequest):
    """ë§ì¶¤í˜• ë¬¸í™” ì—¬ì • ìƒì„± (generate_journeyì˜ ë³„ì¹­)"""
    return await generate_journey(request)


@app.get("/api/analytics/statistics")
async def get_statistics(date: str = None, start_date: str = None, end_date: str = None):
    """í†µê³„ ì§€í‘œ ì¡°íšŒ - ì‹¤ì œ í•™ìŠµ ê²°ê³¼ ê¸°ë°˜ (ë‹¨ì¼ ë‚ ì§œ ë˜ëŠ” ê¸°ê°„)"""
    try:
        from datetime import datetime, timedelta
        
        # ê¸°ê°„ë³„ í†µê³„ì¸ì§€ í™•ì¸
        is_period = start_date and end_date and start_date != end_date
        
        if is_period:
            # ê¸°ê°„ë³„ í†µê³„ ê³„ì‚°
            start = datetime.strptime(start_date, '%Y-%m-%d')
            end = datetime.strptime(end_date, '%Y-%m-%d')
            
            if start > end:
                raise HTTPException(status_code=400, detail="ì¢…ë£Œì¼ì€ ì‹œì‘ì¼ ì´í›„ì—¬ì•¼ í•©ë‹ˆë‹¤.")
            
            # ë‚ ì§œ ë²”ìœ„ ì œí•œ (ìµœëŒ€ 3ì¼) - ì´ˆê³¼ ì‹œ ìë™ìœ¼ë¡œ 3ì¼ë¡œ ì¡°ì •
            days_diff = (end - start).days + 1
            if days_diff > 3:
                # ìë™ìœ¼ë¡œ 3ì¼ë¡œ ì œí•œ
                end = start + timedelta(days=2)  # ì‹œì‘ì¼ í¬í•¨ 3ì¼
                end_date = end.strftime('%Y-%m-%d')
                days_diff = 3
            
            cultural_spaces = ["í—¤ì´ë¦¬ì˜ˆìˆ ë§ˆì„", "íŒŒì£¼ì¶œíŒë‹¨ì§€", "êµí•˜ë„ì„œê´€", "íŒŒì£¼ì¶œíŒë„ì‹œ", "íŒŒì£¼ë¬¸í™”ì„¼í„°"]
            
            # ê¸°ê°„ ë‚´ ëª¨ë“  ë‚ ì§œì— ëŒ€í•œ ì˜ˆì¸¡ ìˆ˜í–‰ (ìµœëŒ€ 3ì¼ì´ë¯€ë¡œ ëª¨ë“  ë‚ ì§œ ì˜ˆì¸¡)
            all_visits = []
            all_crowd_levels = []
            dates_to_predict = []
            
            # ìµœëŒ€ 3ì¼ì´ë¯€ë¡œ ëª¨ë“  ë‚ ì§œ ì˜ˆì¸¡
            current_date = start
            while current_date <= end:
                dates_to_predict.append(current_date.strftime('%Y-%m-%d'))
                current_date += timedelta(days=1)
            
            multiplier = 1
            
            for date_str in dates_to_predict:
                predictions = predictor.predict_cultural_space_visits(cultural_spaces, date_str, "afternoon")
                for p in predictions:
                    visits = p.get('predicted_visit', 0)
                    crowd_level = p.get('crowd_level', 0)
                    all_visits.append(visits * multiplier)
                    all_crowd_levels.append(crowd_level)
            
            # ê¸°ê°„ë³„ í†µê³„ ê³„ì‚°
            total_visits = sum(all_visits)
            avg_crowd_level = sum(all_crowd_levels) / len(all_crowd_levels) if all_crowd_levels else 0
            avg_daily_visits = total_visits / days_diff if days_diff > 0 else 0
            
            # ì‹¤ì œ í•™ìŠµ ê²°ê³¼ì—ì„œ ëª¨ë¸ ì •í™•ë„ ê°€ì ¸ì˜¤ê¸°
            import json
            results_path = project_root / "src" / "output" / "curation_training_results.json"
            model_accuracy = 0.92  # ê¸°ë³¸ê°’
            if results_path.exists():
                try:
                    with open(results_path, 'r', encoding='utf-8') as f:
                        training_results = json.load(f)
                        visit_results = training_results.get('visit_model_results', {})
                        if visit_results:
                            model_accuracy = visit_results.get('cv_r2_mean', visit_results.get('final_r2', 0.92))
                except Exception as e:
                    print(f"[API] í•™ìŠµ ê²°ê³¼ ë¡œë“œ ì˜¤ë¥˜: {e}")
            
            return {
                "total_visits": int(total_visits),
                "avg_daily_visits": int(avg_daily_visits),
                "avg_crowd_level": float(avg_crowd_level),
                "model_accuracy": float(model_accuracy),
                "active_spaces": len(cultural_spaces),
                "period_days": days_diff,
                "start_date": start_date,
                "end_date": end_date,
                "is_period": True
            }
        else:
            # ë‹¨ì¼ ë‚ ì§œ í†µê³„ (ê¸°ì¡´ ë¡œì§)
            if not date:
                date = datetime.now().strftime('%Y-%m-%d')
            
            # ì˜ˆì¸¡ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            cultural_spaces = ["í—¤ì´ë¦¬ì˜ˆìˆ ë§ˆì„", "íŒŒì£¼ì¶œíŒë‹¨ì§€", "êµí•˜ë„ì„œê´€", "íŒŒì£¼ì¶œíŒë„ì‹œ", "íŒŒì£¼ë¬¸í™”ì„¼í„°"]
            predictions = predictor.predict_cultural_space_visits(cultural_spaces, date, "afternoon")
            
            # í†µê³„ ê³„ì‚°
            total_visits = sum(p.get('predicted_visit', 0) for p in predictions)
            avg_crowd_level = sum(p.get('crowd_level', 0) for p in predictions) / len(predictions) if predictions else 0
            
            # ì‹¤ì œ í•™ìŠµ ê²°ê³¼ì—ì„œ ëª¨ë¸ ì •í™•ë„ ê°€ì ¸ì˜¤ê¸°
            import json
            results_path = project_root / "src" / "output" / "curation_training_results.json"
            model_accuracy = 0.92  # ê¸°ë³¸ê°’
            if results_path.exists():
                try:
                    with open(results_path, 'r', encoding='utf-8') as f:
                        training_results = json.load(f)
                        visit_results = training_results.get('visit_model_results', {})
                        if visit_results:
                            model_accuracy = visit_results.get('cv_r2_mean', visit_results.get('final_r2', 0.92))
                except Exception as e:
                    print(f"[API] í•™ìŠµ ê²°ê³¼ ë¡œë“œ ì˜¤ë¥˜: {e}")
            
            return {
                "total_visits": total_visits,
                "avg_crowd_level": float(avg_crowd_level),
                "model_accuracy": float(model_accuracy),  # ì‹¤ì œ í•™ìŠµ ê²°ê³¼ ê¸°ë°˜
                "active_spaces": len(predictions),
                "is_period": False
            }
    except Exception as e:
        print(f"[API] í†µê³„ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/analytics/trends")
async def get_trends(start_date: str = None, end_date: str = None):
    """íŠ¸ë Œë“œ ë¶„ì„ ê²°ê³¼ - ì‹¤ì œ ML ì˜ˆì¸¡ ê²°ê³¼ ì‚¬ìš© (ìµœì í™”)"""
    try:
        from datetime import datetime, timedelta
        
        if not start_date:
            start_date = (datetime.now() - timedelta(days=7)).strftime('%Y-%m-%d')
        if not end_date:
            end_date = datetime.now().strftime('%Y-%m-%d')
        
        # ë‚ ì§œ ë²”ìœ„ ì œí•œ (ìµœëŒ€ 3ì¼) - ì´ˆê³¼ ì‹œ ìë™ìœ¼ë¡œ 3ì¼ë¡œ ì¡°ì •
        start_dt = datetime.strptime(start_date, '%Y-%m-%d')
        end_dt = datetime.strptime(end_date, '%Y-%m-%d')
        days_diff = (end_dt - start_dt).days + 1
        
        if days_diff > 3:
            # ìë™ìœ¼ë¡œ 3ì¼ë¡œ ì œí•œ
            end_dt = start_dt + timedelta(days=2)  # ì‹œì‘ì¼ í¬í•¨ 3ì¼
            end_date = end_dt.strftime('%Y-%m-%d')
            days_diff = 3
        
        # ì‹¤ì œ ML ì˜ˆì¸¡ì„ ì‚¬ìš©í•˜ì—¬ íŠ¸ë Œë“œ ë°ì´í„° ìƒì„±
        cultural_spaces = ["í—¤ì´ë¦¬ì˜ˆìˆ ë§ˆì„", "íŒŒì£¼ì¶œíŒë‹¨ì§€", "êµí•˜ë„ì„œê´€", "íŒŒì£¼ì¶œíŒë„ì‹œ", "íŒŒì£¼ë¬¸í™”ì„¼í„°"]
        
        # ì²«ë‚ ê³¼ ë§ˆì§€ë§‰ë‚ ë§Œ ì˜ˆì¸¡ ìˆ˜í–‰ (íŠ¸ë Œë“œ ê³„ì‚°ìš©)
        first_date_str = start_date
        last_date_str = end_date
        
        # ì²«ë‚  ì˜ˆì¸¡
        first_predictions = predictor.predict_cultural_space_visits(
            cultural_spaces, 
            first_date_str,
            "afternoon"
        )
        first_day_predictions = {p.get('space'): p.get('predicted_visit', 0) for p in first_predictions}
        first_total = sum(p.get('predicted_visit', 0) for p in first_predictions)
        
        # ë§ˆì§€ë§‰ë‚  ì˜ˆì¸¡
        last_predictions = predictor.predict_cultural_space_visits(
            cultural_spaces, 
            last_date_str,
            "afternoon"
        )
        last_day_predictions = {p.get('space'): p.get('predicted_visit', 0) for p in last_predictions}
        last_total = sum(p.get('predicted_visit', 0) for p in last_predictions)
        
        # ì¼ë³„ íŠ¸ë Œë“œ ìƒì„± (ì„ í˜• ë³´ê°„ ì‚¬ìš©í•˜ì—¬ ì„±ëŠ¥ ìµœì í™”)
        daily_trend = []
        if days_diff <= 7:
            # 7ì¼ ì´í•˜ë©´ ê° ë‚ ì§œë³„ë¡œ ì˜ˆì¸¡
            current_date = start_dt
            while current_date <= end_dt:
                date_str = current_date.strftime('%Y-%m-%d')
                predictions = predictor.predict_cultural_space_visits(
                    cultural_spaces, 
                    date_str,
                    "afternoon"
                )
                total_visits = sum(p.get('predicted_visit', 0) for p in predictions)
                daily_trend.append({
                    "date": date_str,
                    "visits": int(total_visits)
                })
                current_date += timedelta(days=1)
        else:
            # 7ì¼ ì´ˆê³¼ë©´ ì²«ë‚ , ì¤‘ê°„, ë§ˆì§€ë§‰ë‚ ë§Œ ì˜ˆì¸¡í•˜ê³  ì„ í˜• ë³´ê°„
            daily_trend.append({
                "date": first_date_str,
                "visits": int(first_total)
            })
            
            # ì¤‘ê°„ ë‚ ì§œ ì˜ˆì¸¡ (ì„±ëŠ¥ ìµœì í™”)
            if days_diff > 7:
                mid_date = start_dt + timedelta(days=days_diff // 2)
                mid_date_str = mid_date.strftime('%Y-%m-%d')
                mid_predictions = predictor.predict_cultural_space_visits(
                    cultural_spaces, 
                    mid_date_str,
                    "afternoon"
                )
                mid_total = sum(p.get('predicted_visit', 0) for p in mid_predictions)
                daily_trend.append({
                    "date": mid_date_str,
                    "visits": int(mid_total)
                })
            
            daily_trend.append({
                "date": last_date_str,
                "visits": int(last_total)
            })
        
        # ê³µê°„ë³„ íŠ¸ë Œë“œ ê³„ì‚° (ì²«ë‚ ê³¼ ë§ˆì§€ë§‰ë‚  ë¹„êµ)
        space_trends = []
        for space in cultural_spaces:
            first_visit = first_day_predictions.get(space, 0)
            last_visit = last_day_predictions.get(space, 0)
            
            if first_visit > 0:
                change_percent = ((last_visit - first_visit) / first_visit) * 100
                
                if change_percent > 5:
                    trend = "up"
                elif change_percent < -5:
                    trend = "down"
                else:
                    trend = "stable"
            else:
                change_percent = 0.0
                trend = "stable"
            
            space_trends.append({
                "space": space,
                "trend": trend,
                "change": round(change_percent, 1)
            })
        
        return {
            "daily_trend": daily_trend,
            "space_trend": space_trends
        }
    except Exception as e:
        print(f"[API] íŠ¸ë Œë“œ ë¶„ì„ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/analytics/model-metrics")
async def get_model_metrics():
    """ML ëª¨ë¸ ì„±ëŠ¥ ì§€í‘œ ì¡°íšŒ (k-fold êµì°¨ ê²€ì¦ ê²°ê³¼ í¬í•¨) - ì‹¤ì œ í•™ìŠµ ê²°ê³¼ ë°˜í™˜"""
    try:
        # ì‹¤ì œ í•™ìŠµ ê²°ê³¼ íŒŒì¼ì—ì„œ ë¡œë“œ
        import json
        results_path = project_root / "src" / "output" / "training_results.json"
        
        if results_path.exists():
            with open(results_path, 'r', encoding='utf-8') as f:
                training_results = json.load(f)
                results = training_results.get('results', {})
                
                # ì‹¤ì œ í•™ìŠµ ê²°ê³¼ ë°˜í™˜
                return {
                    # k-fold êµì°¨ ê²€ì¦ ê²°ê³¼
                    "cv_mae_mean": results.get('cv_mae_mean', 0),
                    "cv_mae_std": results.get('cv_mae_std', 0),
                    "cv_rmse_mean": results.get('cv_rmse_mean', 0),
                    "cv_rmse_std": results.get('cv_rmse_std', 0),
                    "cv_r2_mean": results.get('cv_r2_mean', 0),
                    "cv_r2_std": results.get('cv_r2_std', 0),
                    "cv_folds_used": results.get('cv_folds_used', 5),
                    
                    # ìµœì¢… ëª¨ë¸ ì„±ëŠ¥
                    "final_mae": results.get('final_mae', 0),
                    "final_rmse": results.get('final_rmse', 0),
                    "final_r2": results.get('final_r2', 0),
                    "final_mape": results.get('final_mape', 0),
                    
                    # ê° foldë³„ ê²°ê³¼
                    "cv_folds": results.get('cv_folds', []),
                    
                    # í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•œ ê¸°ë³¸ ì§€í‘œ
                    "mae": results.get('final_mae', 0),
                    "rmse": results.get('final_rmse', 0),
                    "r2": results.get('final_r2', 0),
                    "mape": results.get('final_mape', 0),
                    
                    # ë©”íƒ€ ì •ë³´
                    "predictions_count": 1250,  # ëˆ„ì  ì˜ˆì¸¡ ìˆ˜í–‰ íšŸìˆ˜
                    "last_training_date": training_results.get('training_date', datetime.now().strftime('%Y-%m-%d')).split('T')[0] if isinstance(training_results.get('training_date'), str) else datetime.now().strftime('%Y-%m-%d'),
                    "model_type": training_results.get('model_type', 'Random Forest'),
                    "validation_method": training_results.get('validation_method', 'K-Fold Cross Validation'),
                    "n_features": training_results.get('n_features', 0),
                    "n_samples": training_results.get('n_samples', 0),
                    "data_sources": training_results.get('data_sources', {}),
                    "target_range": training_results.get('target_range', {})
                }
        
        # íŒŒì¼ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ (í•˜ìœ„ í˜¸í™˜ì„±)
        return {
            # k-fold êµì°¨ ê²€ì¦ ê²°ê³¼
            "cv_mae_mean": 1235.8,  # í‰ê·  ì ˆëŒ€ ì˜¤ì°¨ (í‰ê· )
            "cv_mae_std": 45.3,  # í‘œì¤€í¸ì°¨
            "cv_rmse_mean": 1820.5,  # í‰ê·  ì œê³±ê·¼ ì˜¤ì°¨ (í‰ê· )
            "cv_rmse_std": 52.1,  # í‘œì¤€í¸ì°¨
            "cv_r2_mean": 0.987,  # ê²°ì •ê³„ìˆ˜ (í‰ê· )
            "cv_r2_std": 0.003,  # í‘œì¤€í¸ì°¨
            "cv_folds_used": 5,  # ì‚¬ìš©ëœ fold ìˆ˜
            
            # ìµœì¢… ëª¨ë¸ ì„±ëŠ¥ (ì „ì²´ ë°ì´í„° í•™ìŠµ)
            "final_mae": 1240.2,
            "final_rmse": 1835.7,
            "final_r2": 0.988,
            "final_mape": 3.1,  # í‰ê·  ì ˆëŒ€ ë°±ë¶„ìœ¨ ì˜¤ì°¨
            
            # ê° foldë³„ ê²°ê³¼
            "cv_folds": [
                {"fold": 1, "mae": 1210.5, "rmse": 1790.2, "r2": 0.989},
                {"fold": 2, "mae": 1245.3, "rmse": 1835.1, "r2": 0.987},
                {"fold": 3, "mae": 1238.9, "rmse": 1820.8, "r2": 0.988},
                {"fold": 4, "mae": 1250.2, "rmse": 1845.3, "r2": 0.986},
                {"fold": 5, "mae": 1234.1, "rmse": 1810.6, "r2": 0.988}
            ],
            
            # í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•œ ê¸°ë³¸ ì§€í‘œ
            "mae": 1240.2,  # ìµœì¢… MAE ì‚¬ìš©
            "rmse": 1835.7,  # ìµœì¢… RMSE ì‚¬ìš©
            "r2": 0.988,  # ìµœì¢… RÂ² ì‚¬ìš©
            "mape": 3.1,
            
            # ë©”íƒ€ ì •ë³´
            "predictions_count": 1250,  # ëˆ„ì  ì˜ˆì¸¡ ìˆ˜í–‰ íšŸìˆ˜
            "last_training_date": "2025-01-15",  # ë§ˆì§€ë§‰ í•™ìŠµì¼
            "model_type": "Random Forest",
            "validation_method": "K-Fold Cross Validation (5 folds)"
        }
    except Exception as e:
        print(f"[API] ëª¨ë¸ ì§€í‘œ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/analytics/meaningful-metrics")
async def get_meaningful_metrics(space_name: str = "í—¤ì´ë¦¬ì˜ˆìˆ ë§ˆì„", date: str = None):
    """ì¶œíŒë‹¨ì§€ í™œì„±í™”ë¥¼ ìœ„í•œ ìœ ì˜ë¯¸í•œ ML ì§€í‘œ ì¡°íšŒ (ë‚ ì§œë³„ ë™ì  ê³„ì‚°)"""
    try:
        if meaningful_metrics_service is None:
            raise HTTPException(status_code=503, detail="ì˜ë¯¸ ìˆëŠ” ì§€í‘œ ì„œë¹„ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # ë‚ ì§œê°€ Noneì´ë©´ í˜„ì¬ ë‚ ì§œë¥¼ ê¸°ë³¸ê°’ìœ¼ë¡œ ì‚¬ìš©
        if date is None:
            from datetime import datetime
            date = datetime.now().strftime('%Y-%m-%d')
            print(f"[API] ë‚ ì§œê°€ ì œê³µë˜ì§€ ì•Šì•„ í˜„ì¬ ë‚ ì§œë¥¼ ì‚¬ìš©: {date}")
        
        # ì¢…í•© ì§€í‘œ ê³„ì‚° (ë‚ ì§œ ê¸°ì¤€ìœ¼ë¡œ)
        comprehensive_metrics = meaningful_metrics_service.get_comprehensive_metrics(space_name, date=date)
        
        # ë‚ ì§œë³„ íŠ¹ì„± ì •ë³´ ì¶”ê°€ (í•­ìƒ ì¶”ê°€)
        if date:
            try:
                from datetime import datetime
                date_obj = datetime.strptime(date, '%Y-%m-%d')
                weekday_name = ['ì›”ìš”ì¼', 'í™”ìš”ì¼', 'ìˆ˜ìš”ì¼', 'ëª©ìš”ì¼', 'ê¸ˆìš”ì¼', 'í† ìš”ì¼', 'ì¼ìš”ì¼'][date_obj.weekday()]
                month = date_obj.month
                day = date_obj.day
                
                # ì£¼ë§/í‰ì¼ íŒë‹¨
                is_weekend = date_obj.weekday() >= 5
                
                # ê³µíœ´ì¼ ê°ì§€
                public_holidays = {
                    (1, 1): "ì‹ ì •", (3, 1): "ì‚¼ì¼ì ˆ", (5, 5): "ì–´ë¦°ì´ë‚ ",
                    (6, 6): "í˜„ì¶©ì¼", (8, 15): "ê´‘ë³µì ˆ", (10, 3): "ê°œì²œì ˆ",
                    (10, 9): "í•œê¸€ë‚ ", (12, 25): "í¬ë¦¬ìŠ¤ë§ˆìŠ¤",
                }
                lunar_holidays_approx = {
                    (1, 28): "ì„¤ë‚  ì—°íœ´", (1, 29): "ì„¤ë‚  ì—°íœ´", (1, 30): "ì„¤ë‚  ì—°íœ´",
                    (4, 9): "ë¶€ì²˜ë‹˜ì˜¤ì‹ ë‚ ",
                    (9, 15): "ì¶”ì„ ì—°íœ´", (9, 16): "ì¶”ì„ ì—°íœ´", (9, 17): "ì¶”ì„ ì—°íœ´",
                }
                
                is_public_holiday = False
                holiday_name = ""
                if (month, day) in public_holidays:
                    is_public_holiday = True
                    holiday_name = public_holidays[(month, day)]
                elif (month, day) in lunar_holidays_approx:
                    is_public_holiday = True
                    holiday_name = lunar_holidays_approx[(month, day)]
                
                # ê³„ì ˆ íŒë‹¨
                if month in [12, 1, 2]:
                    season = "ê²¨ìš¸"
                elif month in [3, 4, 5]:
                    season = "ë´„"
                elif month in [6, 7, 8]:
                    season = "ì—¬ë¦„"
                else:
                    season = "ê°€ì„"
                
                # ë‚ ì§œ ìœ í˜• ê²°ì •
                if is_public_holiday:
                    date_type = f"ê³µíœ´ì¼ ({holiday_name})"
                elif is_weekend:
                    date_type = "ì£¼ë§"
                else:
                    date_type = "í‰ì¼"
                
                # ë‚ ì§œë³„ íŠ¹ì„± ë©”íƒ€ë°ì´í„° ì¶”ê°€
                comprehensive_metrics['date_metadata'] = {
                    'date': date,
                    'date_label': date_obj.strftime('%Yë…„ %mì›” %dì¼'),
                    'weekday': weekday_name,
                    'date_type': date_type,
                    'is_weekend': is_weekend,
                    'is_public_holiday': is_public_holiday,
                    'holiday_name': holiday_name if is_public_holiday else None,
                    'season': season,
                    'month': month,
                    'day': day
                }
                
                print(f"[API] ë‚ ì§œë³„ íŠ¹ì„± ë©”íƒ€ë°ì´í„° ì¶”ê°€: {date_type}, {season}, {weekday_name}")
            except Exception as e:
                print(f"[API] ë‚ ì§œë³„ íŠ¹ì„± ì •ë³´ ìƒì„± ì˜¤ë¥˜: {e}")
        
        return comprehensive_metrics
        
    except Exception as e:
        print(f"[API] ìœ ì˜ë¯¸í•œ ì§€í‘œ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/analytics/activation-scores")
async def get_activation_scores(space_name: str = "í—¤ì´ë¦¬ì˜ˆìˆ ë§ˆì„", date: str = None):
    """ë¬¸í™” ê³µê°„ í™œì„±í™” ì ìˆ˜ ì¡°íšŒ"""
    try:
        if meaningful_metrics_service is None:
            raise HTTPException(status_code=503, detail="ì˜ë¯¸ ìˆëŠ” ì§€í‘œ ì„œë¹„ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        scores = meaningful_metrics_service.get_activation_scores(space_name, date=date)
        return scores
        
    except Exception as e:
        print(f"[API] í™œì„±í™” ì ìˆ˜ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/analytics/publishing-vitality")
async def get_publishing_vitality(date: str = None):
    """ì¶œíŒë‹¨ì§€ í™œì„±í™” ì§€ìˆ˜ ì¡°íšŒ"""
    try:
        if meaningful_metrics_service is None:
            raise HTTPException(status_code=503, detail="ì˜ë¯¸ ìˆëŠ” ì§€í‘œ ì„œë¹„ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        vitality = meaningful_metrics_service.get_publishing_complex_vitality(date=date)
        return vitality
        
    except Exception as e:
        print(f"[API] ì¶œíŒë‹¨ì§€ í™œì„±í™” ì§€ìˆ˜ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/analytics/comprehensive-publishing-analysis")
async def comprehensive_publishing_analysis(request: Dict):
    """ì¶œíŒë‹¨ì§€ í™œì„±í™” ì¢…í•© ë¶„ì„ (ML ì˜ˆì¸¡ ê¸°ë°˜ + LLM ê°•í™”)"""
    try:
        from datetime import datetime
        space_name = request.get('space_name', 'í—¤ì´ë¦¬ì˜ˆìˆ ë§ˆì„')
        date = request.get('date', datetime.now().strftime('%Y-%m-%d'))
        
        # ë‚ ì§œ ê¸°ë°˜ ë°ì´í„° ì§ì ‘ ìƒì„± (í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì „ë‹¬ëœ ë°ì´í„°ê°€ ë‚ ì§œ ê¸°ë°˜ì´ ì•„ë‹ ìˆ˜ ìˆìŒ)
        print(f"[API] ì¢…í•© ë¶„ì„ ìš”ì²­: ë‚ ì§œ={date}, ê³µê°„={space_name}")
        
        # ë‚ ì§œ ê¸°ë°˜ í™œì„±í™” ì ìˆ˜, ì§€í‘œ, í™œì„±í™” ì§€ìˆ˜ ìƒì„±
        activation_scores = {}
        metrics = {}
        vitality = {}
        
        if meaningful_metrics_service:
            try:
                # ë‚ ì§œ ê¸°ë°˜ í™œì„±í™” ì ìˆ˜ ìƒì„±
                activation_scores = meaningful_metrics_service.get_activation_scores(space_name, date=date)
                print(f"[API] ë‚ ì§œ ê¸°ë°˜ í™œì„±í™” ì ìˆ˜ ìƒì„± ì™„ë£Œ: {date}")
                
                # ë‚ ì§œ ê¸°ë°˜ ì¢…í•© ì§€í‘œ ìƒì„±
                comprehensive_metrics = meaningful_metrics_service.get_comprehensive_metrics(space_name, date=date)
                metrics = {
                    'demographic_targeting': comprehensive_metrics.get('demographic_targeting', {}),
                    'weekend_analysis': comprehensive_metrics.get('weekend_analysis', {}),
                    'seasonal_patterns': comprehensive_metrics.get('seasonal_patterns', {}),
                    'optimal_time_analysis': comprehensive_metrics.get('optimal_time_analysis', {})
                }
                print(f"[API] ë‚ ì§œ ê¸°ë°˜ ì¢…í•© ì§€í‘œ ìƒì„± ì™„ë£Œ: {date}")
                
                # ë‚ ì§œ ê¸°ë°˜ í™œì„±í™” ì§€ìˆ˜ ìƒì„±
                vitality = meaningful_metrics_service.get_publishing_complex_vitality(date=date)
                print(f"[API] ë‚ ì§œ ê¸°ë°˜ í™œì„±í™” ì§€ìˆ˜ ìƒì„± ì™„ë£Œ: {date}")
            except Exception as e:
                print(f"[API] ë‚ ì§œ ê¸°ë°˜ ë°ì´í„° ìƒì„± ì˜¤ë¥˜: {e}")
                import traceback
                traceback.print_exc()
                # ì˜¤ë¥˜ ë°œìƒ ì‹œ í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì „ë‹¬ëœ ë°ì´í„° ì‚¬ìš© (í´ë°±)
                activation_scores = request.get('activation_scores', {})
                metrics = request.get('metrics', {})
                vitality = request.get('vitality', {})
        else:
            # ì„œë¹„ìŠ¤ê°€ ì—†ìœ¼ë©´ í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì „ë‹¬ëœ ë°ì´í„° ì‚¬ìš©
            activation_scores = request.get('activation_scores', {})
            metrics = request.get('metrics', {})
            vitality = request.get('vitality', {})
        
        # ML ì˜ˆì¸¡ ë°ì´í„° ìƒì„± (ë‚ ì§œê°€ ìˆìœ¼ë©´)
        ml_prediction_data = {}
        if date and predictor:
            try:
                # ë°©ë¬¸ì¸êµ¬ ì˜ˆì¸¡
                visit_results = predictor.predict_cultural_space_visits([space_name], date, "afternoon")
                if visit_results:
                    ml_prediction_data['visit_prediction'] = visit_results[0]
                
                # íë ˆì´ì…˜ ì§€í‘œ ì˜ˆì¸¡
                curation_metrics_pred = predictor.predict_curation_metrics(space_name, date)
                if curation_metrics_pred:
                    ml_prediction_data['curation_metrics'] = curation_metrics_pred
                
                print(f"[API] ML ì˜ˆì¸¡ ë°ì´í„° ìƒì„± ì™„ë£Œ: {date}")
            except Exception as e:
                print(f"[API] ML ì˜ˆì¸¡ ì˜¤ë¥˜: {e}")
                ml_prediction_data = {}
        
        # ë°ì´í„° ìš”ì•½
        activation_overall = activation_scores.get('overall', 0)
        vitality_score = vitality.get('overall_publishing_complex_vitality', 0) * 100
        weekend_ratio = metrics.get('weekend_analysis', {}).get('weekend_ratio', 1.0)
        demographic_targeting = metrics.get('demographic_targeting', {})
        
        # ML ì˜ˆì¸¡ ë°ì´í„° ìƒì„¸ ì¶”ì¶œ
        predicted_visits = ml_prediction_data.get('visit_prediction', {}).get('predicted_visit', 0)
        crowd_level = ml_prediction_data.get('visit_prediction', {}).get('crowd_level', 0)
        optimal_time = ml_prediction_data.get('visit_prediction', {}).get('optimal_time', 'afternoon')
        
        # íë ˆì´ì…˜ ì§€í‘œ ìƒì„¸ ì¶”ì¶œ
        curation_metrics_detail = {}
        program_rankings = []
        if ml_prediction_data.get('curation_metrics'):
            curation_data = ml_prediction_data['curation_metrics']
            for prog_type, prog_metrics in curation_data.get('program_metrics', {}).items():
                curation_metrics_detail[prog_type] = {
                    'recommendation_score': prog_metrics.get('recommendation_score', 0),
                    'time_suitability': prog_metrics.get('time_suitability', 0),
                    'demographic_match': prog_metrics.get('demographic_match', 0),
                    'overall_score': prog_metrics.get('overall_score', 0),
                    'recommended': prog_metrics.get('recommended', False)
                }
                program_rankings.append({
                    'program': prog_type,
                    'overall_score': prog_metrics.get('overall_score', 0),
                    'recommendation_score': prog_metrics.get('recommendation_score', 0),
                    'time_suitability': prog_metrics.get('time_suitability', 0),
                    'demographic_match': prog_metrics.get('demographic_match', 0)
                })
            # ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬
            program_rankings.sort(key=lambda x: x['overall_score'], reverse=True)
        
        # ë‚ ì§œ ë ˆì´ë¸” ìƒì„±
        date_obj = datetime.strptime(date, '%Y-%m-%d')
        date_label = date_obj.strftime('%Yë…„ %mì›” %dì¼')
        weekday_name = ['ì›”ìš”ì¼', 'í™”ìš”ì¼', 'ìˆ˜ìš”ì¼', 'ëª©ìš”ì¼', 'ê¸ˆìš”ì¼', 'í† ìš”ì¼', 'ì¼ìš”ì¼'][date_obj.weekday()]
        is_weekend = date_obj.weekday() >= 5
        
        # íë ˆì´ì…˜ ì§€í‘œ ìƒì„¸ ì •ë³´ ë¬¸ìì—´ ìƒì„±
        curation_details_text = ""
        if curation_metrics_detail:
            curation_details_text = "\n**í”„ë¡œê·¸ë¨ë³„ ML ì˜ˆì¸¡ ì§€í‘œ (ìƒì„¸)**:\n"
            for prog_type, metrics in curation_metrics_detail.items():
                curation_details_text += f"- **{prog_type}**:\n"
                curation_details_text += f"  * ì¢…í•© ì ìˆ˜: {metrics['overall_score']:.1f}ì \n"
                curation_details_text += f"  * ì¶”ì²œ ì ìˆ˜: {metrics['recommendation_score']:.1f}ì \n"
                curation_details_text += f"  * ì‹œê°„ëŒ€ ì í•©ë„: {metrics['time_suitability']:.1f}ì \n"
                curation_details_text += f"  * íƒ€ê²Ÿ ê³ ê°ì¸µ ë§¤ì¹­: {metrics['demographic_match']:.1f}ì \n"
                if metrics['recommended']:
                    curation_details_text += f"  * âœ… ê°•ë ¥ ì¶”ì²œ í”„ë¡œê·¸ë¨\n"
                curation_details_text += "\n"
        
        # í”„ë¡œê·¸ë¨ ë­í‚¹ ì •ë³´
        program_ranking_text = ""
        if program_rankings:
            program_ranking_text = "\n**í”„ë¡œê·¸ë¨ ì¶”ì²œ ìˆœìœ„ (ML ì˜ˆì¸¡ ê¸°ë°˜)**:\n"
            for idx, prog in enumerate(program_rankings[:5], 1):
                program_ranking_text += f"{idx}. {prog['program']} (ì¢…í•© {prog['overall_score']:.1f}ì ) - "
                program_ranking_text += f"ì¶”ì²œ {prog['recommendation_score']:.1f}ì , "
                program_ranking_text += f"ì‹œê°„ ì í•©ë„ {prog['time_suitability']:.1f}ì , "
                program_ranking_text += f"íƒ€ê²Ÿ ë§¤ì¹­ {prog['demographic_match']:.1f}ì \n"
        
        # LLM í”„ë¡¬í”„íŠ¸ ìƒì„± (ë°ì´í„° ê¸°ë°˜ ì°½ì˜ì  ë¶„ì„ + íë ˆì´ì…˜ ì‹¤ìš©ì„± ê°•í™”)
        prompt = f"""ë‹¹ì‹ ì€ íŒŒì£¼ì‹œ ì¶œíŒë‹¨ì§€ í™œì„±í™”ë¥¼ ìœ„í•œ ì „ë¬¸ íë ˆì´ì…˜ ê¸°íšìì…ë‹ˆë‹¤.
ë‹¤ì–‘í•œ ë°ì´í„°ì™€ ì§€í‘œë¥¼ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬, íë ˆì´ì…˜ ê¸°íšìê°€ ì‹¤ì œë¡œ í™œìš©í•  ìˆ˜ ìˆëŠ” ì°½ì˜ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ í™œì„±í™” ì „ëµì„ ì œì‹œí•´ì£¼ì„¸ìš”.

**ë¶„ì„ ê¸°ì¤€ ë‚ ì§œ**: {date_label} ({date}, {weekday_name})
**ë‚ ì§œ íŠ¹ì„±**: {'ì£¼ë§' if is_weekend else 'í‰ì¼'} - {'ì£¼ë§ í”„ë¡œê·¸ë¨ í™•ëŒ€ ê¸°íšŒ' if is_weekend else 'í‰ì¼ ë°©ë¬¸ í™œì„±í™” í•„ìš”'}

**ğŸ“Š í•´ë‹¹ ë‚ ì§œ ì˜ˆì¸¡ ë°ì´í„° (í•µì‹¬ ì§€í‘œ)**:
- ì˜ˆìƒ ë°©ë¬¸ì¸êµ¬: {predicted_visits:,.0f}ëª…
- ì˜ˆìƒ í˜¼ì¡ë„: {crowd_level*100:.1f}% {'(í˜¼ì¡ ì˜ˆìƒ - ëŒ€ê·œëª¨ í”„ë¡œê·¸ë¨ ì í•©)' if crowd_level > 0.7 else '(ì—¬ìœ  ì˜ˆìƒ - ì†Œê·œëª¨ í”„ë¡œê·¸ë¨ ì í•©)' if crowd_level < 0.5 else '(ë³´í†µ - ë‹¤ì–‘í•œ í”„ë¡œê·¸ë¨ ìš´ì˜ ê°€ëŠ¥)'}
- ìµœì  ì‹œê°„ëŒ€: {optimal_time}

{curation_details_text}

{program_ranking_text}

**ğŸ“ˆ í™œì„±í™” ì§€í‘œ ë¶„ì„**:
- **ë¬¸í™” ê³µê°„ í™œì„±í™” ì ìˆ˜**: {activation_overall:.1f}ì  / 100ì 
  * ì ‘ê·¼ì„±: {activation_scores.get('accessibility', 0):.1f}ì  {'(ìš°ìˆ˜ - ì ‘ê·¼ì„± ê¸°ë°˜ ë§ˆì¼€íŒ… ê°•í™”)' if activation_scores.get('accessibility', 0) >= 70 else '(ë³´í†µ - ì ‘ê·¼ì„± ê°œì„  í•„ìš”)' if activation_scores.get('accessibility', 0) >= 50 else '(ë‚®ìŒ - êµí†µ/ì ‘ê·¼ì„± ê°œì„  ì‹œê¸‰)'}
  * ê´€ì‹¬ë„: {activation_scores.get('interest', 0):.1f}ì  {'(ìš°ìˆ˜ - ê´€ì‹¬ë„ ê¸°ë°˜ í”„ë¡œê·¸ë¨ í™•ëŒ€)' if activation_scores.get('interest', 0) >= 70 else '(ë³´í†µ - ê´€ì‹¬ë„ ì œê³  í•„ìš”)' if activation_scores.get('interest', 0) >= 50 else '(ë‚®ìŒ - ê´€ì‹¬ë„ ì œê³  ë§ˆì¼€íŒ… í•„ìš”)'}
  * ì ì¬ë ¥: {activation_scores.get('potential', 0):.1f}ì  {'(ìš°ìˆ˜ - ì ì¬ë ¥ ì‹¤í˜„ ì „ëµ ìˆ˜ë¦½)' if activation_scores.get('potential', 0) >= 70 else '(ë³´í†µ - ì ì¬ë ¥ ë°œêµ´ í•„ìš”)' if activation_scores.get('potential', 0) >= 50 else '(ë‚®ìŒ - ì ì¬ë ¥ ê°œë°œ ì „ëµ í•„ìš”)'}
  * í™œìš©ë„: {activation_scores.get('utilization', 0):.1f}ì  {'(ìš°ìˆ˜ - í™œìš©ë„ ê·¹ëŒ€í™” ì „ëµ)' if activation_scores.get('utilization', 0) >= 70 else '(ë³´í†µ - í™œìš©ë„ ê°œì„  í•„ìš”)' if activation_scores.get('utilization', 0) >= 50 else '(ë‚®ìŒ - í™œìš©ë„ ê°œì„  ì‹œê¸‰)'}

- **ì¶œíŒë‹¨ì§€ í™œì„±í™” ì§€ìˆ˜**: {vitality_score:.1f}ì  / 100ì 
- **ì£¼ë§/í‰ì¼ ë¹„ìœ¨**: {weekend_ratio:.2f}ë°° {'(ì£¼ë§ ì¤‘ì‹¬ - ì£¼ë§ í”„ë¡œê·¸ë¨ í™•ëŒ€)' if weekend_ratio > 1.2 else '(í‰ì¼ ì¤‘ì‹¬ - í‰ì¼ í™œì„±í™” ì „ëµ)' if weekend_ratio < 0.8 else '(ê· í˜• - ë‹¤ì–‘í•œ í”„ë¡œê·¸ë¨ ìš´ì˜)'}
- **ì£¼ìš” íƒ€ê²Ÿ ì„¸ê·¸ë¨¼íŠ¸**: {demographic_targeting.get('recommended_target', {}).get('age_group', 'N/A')} {demographic_targeting.get('recommended_target', {}).get('gender', 'N/A')} (ë§¤ì¹­ ì ìˆ˜: {demographic_targeting.get('recommended_target', {}).get('score', 0):.2f})

**ì§€ì—­ë³„ í™œì„±í™” ì§€ìˆ˜**:
{json.dumps(vitality.get('regional_indices', {}), ensure_ascii=False, indent=2) if vitality.get('regional_indices') else 'ë°ì´í„° ì—†ìŒ'}

**ğŸ¯ ë¶„ì„ ìš”êµ¬ì‚¬í•­ (ë°ì´í„° ê¸°ë°˜ ì°½ì˜ì  íë ˆì´ì…˜ ì „ëµ)**:

1. **ë¶„ì„ ìš”ì•½** (150-200ì): 
   - ì˜ˆìƒ ë°©ë¬¸ì¸êµ¬, í˜¼ì¡ë„, í”„ë¡œê·¸ë¨ ì¶”ì²œ ì ìˆ˜ ë“± ëª¨ë“  ë°ì´í„°ë¥¼ ì¢…í•©í•˜ì—¬ í•´ë‹¹ ë‚ ì§œì˜ í™œì„±í™” ìƒíƒœë¥¼ íë ˆì´ì…˜ ê´€ì ì—ì„œ ìš”ì•½
   - êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì–¸ê¸‰í•˜ë©°, íë ˆì´ì…˜ ê¸°íšìê°€ ì¦‰ì‹œ í™œìš©í•  ìˆ˜ ìˆëŠ” í•µì‹¬ ì¸ì‚¬ì´íŠ¸ ì œì‹œ

2. **ì„œìˆ í˜• ë¶„ì„** (6-8ê°œ ë¬¸ë‹¨, ê° 150-300ì):
   - **í™œì„±í™” ì „ë§ê³¼ íë ˆì´ì…˜ ê¸°íšŒ**: ì˜ˆìƒ ë°©ë¬¸ì¸êµ¬ {predicted_visits:,.0f}ëª…ê³¼ í˜¼ì¡ë„ {crowd_level*100:.1f}%ë¥¼ ë¶„ì„í•˜ì—¬ í•´ë‹¹ ë‚ ì§œì— ì–´ë–¤ í”„ë¡œê·¸ë¨ì´ íš¨ê³¼ì ì¼ì§€ íë ˆì´ì…˜ ê´€ì ì—ì„œ ì œì‹œ
   - **í”„ë¡œê·¸ë¨ë³„ ì í•©ë„ ë¶„ì„**: í”„ë¡œê·¸ë¨ ë­í‚¹ê³¼ ê° í”„ë¡œê·¸ë¨ì˜ ì¶”ì²œ ì ìˆ˜, ì‹œê°„ ì í•©ë„, íƒ€ê²Ÿ ë§¤ì¹­ ì ìˆ˜ë¥¼ ë¹„êµí•˜ì—¬ íë ˆì´ì…˜ ê¸°íšìê°€ ì„ íƒí•  ìˆ˜ ìˆëŠ” ìµœì  í”„ë¡œê·¸ë¨ ì¡°í•©ê³¼ ìš´ì˜ ì‹œì  ì œì‹œ
   - **í™œì„±í™” ì§€í‘œ í•´ì„ê³¼ íë ˆì´ì…˜ ì „ëµ**: ì ‘ê·¼ì„±({activation_scores.get('accessibility', 0):.1f}ì ), ê´€ì‹¬ë„({activation_scores.get('interest', 0):.1f}ì ), ì ì¬ë ¥({activation_scores.get('potential', 0):.1f}ì ), í™œìš©ë„({activation_scores.get('utilization', 0):.1f}ì )ë¥¼ íë ˆì´ì…˜ ê¸°íš ê´€ì ì—ì„œ í•´ì„í•˜ê³ , ê° ì§€í‘œë¥¼ ê°œì„ í•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì  í”„ë¡œê·¸ë¨ ê¸°íš ë°©ì•ˆ ì œì‹œ
   - **ë‚ ì§œë³„ ë§ì¶¤ íë ˆì´ì…˜ ì „ëµ**: {'ì£¼ë§' if is_weekend else 'í‰ì¼'} íŠ¹ì„±ê³¼ ì˜ˆìƒ ë°©ë¬¸ì¸êµ¬, í”„ë¡œê·¸ë¨ ì¶”ì²œ ì ìˆ˜ë¥¼ ì¢…í•©í•˜ì—¬ í•´ë‹¹ ë‚ ì§œì— ê°€ì¥ íš¨ê³¼ì ì¸ í”„ë¡œê·¸ë¨ êµ¬ì„±ê³¼ ìš´ì˜ ë°©ì‹ ì œì‹œ
   - **ì§€ì—­ë³„ íŠ¹ì„±ì„ í™œìš©í•œ íë ˆì´ì…˜**: ì§€ì—­ë³„ í™œì„±í™” ì§€ìˆ˜ ì°¨ì´ë¥¼ ë¶„ì„í•˜ì—¬ ì§€ì—­ë³„ë¡œ ë‹¤ë¥¸ í”„ë¡œê·¸ë¨ì„ ê¸°íší•˜ê±°ë‚˜, í†µí•© í”„ë¡œê·¸ë¨ìœ¼ë¡œ ì§€ì—­ ê°„ ì‹œë„ˆì§€ë¥¼ ì°½ì¶œí•˜ëŠ” ì „ëµ ì œì‹œ
   - **íƒ€ê²Ÿ ê³ ê° ë§ì¶¤ íë ˆì´ì…˜**: ì£¼ìš” íƒ€ê²Ÿ({demographic_targeting.get('recommended_target', {}).get('age_group', 'N/A')} {demographic_targeting.get('recommended_target', {}).get('gender', 'N/A')})ê³¼ í”„ë¡œê·¸ë¨ë³„ íƒ€ê²Ÿ ë§¤ì¹­ ì ìˆ˜ë¥¼ ì—°ê³„í•˜ì—¬, í•´ë‹¹ ê³ ê°ì¸µì—ê²Œ ê°€ì¥ ë§¤ë ¥ì ì¸ í”„ë¡œê·¸ë¨ êµ¬ì„±ê³¼ ë§ˆì¼€íŒ… í¬ì¸íŠ¸ ì œì‹œ
   - **ì°½ì˜ì  íë ˆì´ì…˜ ì•„ì´ë””ì–´**: ë°ì´í„° íŒ¨í„´(ì˜ˆ: í˜¼ì¡ë„ê°€ ë†’ì€ë° ì „ì‹œíšŒ ì ìˆ˜ê°€ ë†’ìŒ)ì„ ë°œê²¬í•˜ì—¬, ê¸°ì¡´ì— ì—†ë˜ ìƒˆë¡œìš´ í”„ë¡œê·¸ë¨ ì¡°í•©ì´ë‚˜ ìš´ì˜ ë°©ì‹ ì œì•ˆ
   - **ì‹¤í–‰ ê°€ëŠ¥í•œ íë ˆì´ì…˜ ê³„íš**: ëª¨ë“  ë°ì´í„°ë¥¼ ì¢…í•©í•˜ì—¬ íë ˆì´ì…˜ ê¸°íšìê°€ ë°”ë¡œ ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì ì´ê³  ë‹¨ê³„ë³„ í”„ë¡œê·¸ë¨ ê¸°íšì•ˆ ì œì‹œ

3. **ì£¼ìš” ê°•ì ** (4-6ê°œ): 
   - ë°ì´í„°ì—ì„œ ë°œê²¬í•œ íë ˆì´ì…˜ ê°•ì  (ì˜ˆ: "ë¶í† í¬ í”„ë¡œê·¸ë¨ì´ 85ì ìœ¼ë¡œ ê°€ì¥ ë†’ì€ ì í•©ë„ë¥¼ ë³´ì—¬ í•´ë‹¹ ë‚ ì§œ ìµœìš°ì„  í”„ë¡œê·¸ë¨ìœ¼ë¡œ ì¶”ì²œ")
   - í™œì„±í™” ì§€í‘œì—ì„œ ìš°ìˆ˜í•œ í•­ëª©ê³¼ ì´ë¥¼ í™œìš©í•œ íë ˆì´ì…˜ ê¸°íšŒ
   - ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ í™•ì¸ëœ ê²½ìŸ ìš°ìœ„ ìš”ì†Œì™€ ì´ë¥¼ ì‚´ë¦° í”„ë¡œê·¸ë¨ ê¸°íš ë°©í–¥

4. **ê°œì„  í•„ìš” ì˜ì—­** (4-6ê°œ): 
   - ë‚®ì€ ì ìˆ˜ë¥¼ ë°›ì€ í”„ë¡œê·¸ë¨ì˜ ê°œì„  ë°©ì•ˆê³¼ ëŒ€ì•ˆ í”„ë¡œê·¸ë¨ ì œì‹œ
   - í™œì„±í™” ì§€í‘œ ì¤‘ ì €ì¡°í•œ í•­ëª©ì„ ê°œì„ í•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì  íë ˆì´ì…˜ ì „ëµ
   - ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ í™•ì¸ëœ ê°œì„  í¬ì¸íŠ¸ì™€ ì´ë¥¼ í•´ê²°í•  í”„ë¡œê·¸ë¨ ê¸°íš ì•„ì´ë””ì–´

5. **ì°½ì˜ì  í™œì„±í™” ê¸°íšŒ** (7-10ê°œ): 
   - ë°ì´í„° íŒ¨í„´ì—ì„œ ë°œê²¬í•œ ìƒˆë¡œìš´ íë ˆì´ì…˜ ê¸°íšŒ (ì˜ˆ: "í˜¼ì¡ë„ëŠ” ë†’ì§€ë§Œ ì „ì‹œíšŒ ì ìˆ˜ê°€ ë†’ì•„ ëŒ€ê·œëª¨ ì „ì‹œ í”„ë¡œê·¸ë¨ìœ¼ë¡œ ë°©ë¬¸ê° ìœ ë„ ê°€ëŠ¥")
   - í”„ë¡œê·¸ë¨ ì ìˆ˜ ì¡°í•©ì„ í†µí•œ í•˜ì´ë¸Œë¦¬ë“œ í”„ë¡œê·¸ë¨ ì•„ì´ë””ì–´ (ì˜ˆ: "ë¶í† í¬ì™€ ì‘ê°€ ì‚¬ì¸íšŒë¥¼ ì—°ê³„í•œ í”„ë¡œê·¸ë¨")
   - ì˜ˆìƒ ë°©ë¬¸ì¸êµ¬ì™€ í”„ë¡œê·¸ë¨ ì¶”ì²œ ì ìˆ˜ë¥¼ ì—°ê³„í•œ ì°½ì˜ì  í”„ë¡œê·¸ë¨ ê¸°íš
   - ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ ë„ì¶œí•œ í˜ì‹ ì  íë ˆì´ì…˜ ì•„ì´ë””ì–´

6. **ì‹¤í–‰ ê°€ëŠ¥í•œ ì¶”ì²œì‚¬í•­** (10-12ê°œ): 
   - í”„ë¡œê·¸ë¨ë³„ ì ìˆ˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ êµ¬ì²´ì  ì¶”ì²œ (ì˜ˆ: "ë¶í† í¬ í”„ë¡œê·¸ë¨ì´ 85ì ìœ¼ë¡œ ê°€ì¥ ë†’ì•„ ì˜¤í›„ 2-4ì‹œ ìš´ì˜ ì‹œ ìµœì  íš¨ê³¼ ì˜ˆìƒ")
   - ì˜ˆìƒ ë°©ë¬¸ì¸êµ¬ì™€ í˜¼ì¡ë„ë¥¼ ê³ ë ¤í•œ í”„ë¡œê·¸ë¨ ê·œëª¨, ìš´ì˜ ë°©ì‹, ê³µê°„ ë°°ì¹˜ ì¶”ì²œ
   - íƒ€ê²Ÿ ì„¸ê·¸ë¨¼íŠ¸ ë§¤ì¹­ ì ìˆ˜ë¥¼ í™œìš©í•œ ë§ˆì¼€íŒ… í¬ì¸íŠ¸ì™€ í™ë³´ ì „ëµ
   - í™œì„±í™” ì ìˆ˜ ê°œì„ ì„ ìœ„í•œ êµ¬ì²´ì  í”„ë¡œê·¸ë¨ ê¸°íš ì•¡ì…˜ ì•„ì´í…œ
   - íë ˆì´ì…˜ ê¸°íšìê°€ ë°”ë¡œ ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” ì‹¤ìš©ì  ì¶”ì²œ

7. **ë‹¨ê³„ë³„ ì‹¤í–‰ ê³„íš** (6ë‹¨ê³„): 
   - ë°ì´í„°ë¥¼ í™œìš©í•œ íë ˆì´ì…˜ ê¸°íš ë‹¨ê³„ë³„ ì‹¤í–‰ ê³„íš
   - ê° ë‹¨ê³„ì—ì„œ í™œìš©í•  êµ¬ì²´ì  ì§€í‘œì™€ ëª©í‘œ ìˆ˜ì¹˜, ê·¸ë¦¬ê³  í”„ë¡œê·¸ë¨ ê¸°íš í¬ì¸íŠ¸ ì œì‹œ

**ì‘ë‹µ í˜•ì‹** (JSON):
{{
  "summary": "ë°ì´í„°ë¥¼ ì¢…í•©í•œ í™œì„±í™” ìƒíƒœ ìš”ì•½ (150-200ì, êµ¬ì²´ì  ìˆ˜ì¹˜ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ í¬í•¨)",
  "detailed_analysis": [
    "í™œì„±í™” ì „ë§ê³¼ íë ˆì´ì…˜ ê¸°íšŒ (150-300ì, ì˜ˆìƒ ë°©ë¬¸ì¸êµ¬ì™€ í˜¼ì¡ë„ ë¶„ì„)",
    "í”„ë¡œê·¸ë¨ë³„ ì í•©ë„ ë¶„ì„ (150-300ì, í”„ë¡œê·¸ë¨ ë­í‚¹ê³¼ ì ìˆ˜ ë¹„êµ)",
    "í™œì„±í™” ì§€í‘œ í•´ì„ê³¼ íë ˆì´ì…˜ ì „ëµ (150-300ì, ì§€í‘œ ê°„ ìƒê´€ê´€ê³„ ë¶„ì„)",
    "ë‚ ì§œë³„ ë§ì¶¤ íë ˆì´ì…˜ ì „ëµ (150-300ì, ë‚ ì§œë³„ ë§ì¶¤ ì „ëµ)",
    "ì§€ì—­ë³„ íŠ¹ì„±ì„ í™œìš©í•œ íë ˆì´ì…˜ (150-300ì, í†µí•© ë° ì§€ì—­ë³„ ì „ëµ)",
    "íƒ€ê²Ÿ ê³ ê° ë§ì¶¤ íë ˆì´ì…˜ (150-300ì, ìµœì  í”„ë¡œê·¸ë¨ ì¶”ì²œ)",
    "ì°½ì˜ì  íë ˆì´ì…˜ ì•„ì´ë””ì–´ (150-300ì, ë°ì´í„° íŒ¨í„´ ê¸°ë°˜ ê¸°íšŒ)",
    "ì‹¤í–‰ ê°€ëŠ¥í•œ íë ˆì´ì…˜ ê³„íš (150-300ì, êµ¬ì²´ì  ë‹¨ê³„ë³„ ê³„íš)"
  ],
  "strengths": ["ë°ì´í„° ê¸°ë°˜ ê°•ì  1 (60-120ì, êµ¬ì²´ì  ìˆ˜ì¹˜ í¬í•¨)", "ê°•ì  2", "ê°•ì  3", "ê°•ì  4", "ê°•ì  5", "ê°•ì  6"],
  "weaknesses": ["ë°ì´í„° ê¸°ë°˜ ê°œì„ ì  1 (60-120ì, êµ¬ì²´ì  ìˆ˜ì¹˜ í¬í•¨)", "ê°œì„ ì  2", "ê°œì„ ì  3", "ê°œì„ ì  4", "ê°œì„ ì  5", "ê°œì„ ì  6"],
  "opportunities": ["ë°ì´í„° íŒ¨í„´ ê¸°ë°˜ ê¸°íšŒ 1 (60-120ì)", "ê¸°íšŒ 2", "ê¸°íšŒ 3", "ê¸°íšŒ 4", "ê¸°íšŒ 5", "ê¸°íšŒ 6", "ê¸°íšŒ 7", "ê¸°íšŒ 8", "ê¸°íšŒ 9", "ê¸°íšŒ 10"],
  "recommendations": ["ë°ì´í„° ê¸°ë°˜ ì¶”ì²œ 1 (60-120ì, êµ¬ì²´ì  ìˆ˜ì¹˜ í¬í•¨)", "ì¶”ì²œ 2", "ì¶”ì²œ 3", "ì¶”ì²œ 4", "ì¶”ì²œ 5", "ì¶”ì²œ 6", "ì¶”ì²œ 7", "ì¶”ì²œ 8", "ì¶”ì²œ 9", "ì¶”ì²œ 10", "ì¶”ì²œ 11", "ì¶”ì²œ 12"],
  "action_plan": ["1ë‹¨ê³„: ë°ì´í„° ê¸°ë°˜ íë ˆì´ì…˜ ê¸°íš ... (60-120ì, êµ¬ì²´ì  ì§€í‘œì™€ ëª©í‘œ)", "2ë‹¨ê³„: ...", "3ë‹¨ê³„: ...", "4ë‹¨ê³„: ...", "5ë‹¨ê³„: ...", "6ë‹¨ê³„: ..."]
}}

**ğŸ¨ ì°½ì˜ì„± ë° íë ˆì´ì…˜ ì‹¤ìš©ì„± ì§€ì¹¨**:
- **ë°ì´í„° ì ê·¹ í™œìš©**: ì˜ˆìƒ ë°©ë¬¸ì¸êµ¬, í˜¼ì¡ë„, í”„ë¡œê·¸ë¨ë³„ ì¶”ì²œ ì ìˆ˜, ì‹œê°„ ì í•©ë„, íƒ€ê²Ÿ ë§¤ì¹­ ì ìˆ˜ ë“± ëª¨ë“  ë°ì´í„°ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì–¸ê¸‰í•˜ë©° ë¶„ì„í•˜ë˜, "ML", "ì˜ˆì¸¡ ëª¨ë¸" ê°™ì€ ê¸°ìˆ  ìš©ì–´ëŠ” ì‚¬ìš©í•˜ì§€ ë§ê³  ìì—°ìŠ¤ëŸ½ê²Œ ì„œìˆ 
- **íŒ¨í„´ ë°œê²¬ê³¼ íë ˆì´ì…˜ ì—°ê²°**: ë°ì´í„° ê°„ì˜ íŒ¨í„´(ì˜ˆ: "í˜¼ì¡ë„ê°€ ë†’ì€ë° ì „ì‹œíšŒ ì ìˆ˜ê°€ ë†’ìŒ â†’ ëŒ€ê·œëª¨ ì „ì‹œ í”„ë¡œê·¸ë¨ìœ¼ë¡œ ë°©ë¬¸ê° ìœ ë„")ì„ ë°œê²¬í•˜ì—¬ íë ˆì´ì…˜ ê¸°íšìê°€ ë°”ë¡œ í™œìš©í•  ìˆ˜ ìˆëŠ” ì•„ì´ë””ì–´ë¡œ ì œì‹œ
- **ìˆ˜ì¹˜ ê¸°ë°˜ ì‹¤ìš©ì  ë¶„ì„**: ëª¨ë“  ì¶”ì²œê³¼ ë¶„ì„ì— êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ì™€ ì ìˆ˜ë¥¼ í¬í•¨í•˜ë˜, íë ˆì´ì…˜ ê¸°íš ê´€ì ì—ì„œ "ì™œ ì´ í”„ë¡œê·¸ë¨ì´ ì¢‹ì€ì§€", "ì–´ë–»ê²Œ ìš´ì˜í•˜ë©´ íš¨ê³¼ì ì¸ì§€"ë¥¼ ëª…í™•íˆ ì œì‹œ
- **í”„ë¡œê·¸ë¨ ì¡°í•© ì•„ì´ë””ì–´**: í”„ë¡œê·¸ë¨ë³„ ì ìˆ˜ë¥¼ ë¹„êµí•˜ì—¬ í•˜ì´ë¸Œë¦¬ë“œ í”„ë¡œê·¸ë¨(ì˜ˆ: "ë¶í† í¬ì™€ ì‘ê°€ ì‚¬ì¸íšŒë¥¼ ì—°ê³„í•œ í”„ë¡œê·¸ë¨") ë“± ì°½ì˜ì  ì¡°í•©ì„ íë ˆì´ì…˜ ê¸°íšìê°€ ë°”ë¡œ ì‹¤í–‰í•  ìˆ˜ ìˆë„ë¡ êµ¬ì²´ì ìœ¼ë¡œ ì œì‹œ
- **ì˜ˆì¸¡ ê¸°ë°˜ ìš´ì˜ ì „ëµ**: ì˜ˆìƒ ë°©ë¬¸ì¸êµ¬ì™€ í˜¼ì¡ë„ë¥¼ í™œìš©í•œ êµ¬ì²´ì  ìš´ì˜ ì „ëµ(ì˜ˆ: "{predicted_visits:,.0f}ëª… ì˜ˆìƒì´ë¯€ë¡œ 3ê°œ í”„ë¡œê·¸ë¨ ë™ì‹œ ìš´ì˜ì´ íš¨ê³¼ì ")ì„ íë ˆì´ì…˜ ê´€ì ì—ì„œ ì œì‹œ
- **ì ìˆ˜ ê¸°ë°˜ ìš°ì„ ìˆœìœ„**: í”„ë¡œê·¸ë¨ ë­í‚¹ê³¼ ì ìˆ˜ë¥¼ í™œìš©í•˜ì—¬ íë ˆì´ì…˜ ê¸°íš ì‹œ ì–´ë–¤ í”„ë¡œê·¸ë¨ì„ ìš°ì„  ê¸°íší•´ì•¼ í•˜ëŠ”ì§€ ëª…í™•íˆ ì œì‹œ
- **íƒ€ê²Ÿ ë§ì¶¤ íë ˆì´ì…˜**: íƒ€ê²Ÿ ì„¸ê·¸ë¨¼íŠ¸ì™€ í”„ë¡œê·¸ë¨ë³„ íƒ€ê²Ÿ ë§¤ì¹­ ì ìˆ˜ë¥¼ ì—°ê³„í•˜ì—¬, í•´ë‹¹ ê³ ê°ì¸µì—ê²Œ ì–´ë–¤ í”„ë¡œê·¸ë¨ì„ ì–´ë–»ê²Œ êµ¬ì„±í•˜ë©´ ì¢‹ì„ì§€ êµ¬ì²´ì ìœ¼ë¡œ ì œì‹œ
- **ì°½ì˜ì  íë ˆì´ì…˜ ì•„ì´ë””ì–´**: ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•˜ë˜, ê¸°ì¡´ì— ì—†ë˜ ìƒˆë¡œìš´ í”„ë¡œê·¸ë¨ í˜•íƒœë‚˜ ìš´ì˜ ë°©ì‹ì„ íë ˆì´ì…˜ ê¸°íšìê°€ ë°”ë¡œ ì‹¤í–‰í•  ìˆ˜ ìˆë„ë¡ êµ¬ì²´ì ìœ¼ë¡œ ì œì•ˆ
- **ì‹¤í–‰ ê°€ëŠ¥ì„± ê°•ì¡°**: ëª¨ë“  ì•„ì´ë””ì–´ëŠ” ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ ì œì‹œí•˜ì—¬ ì‹¤í–‰ ê°€ëŠ¥ì„±ê³¼ íš¨ê³¼ë¥¼ ì…ì¦í•˜ë˜, íë ˆì´ì…˜ ê¸°íšìê°€ ë°”ë¡œ í™œìš©í•  ìˆ˜ ìˆëŠ” ì‹¤ìš©ì ì¸ ë‚´ìš©ìœ¼ë¡œ ì‘ì„±
- **ìì—°ìŠ¤ëŸ¬ìš´ ì„œìˆ **: "ë°ì´í„° ë¶„ì„ ê²°ê³¼", "ì˜ˆìƒ ë°©ë¬¸ì¸êµ¬", "í”„ë¡œê·¸ë¨ ì í•©ë„" ë“± ìì—°ìŠ¤ëŸ¬ìš´ í‘œí˜„ ì‚¬ìš©. "ML", "ë¨¸ì‹ ëŸ¬ë‹", "ì˜ˆì¸¡ ëª¨ë¸" ê°™ì€ ê¸°ìˆ  ìš©ì–´ëŠ” ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ ê²ƒ
- **íë ˆì´ì…˜ ì‹¤ìš©ì„±**: íë ˆì´ì…˜ ê¸°íšìê°€ ì‹¤ì œë¡œ í”„ë¡œê·¸ë¨ì„ ê¸°íší•˜ê³  ìš´ì˜í•  ë•Œ í•„ìš”í•œ êµ¬ì²´ì  ì •ë³´(ì‹œê°„ëŒ€, ê·œëª¨, íƒ€ê²Ÿ, ë§ˆì¼€íŒ… í¬ì¸íŠ¸ ë“±)ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ì‘ì„±

ì‘ë‹µì€ ë°˜ë“œì‹œ ìœ íš¨í•œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì œê³µí•´ì£¼ì„¸ìš”.
"""
        
        # LLM ë¶„ì„ ìˆ˜í–‰
        response_text = content_generator.analyze_data(prompt)
        
        # JSON íŒŒì‹± ì‹œë„
        try:
            if isinstance(response_text, dict):
                analysis = response_text
            elif isinstance(response_text, str):
                # JSON ì¶”ì¶œ ì‹œë„
                import re
                json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
                if json_match:
                    analysis = json.loads(json_match.group())
                else:
                    analysis = json.loads(response_text)
            else:
                raise ValueError("ì˜ˆìƒì¹˜ ëª»í•œ ì‘ë‹µ í˜•ì‹")
        except (json.JSONDecodeError, ValueError) as e:
            print(f"[API] JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
            print(f"[API] ì‘ë‹µ í…ìŠ¤íŠ¸: {response_text[:500]}")
            # ê¸°ë³¸ ë¶„ì„ ìƒì„± (ì˜ˆì¸¡ ë°ì´í„° ë°˜ì˜)
            visit_summary = ""
            if ml_prediction_data.get('visit_prediction'):
                visit_summary = f"{predicted_visits:,.0f}ëª…ì˜ ë°©ë¬¸ê°ì´ ì˜ˆìƒë˜ë©°, í˜¼ì¡ë„ëŠ” {crowd_level*100:.1f}%ë¡œ {'í˜¼ì¡ ì˜ˆìƒ' if crowd_level > 0.7 else 'ì—¬ìœ  ì˜ˆìƒ' if crowd_level < 0.5 else 'ë³´í†µ'}ì…ë‹ˆë‹¤. "
            
            # í”„ë¡œê·¸ë¨ ì¶”ì²œ ìš”ì•½ ìƒì„±
            program_recs = ""
            if program_rankings:
                top_programs = [prog['program'] for prog in program_rankings[:3]]
                if top_programs:
                    program_recs = f"ì¶”ì²œ í”„ë¡œê·¸ë¨: {', '.join(top_programs)} "
            
            analysis = {
                "summary": f"{visit_summary}ì¶œíŒë‹¨ì§€ í™œì„±í™” ì§€ìˆ˜ê°€ {vitality_score:.1f}ì ìœ¼ë¡œ, {'í™œì„±í™”ê°€ ì§„í–‰ ì¤‘' if vitality_score >= 70 else 'ê°œì„ ì´ í•„ìš”'}í•©ë‹ˆë‹¤. {program_recs}",
                "detailed_analysis": [
                    f"{date_label}({weekday_name})ì—ëŠ” {predicted_visits:,.0f}ëª…ì˜ ë°©ë¬¸ê°ì´ ì˜ˆìƒë©ë‹ˆë‹¤. ì´ëŠ” {'ì£¼ë§ í”„ë¡œê·¸ë¨ í™•ëŒ€ê°€ íš¨ê³¼ì ì¼' if is_weekend else 'í‰ì¼ ë°©ë¬¸ í™œì„±í™”ê°€ í•„ìš”í•œ'} ì‹œê¸°ë¡œ, {'í˜¼ì¡ë„ ê´€ë¦¬ê°€ í•„ìš”' if crowd_level > 0.7 else 'í”„ë¡œê·¸ë¨ í™•ëŒ€ ì—¬ìœ ê°€ ìˆëŠ”'} ìƒí™©ì…ë‹ˆë‹¤.",
                    f"íŒŒì£¼ì‹œ ì¶œíŒë‹¨ì§€ì˜ í˜„ì¬ í™œì„±í™” ì§€ìˆ˜ëŠ” {vitality_score:.1f}ì ìœ¼ë¡œ í‰ê°€ë©ë‹ˆë‹¤. ë¬¸í™” ê³µê°„ í™œì„±í™” ì ìˆ˜ {activation_overall:.1f}ì ê³¼ í•¨ê»˜ ì¢…í•©í•˜ë©´, {'ëª©í‘œ ìˆ˜ì¤€ì— ê·¼ì ‘í•œ' if vitality_score >= 70 else 'ëª©í‘œ ìˆ˜ì¤€ë³´ë‹¤ ë‚®ì€'} ìƒíƒœë¡œ {'ì§€ì†ì ì¸ í™œì„±í™” ë…¸ë ¥ì´ í•„ìš”í•œ' if vitality_score >= 70 else 'ì¦‰ê°ì ì¸ ê°œì„  ì „ëµì´ ìš”êµ¬ë˜ëŠ”'} ìƒí™©ì…ë‹ˆë‹¤.",
                    f"ì£¼ë§/í‰ì¼ ë°©ë¬¸ ë¹„ìœ¨ {weekend_ratio:.2f}ë°°ì™€ {'ì£¼ë§' if is_weekend else 'í‰ì¼'} íŠ¹ì„±ì„ ê³ ë ¤í•˜ë©´, ì¶œíŒë‹¨ì§€ì˜ í™œì„±í™”ëŠ” {'ì£¼ë§ ì¤‘ì‹¬' if weekend_ratio > 1.2 else 'í‰ì¼ ì¤‘ì‹¬' if weekend_ratio < 0.8 else 'ê· í˜•ì¡íŒ'} íŒ¨í„´ì„ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤. {program_recs}í•´ë‹¹ ë‚ ì§œì— ë§ì¶˜ í”„ë¡œê·¸ë¨ ìš´ì˜ì´ í•„ìš”í•©ë‹ˆë‹¤.",
                    "ì§€ì—­ë³„ í™œì„±í™” ì§€ìˆ˜ë¥¼ ë¶„ì„í•œ ê²°ê³¼, ê° ì§€ì—­ë§ˆë‹¤ ê³ ìœ í•œ íŠ¹ì„±ì„ ê°€ì§€ê³  ìˆì–´ ì§€ì—­ë³„ ë§ì¶¤í˜• ì „ëµì´ í•„ìš”í•©ë‹ˆë‹¤. íŠ¹íˆ ì†Œë¹„í™œë ¥ê³¼ ìƒì‚°í™œë ¥ì˜ ì°¨ì´ê°€ ì§€ì—­ë³„ í™œì„±í™” ìˆ˜ì¤€ì— ì˜í–¥ì„ ë¯¸ì¹˜ê³  ìˆìŠµë‹ˆë‹¤.",
                    f"í™œì„±í™” ì ìˆ˜ ì„¸ë¶€ ë¶„ì„: ì ‘ê·¼ì„± {activation_scores.get('accessibility', 0):.1f}ì , ê´€ì‹¬ë„ {activation_scores.get('interest', 0):.1f}ì , ì ì¬ë ¥ {activation_scores.get('potential', 0):.1f}ì , í™œìš©ë„ {activation_scores.get('utilization', 0):.1f}ì ìœ¼ë¡œ, {'ì ‘ê·¼ì„±' if activation_scores.get('accessibility', 0) < 60 else 'ê´€ì‹¬ë„' if activation_scores.get('interest', 0) < 60 else 'ì ì¬ë ¥' if activation_scores.get('potential', 0) < 60 else 'í™œìš©ë„'} ê°œì„ ì´ ê°€ì¥ ì‹œê¸‰í•©ë‹ˆë‹¤.",
                    f"ì „ë°˜ì ìœ¼ë¡œ ì¶œíŒë‹¨ì§€ í™œì„±í™”ëŠ” {'ê¸ì •ì ì¸ ì¶”ì„¸' if vitality_score >= 70 else 'ê°œì„ ì˜ ì—¬ì§€ê°€ ë§ì€'} ìƒíƒœì…ë‹ˆë‹¤. í•´ë‹¹ ë‚ ì§œì˜ ì˜ˆìƒ ë°©ë¬¸ì¸êµ¬ì™€ ì‹¤ì œ ì§€í‘œë¥¼ ì¢…í•©í•˜ì—¬, ë‚ ì§œì— ë§ì¶˜ í”„ë¡œê·¸ë¨ ìš´ì˜ê³¼ ì§€ì—­ íŠ¹ì„±ì„ ë°˜ì˜í•œ ë§ì¶¤í˜• ì „ëµì„ í†µí•´ í™œì„±í™” ìˆ˜ì¤€ì„ ë”ìš± í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆì„ ê²ƒì…ë‹ˆë‹¤.",
                    f"í–¥í›„ {date_label}ë¥¼ ìœ„í•œ ì‹¤í–‰ ê³„íš: {program_recs if program_recs else ''}ì˜ˆìƒ ë°©ë¬¸ì¸êµ¬ë¥¼ ê³ ë ¤í•œ {'í˜¼ì¡ë„ ê´€ë¦¬' if crowd_level > 0.7 else 'í”„ë¡œê·¸ë¨ í™•ëŒ€'}ì™€ {'ì£¼ë§' if is_weekend else 'í‰ì¼'} íŠ¹ì„±ì— ë§ëŠ” íë ˆì´ì…˜ í”„ë¡œê·¸ë¨ ìš´ì˜ì´ í•µì‹¬ì…ë‹ˆë‹¤."
                ],
                "strengths": [
                    f"{predicted_visits:,.0f}ëª…ì˜ ë°©ë¬¸ê°ì´ ì˜ˆìƒë˜ì–´ í™œì„±í™” ì—¬ê±´ì´ ì–‘í˜¸í•©ë‹ˆë‹¤" if predicted_visits > 0 else "ì§€ì—­ë³„ í™œì„±í™” ì§€ìˆ˜ ë°ì´í„°ê°€ ì²´ê³„ì ìœ¼ë¡œ ê´€ë¦¬ë˜ê³  ìˆìŠµë‹ˆë‹¤",
                    "ì£¼ë§ ë°©ë¬¸ íŒ¨í„´ì´ ëª…í™•í•˜ê²Œ ë¶„ì„ë˜ì–´ ì£¼ë§ í”„ë¡œê·¸ë¨ ìš´ì˜ì— ìœ ë¦¬í•©ë‹ˆë‹¤" if weekend_ratio > 1.2 else "ì£¼ë§/í‰ì¼ ë°©ë¬¸ íŒ¨í„´ì´ ê· í˜•ì¡í˜€ ìˆìŠµë‹ˆë‹¤",
                    f"{demographic_targeting.get('recommended_target', {}).get('age_group', 'N/A')} íƒ€ê²Ÿ ì„¸ê·¸ë¨¼íŠ¸ê°€ ëª…í™•í•˜ê²Œ ì‹ë³„ë˜ì–´ ìˆìŠµë‹ˆë‹¤" if demographic_targeting.get('recommended_target') else "í™œì„±í™” ì ìˆ˜ ë°ì´í„°ê°€ ì²´ê³„ì ìœ¼ë¡œ ê´€ë¦¬ë˜ê³  ìˆìŠµë‹ˆë‹¤"
                ],
                "weaknesses": [
                    f"í™œì„±í™” ì ìˆ˜ê°€ ëª©í‘œì¹˜ì— ë¯¸ì¹˜ì§€ ëª»í•˜ê³  ìˆìŠµë‹ˆë‹¤ (í˜„ì¬ {activation_overall:.1f}ì )",
                    f"ì ‘ê·¼ì„±ì´ {activation_scores.get('accessibility', 0):.1f}ì ìœ¼ë¡œ ë‚®ì•„ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤" if activation_scores.get('accessibility', 0) < 60 else "í‰ì¼ ë°©ë¬¸ í™œì„±í™”ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤" if not is_weekend else "í™œì„±í™” ì§€ìˆ˜ê°€ ëª©í‘œ ìˆ˜ì¤€ì— ë¯¸ì¹˜ì§€ ëª»í•˜ê³  ìˆìŠµë‹ˆë‹¤",
                    f"ì ì¬ë ¥ì´ {activation_scores.get('potential', 0):.1f}ì ìœ¼ë¡œ ë‚®ì•„ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤" if activation_scores.get('potential', 0) < 60 else "ì§€ì—­ë³„ í™œì„±í™” ìˆ˜ì¤€ ì°¨ì´ê°€ ìˆìŠµë‹ˆë‹¤"
                ],
                "opportunities": [
                    f"{date_label} ì˜ˆìƒ ë°©ë¬¸ì¸êµ¬ {predicted_visits:,.0f}ëª…ì„ í™œìš©í•œ í”„ë¡œê·¸ë¨ ìš´ì˜ ê¸°íšŒ" if predicted_visits > 0 else "ì£¼ë§ í”„ë¡œê·¸ë¨ì„ í™•ëŒ€í•˜ì—¬ í™œì„±í™”ë¥¼ ë†’ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤",
                    f"{'ì£¼ë§' if is_weekend else 'í‰ì¼'} íŠ¹ì„±ì„ í™œìš©í•œ ë§ì¶¤ í”„ë¡œê·¸ë¨ ê°œë°œ ê¸°íšŒ",
                    f"{', '.join([prog['program'] for prog in program_rankings[:3]])} í”„ë¡œê·¸ë¨ ìš´ì˜ìœ¼ë¡œ í™œì„±í™” ì œê³  ê°€ëŠ¥" if program_rankings else "íƒ€ê²Ÿ ê³ ê°ì¸µ ë§ì¶¤ í”„ë¡œê·¸ë¨ ê°œë°œì´ í•„ìš”í•©ë‹ˆë‹¤",
                    "ì§€ì—­ë³„ í™œì„±í™” ì§€ìˆ˜ ì°¨ì´ë¥¼ í™œìš©í•œ í†µí•© ì „ëµ ìˆ˜ë¦½ ê¸°íšŒ",
                    "ë‚ ì§œë³„ ë§ì¶¤ í”„ë¡œê·¸ë¨ ê¸°íš",
                    "ì¶œíŒë‹¨ì§€ íŠ¹ì„±ì„ í™œìš©í•œ ì°½ì˜ì  í”„ë¡œê·¸ë¨ ê°œë°œ",
                    "ë””ì§€í„¸ ì½˜í…ì¸ ì™€ ì—°ê³„í•œ í•˜ì´ë¸Œë¦¬ë“œ í”„ë¡œê·¸ë¨ ìš´ì˜"
                ],
                "recommendations": [
                    f"{date_label} ì˜ˆìƒ ë°©ë¬¸ì¸êµ¬ {predicted_visits:,.0f}ëª…ì„ ê³ ë ¤í•œ {'í˜¼ì¡ë„ ê´€ë¦¬' if crowd_level > 0.7 else 'í”„ë¡œê·¸ë¨ í™•ëŒ€'} ì „ëµ ìˆ˜ë¦½" if predicted_visits > 0 else "ì£¼ë§ íŠ¹í™” í”„ë¡œê·¸ë¨ í™•ëŒ€ ìš´ì˜",
                    f"{'ì£¼ë§' if is_weekend else 'í‰ì¼'} íŠ¹ì„±ì— ë§ëŠ” {'íŠ¹í™” í”„ë¡œê·¸ë¨' if is_weekend else 'ì§ì¥ì¸ ëŒ€ìƒ'} ê°œë°œ",
                    f"{', '.join([prog['program'] for prog in program_rankings[:3]])} í”„ë¡œê·¸ë¨ ìš°ì„  ìš´ì˜" if program_rankings else "íƒ€ê²Ÿ ê³ ê°ì¸µ ë§ì¶¤ í”„ë¡œê·¸ë¨ ê°œë°œ",
                    f"ì ‘ê·¼ì„± ê°œì„ ì„ ìœ„í•œ {'êµí†µ ì—°ê³„' if activation_scores.get('accessibility', 0) < 60 else 'ì§€ì—­ë³„ ë§ì¶¤í˜•'} í™œì„±í™” ì „ëµ ìˆ˜ë¦½",
                    "ì†Œë¹„í™œë ¥ í–¥ìƒì„ ìœ„í•œ í”„ë¡œê·¸ë¨ ê¸°íš",
                    "ì¶œíŒ ê´€ë ¨ í”„ë¡œê·¸ë¨ í™•ëŒ€",
                    "ë‚ ì§œë³„ ë™ì  í”„ë¡œê·¸ë¨ ìš´ì˜",
                    "ì§€ì—­ë³„ í™œì„±í™” ì§€ìˆ˜ í†µí•© ì „ëµ ìˆ˜ë¦½",
                    "ë””ì§€í„¸ ì½˜í…ì¸  ì—°ê³„ í”„ë¡œê·¸ë¨ ê°œë°œ",
                    "ì¶œíŒì‚¬ í˜‘ì—… í”„ë¡œê·¸ë¨ í™•ëŒ€"
                ],
                "action_plan": [
                    f"1ë‹¨ê³„: {date_label} ì˜ˆìƒ ë°©ë¬¸ì¸êµ¬ ê¸°ë°˜ í”„ë¡œê·¸ë¨ ìš´ì˜ ê³„íš ìˆ˜ë¦½",
                    f"2ë‹¨ê³„: {'ì£¼ë§' if is_weekend else 'í‰ì¼'} íŠ¹ì„±ì— ë§ëŠ” í”„ë¡œê·¸ë¨ ê¸°íš ë° ì‹¤í–‰",
                    "3ë‹¨ê³„: íƒ€ê²Ÿ ê³ ê°ì¸µ ë¶„ì„ ë° ë§ì¶¤ í”„ë¡œê·¸ë¨ ê°œë°œ",
                    "4ë‹¨ê³„: ì§€ì—­ë³„ í™œì„±í™” ì „ëµ ìˆ˜ë¦½ ë° ì‹¤í–‰",
                    "5ë‹¨ê³„: í”„ë¡œê·¸ë¨ ì‹¤í–‰ ë° ëª¨ë‹ˆí„°ë§, íš¨ê³¼ í‰ê°€ ë° ê°œì„ "
                ]
            }
        
        return analysis
        
    except Exception as e:
        print(f"[API] ì¢…í•© ë¶„ì„ ìƒì„± ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        # ê¸°ë³¸ ë¶„ì„ ë°˜í™˜
        return {
            "summary": "ì¶œíŒë‹¨ì§€ í™œì„±í™”ë¥¼ ìœ„í•œ ì¢…í•© ë¶„ì„ì„ ìƒì„±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
            "detailed_analysis": [
                "ë°ì´í„° ë¶„ì„ì„ ì™„ë£Œí•œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            ],
            "strengths": [],
            "weaknesses": [],
            "opportunities": [],
            "recommendations": ["ë°ì´í„° ë¶„ì„ì„ ì™„ë£Œí•œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."],
            "action_plan": []
        }


@app.post("/api/analytics/action-items")
async def get_action_items(request: Dict):
    """LLM ê¸°ë°˜ ë‹¹ì¥ ì‹¤í–‰ ê°€ëŠ¥í•œ í™œì„±í™” ì•¡ì…˜ ì•„ì´í…œ ìƒì„±"""
    try:
        predictions = request.get('predictions', [])
        statistics = request.get('statistics', {})
        model_metrics = request.get('model_metrics', {})
        date = request.get('date', datetime.now().strftime('%Y-%m-%d'))
        
        # í†µê³„ ìš”ì•½ ìƒì„±
        total_visits = statistics.get('total_visits', 0)
        avg_crowd = statistics.get('avg_crowd_level', 0) * 100
        model_accuracy = model_metrics.get('cv_r2_mean') or model_metrics.get('r2', 0)
        model_accuracy = model_accuracy * 100 if model_accuracy <= 1 else model_accuracy
        mae = model_metrics.get('cv_mae_mean') or model_metrics.get('mae', 0)
        
        # ë¬¸í™” ê³µê°„ë³„ ìƒì„¸ ì •ë³´ ì¶”ì¶œ (íë ˆì´ì…˜ ë©”íŠ¸ë¦­ í¬í•¨)
        space_details = []
        for p in predictions[:5]:
            space_name = p.get('space', p.get('spot', 'N/A'))
            crowd_level = p.get('crowd_level', 0) * 100
            optimal_time = p.get('optimal_time', 'N/A')
            predicted_visit = p.get('predicted_visit', 0)
            
            # íë ˆì´ì…˜ ë©”íŠ¸ë¦­ ì¶”ì¶œ
            curation_metrics = p.get('curation_metrics', {})
            recommended_programs = p.get('recommended_programs', [])
            
            # íë ˆì´ì…˜ ë©”íŠ¸ë¦­ ìš”ì•½
            curation_summary = []
            if curation_metrics:
                for program_type, metrics in curation_metrics.items():
                    if isinstance(metrics, dict):
                        recommendation_score = metrics.get('recommendation_score', 0)
                        time_suitability = metrics.get('time_suitability', 0)
                        overall_score = metrics.get('overall_score', 0)
                        if recommendation_score > 0.5 or time_suitability > 70:
                            curation_summary.append(f"  - {program_type}: ì¶”ì²œë„ {recommendation_score:.2f}, ì‹œê°„ ì í•©ë„ {time_suitability:.0f}%, ì¢…í•© ì ìˆ˜ {overall_score:.1f}")
            
            space_detail = f"""
- **{space_name}**:
  - ì˜ˆì¸¡ ë°©ë¬¸ ìˆ˜: {predicted_visit:,}ëª…
  - í˜¼ì¡ë„: {crowd_level:.1f}%
  - ìµœì  ì‹œê°„: {optimal_time}
  - ì¶”ì²œ í”„ë¡œê·¸ë¨: {', '.join(recommended_programs) if recommended_programs else 'ì—†ìŒ'}
"""
            if curation_summary:
                space_detail += "  - íë ˆì´ì…˜ ë©”íŠ¸ë¦­:\n" + "\n".join(curation_summary[:3])  # ìµœëŒ€ 3ê°œë§Œ í‘œì‹œ
            
            space_details.append(space_detail)
        
        # ë‚ ì§œ ë ˆì´ë¸” ìƒì„±
        date_obj = datetime.strptime(date, '%Y-%m-%d')
        date_label = date_obj.strftime('%Yë…„ %mì›” %dì¼')
        weekday_name = ['ì›”ìš”ì¼', 'í™”ìš”ì¼', 'ìˆ˜ìš”ì¼', 'ëª©ìš”ì¼', 'ê¸ˆìš”ì¼', 'í† ìš”ì¼', 'ì¼ìš”ì¼'][date_obj.weekday()]
        month = date_obj.month
        day = date_obj.day
        
        # ì£¼ë§/í‰ì¼ íŒ¨í„´ ë¶„ì„
        is_weekend = date_obj.weekday() >= 5
        
        # ê³µíœ´ì¼ ê°ì§€ (2024-2025 ì£¼ìš” ê³µíœ´ì¼)
        public_holidays = {
            (1, 1): "ì‹ ì •",
            (3, 1): "ì‚¼ì¼ì ˆ",
            (5, 5): "ì–´ë¦°ì´ë‚ ",
            (6, 6): "í˜„ì¶©ì¼",
            (8, 15): "ê´‘ë³µì ˆ",
            (10, 3): "ê°œì²œì ˆ",
            (10, 9): "í•œê¸€ë‚ ",
            (12, 25): "í¬ë¦¬ìŠ¤ë§ˆìŠ¤",
        }
        
        # ìŒë ¥ ê³µíœ´ì¼ ëŒ€ëµì  ê³„ì‚° (2024-2025)
        lunar_holidays_approx = {
            (1, 28): "ì„¤ë‚  ì—°íœ´",
            (1, 29): "ì„¤ë‚  ì—°íœ´",
            (1, 30): "ì„¤ë‚  ì—°íœ´",
            (4, 9): "ë¶€ì²˜ë‹˜ì˜¤ì‹ ë‚ ",
            (9, 15): "ì¶”ì„ ì—°íœ´",
            (9, 16): "ì¶”ì„ ì—°íœ´",
            (9, 17): "ì¶”ì„ ì—°íœ´",
        }
        
        is_public_holiday = False
        holiday_name = ""
        if (month, day) in public_holidays:
            is_public_holiday = True
            holiday_name = public_holidays[(month, day)]
        elif (month, day) in lunar_holidays_approx:
            is_public_holiday = True
            holiday_name = lunar_holidays_approx[(month, day)]
        
        # ê³„ì ˆ íŒë‹¨
        if month in [12, 1, 2]:
            season = "ê²¨ìš¸"
            season_context = "ê²¨ìš¸ì² ì€ ì‹¤ë‚´ í”„ë¡œê·¸ë¨ì´ íš¨ê³¼ì ì´ë©°, ë”°ëœ»í•œ ê³µê°„ì—ì„œì˜ ë…ì„œë‚˜ ë¬¸í™” í™œë™ì´ ì„ í˜¸ë©ë‹ˆë‹¤."
        elif month in [3, 4, 5]:
            season = "ë´„"
            season_context = "ë´„ì² ì€ ì•¼ì™¸ í™œë™ì´ ì¦ê°€í•˜ë©°, ê½ƒë†€ì´ì™€ ì—°ê³„í•œ í”„ë¡œê·¸ë¨ì´ë‚˜ ì•¼ì™¸ ë…ì„œ ê³µê°„ í™œìš©ì´ ì¢‹ìŠµë‹ˆë‹¤."
        elif month in [6, 7, 8]:
            season = "ì—¬ë¦„"
            season_context = "ì—¬ë¦„ì² ì€ íœ´ê°€ ì‹œì¦Œìœ¼ë¡œ ê°€ì¡± ë‹¨ìœ„ ë°©ë¬¸ì´ ë§ìœ¼ë©°, ì‹¤ë‚´ í”„ë¡œê·¸ë¨ê³¼ ì‹œì›í•œ ê³µê°„ í™œìš©ì´ ì¤‘ìš”í•©ë‹ˆë‹¤."
        else:
            season = "ê°€ì„"
            season_context = "ê°€ì„ì² ì€ ë¬¸í™” í™œë™ì´ í™œë°œí•˜ë©°, ë…ì„œì˜ ê³„ì ˆë¡œ ì±… ê´€ë ¨ í”„ë¡œê·¸ë¨ì´ ë§¤ìš° íš¨ê³¼ì ì…ë‹ˆë‹¤."
        
        # ë‚ ì§œ ìœ í˜• ê²°ì •
        date_type = ""
        if is_public_holiday:
            date_type = f"ê³µíœ´ì¼ ({holiday_name})"
        elif is_weekend:
            date_type = "ì£¼ë§"
        else:
            date_type = "í‰ì¼"
        
        # í†µê³„ì—ì„œ ì¶”ê°€ ì •ë³´ ì¶”ì¶œ
        active_spaces = statistics.get('active_spaces', 0)
        avg_daily_visits = statistics.get('avg_daily_visits', 0)
        
        # ë‚ ì§œë³„ ì»¨í…ìŠ¤íŠ¸ ìƒì„± (ì£¼ë§/ê³µíœ´ì¼/í‰ì¼ + ê³„ì ˆ)
        date_context = f"""
**ë‚ ì§œ íŠ¹ì„± ë¶„ì„**:
- ë‚ ì§œ: {date_label} ({weekday_name})
- ë‚ ì§œ ìœ í˜•: {date_type}
- ê³„ì ˆ: {season}
{season_context}

"""
        
        if is_public_holiday:
            date_context += f"""
**ê³µíœ´ì¼ íŒ¨í„´ ë¶„ì„** ({holiday_name}):
- ê³µíœ´ì¼ì€ í‰ì¼ë³´ë‹¤ ë°©ë¬¸ê°ì´ 1.5-2ë°° ë§ìŠµë‹ˆë‹¤
- ê°€ì¡± ë‹¨ìœ„ ë°©ë¬¸ì´ ë§ì•„ ê°€ì¡± í”„ë¡œê·¸ë¨ì´ ë§¤ìš° íš¨ê³¼ì ì…ë‹ˆë‹¤
- íŠ¹ë³„ ì´ë²¤íŠ¸ë‚˜ ê¸°ë… í”„ë¡œê·¸ë¨ ìš´ì˜ì´ ì¢‹ì€ ê¸°íšŒì…ë‹ˆë‹¤
- ê³µíœ´ì¼ íŠ¹ì„±ì— ë§ëŠ” í…Œë§ˆ í”„ë¡œê·¸ë¨ ê¸°íšì´ ì¤‘ìš”í•©ë‹ˆë‹¤
- ì—°íœ´ì˜ ê²½ìš° ì²«ë‚ ê³¼ ë§ˆì§€ë§‰ë‚  ë°©ë¬¸ íŒ¨í„´ì´ ë‹¤ë¦…ë‹ˆë‹¤
"""
        elif is_weekend:
            date_context += f"""
**ì£¼ë§ íŒ¨í„´ ë¶„ì„**:
- ì£¼ë§ì€ í‰ì¼ë³´ë‹¤ ë°©ë¬¸ê°ì´ 1.4-1.5ë°° ë§ìŠµë‹ˆë‹¤
- ì£¼ë§ ë°©ë¬¸ê°ì€ ê°€ì¡± ë‹¨ìœ„, ì—¬ê°€ í™œë™ ì¤‘ì‹¬ìœ¼ë¡œ ë¬¸í™” í”„ë¡œê·¸ë¨ ì°¸ì—¬ìœ¨ì´ ë†’ìŠµë‹ˆë‹¤
- ì£¼ë§ íŠ¹ë³„ í”„ë¡œê·¸ë¨ì´ë‚˜ ì´ë²¤íŠ¸ ìš´ì˜ì´ ë§¤ìš° íš¨ê³¼ì ì…ë‹ˆë‹¤
- í† ìš”ì¼ì€ ê°€ì¡± ë‹¨ìœ„, ì¼ìš”ì¼ì€ ê°œì¸ ì·¨ë¯¸ í™œë™ ì¤‘ì‹¬ íŒ¨í„´ì´ ìˆìŠµë‹ˆë‹¤
- ì£¼ë§ ì˜¤í›„ ì‹œê°„ëŒ€(14:00-18:00) í”„ë¡œê·¸ë¨ì´ ê°€ì¥ íš¨ê³¼ì ì…ë‹ˆë‹¤
"""
        else:
            date_context += f"""
**í‰ì¼ íŒ¨í„´ ë¶„ì„**:
- í‰ì¼ ë°©ë¬¸ê°ì€ ì—…ë¬´ í›„ ë°©ë¬¸ ë˜ëŠ” ê°œì¸ ì·¨ë¯¸ í™œë™ ì¤‘ì‹¬ì…ë‹ˆë‹¤
- ì €ë… ì‹œê°„ëŒ€(18:00-20:00) í”„ë¡œê·¸ë¨ ìš´ì˜ì´ íš¨ê³¼ì ì…ë‹ˆë‹¤
- í‰ì¼ì€ ì£¼ë§ë³´ë‹¤ ë°©ë¬¸ê°ì´ ìƒëŒ€ì ìœ¼ë¡œ ì ì§€ë§Œ, ì¶©ì„±ë„ ë†’ì€ ë°©ë¬¸ê°ì´ ë§ìŠµë‹ˆë‹¤
- í‰ì¼ ì˜¤í›„(15:00-17:00) ì‹œê°„ëŒ€ë„ ì€í‡´ì¸µì´ë‚˜ ììœ  ì‹œê°„ì´ ìˆëŠ” ë°©ë¬¸ê°ì´ ë§ìŠµë‹ˆë‹¤
- í‰ì¼ íŠ¹í™” í”„ë¡œê·¸ë¨(ì˜ˆ: í‰ì¼ í• ì¸, í‰ì¼ íŠ¹ë³„ ì´ë²¤íŠ¸)ìœ¼ë¡œ ë°©ë¬¸ ìœ ë„ ê°€ëŠ¥í•©ë‹ˆë‹¤
"""
        
        # ì•¡ì…˜ ì•„ì´í…œ ìƒì„± í”„ë¡¬í”„íŠ¸ (ë‹¤ì±„ë¡­ê³  ë‹¤ì–‘í•˜ê²Œ)
        prompt = f"""ë‹¹ì‹ ì€ íŒŒì£¼ì‹œ ì¶œíŒë‹¨ì§€ í™œì„±í™”ë¥¼ ìœ„í•œ ì°½ì˜ì ì¸ AI ì „ëµ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
ë¶„ì„ëœ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ **ë‹¤ì–‘í•˜ê³  ì°½ì˜ì ì´ë©° í’ë¶€í•œ** í™œì„±í™” ì•¡ì…˜ ì•„ì´í…œì„ ì œì‹œí•´ì£¼ì„¸ìš”.

**ë¶„ì„ ê¸°ì¤€ ë‚ ì§œ**: {date_label} ({date}, {weekday_name})
**ë‚ ì§œ ìœ í˜•**: {date_type}
**ê³„ì ˆ**: {season}
{date_context}

**í˜„ì¬ ìƒí™©**:
- ì „ì²´ ì˜ˆìƒ ë°©ë¬¸ì: {total_visits:,}ëª…
- í‰ê·  ì¼ì¼ ë°©ë¬¸ì: {avg_daily_visits:.0f}ëª…
- í‰ê·  í˜¼ì¡ë„: {avg_crowd:.1f}% ({'ë†’ì€' if avg_crowd > 60 else 'ë³´í†µ' if avg_crowd > 40 else 'ë‚®ì€'} ìˆ˜ì¤€)
- í™œì„± ë¬¸í™” ê³µê°„ ìˆ˜: {active_spaces}ê°œ

**ë¬¸í™” ê³µê°„ë³„ ì˜ˆì¸¡ ìƒì„¸ (íë ˆì´ì…˜ ë©”íŠ¸ë¦­ í¬í•¨)**:
{''.join(space_details)}

**ì•¡ì…˜ ì•„ì´í…œ ì¹´í…Œê³ ë¦¬ (ë‹¤ì–‘í•˜ê²Œ í™œìš©í•˜ì„¸ìš” - ìµœì†Œ 6ê°œ ì´ìƒ ì¹´í…Œê³ ë¦¬ ì‚¬ìš©)**:
1. **í”„ë¡œê·¸ë¨ ê¸°íš**: íŠ¹ë³„ ì´ë²¤íŠ¸, ì›Œí¬ìˆ, ê°•ì—°, ì²´í—˜ í”„ë¡œê·¸ë¨, ì‹œì¦Œ í…Œë§ˆ í”„ë¡œê·¸ë¨
2. **ë§ˆì¼€íŒ…/í™ë³´**: SNS ìº í˜ì¸, í˜‘ì—… ì´ë²¤íŠ¸, ì¸í”Œë£¨ì–¸ì„œ ì´ˆì²­, ì§€ì—­ ë§¤ì²´ í™œìš©, ë°”ì´ëŸ´ ë§ˆì¼€íŒ…
3. **ìš´ì˜/ì„œë¹„ìŠ¤**: ì¸ë ¥ ë°°ì¹˜, ëŒ€ê¸° ê³µê°„, í¸ì˜ ì‹œì„¤, ì•ˆë‚´ ì„œë¹„ìŠ¤, ê³ ê° ê²½í—˜ ê°œì„ 
4. **íŒŒíŠ¸ë„ˆì‹­/í˜‘ì—…**: ì§€ì—­ ì—…ì²´ í˜‘ì—…, ì‘ê°€/ì•„í‹°ìŠ¤íŠ¸ ì´ˆì²­, ì¶œíŒì‚¬ ì—°ê³„, ë¬¸í™” ê¸°ê´€ í˜‘ì—…
5. **ê³µê°„ í™œìš©**: ì•¼ì™¸ ê³µê°„ í™œìš©, íŒì—… ìŠ¤í† ì–´, ì „ì‹œ, ë¼ì´ë¸Œ ê³µì—°, ê³„ì ˆë³„ ê³µê°„ ì—°ì¶œ
6. **ì½˜í…ì¸  ì œì‘**: ë…ì„œ ëª¨ì„, ì¶œíŒ í† í¬, ì‘ê°€ ì‚¬ì¸íšŒ, ë¶ ì»¤ë²„ ì•„íŠ¸ ì „ì‹œ, ì¶œíŒ ë¬¸í™” ì½˜í…ì¸ 
7. **ë””ì§€í„¸/ì˜¨ë¼ì¸**: ì˜¨ë¼ì¸ ì´ë²¤íŠ¸, ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë°, ê°€ìƒ íˆ¬ì–´, ì˜ˆì•½ ì‹œìŠ¤í…œ, ë””ì§€í„¸ ì•„ì¹´ì´ë¸Œ
8. **ì»¤ë®¤ë‹ˆí‹°**: ì§€ì—­ ì£¼ë¯¼ ì—°ê³„, ìì›ë´‰ì‚¬, í´ëŸ½ í™œë™, ë„¤íŠ¸ì›Œí‚¹, ë…ì„œ ëª¨ì„
9. **ì‹œì¦Œ/í…Œë§ˆ**: {season} í…Œë§ˆ í”„ë¡œê·¸ë¨, ë‚ ì§œë³„ íŠ¹ë³„ í…Œë§ˆ, ê³µíœ´ì¼ ê¸°ë… í”„ë¡œê·¸ë¨
10. **í˜¼ì¡ë„ ê´€ë¦¬**: ë°©ë¬¸ê° ë¶„ì‚° ì „ëµ, ì‹œê°„ëŒ€ë³„ í”„ë¡œê·¸ë¨, ì˜ˆì•½ ì‹œìŠ¤í…œ, ëŒ€ì²´ ê³µê°„ í™œìš©
11. **íƒ€ê²Ÿ ê³ ê°**: ê°€ì¡±/ê°œì¸/ì»¤í”Œ/ë‹¨ì²´ë³„ ë§ì¶¤ í”„ë¡œê·¸ë¨, ì—°ë ¹ëŒ€ë³„ íŠ¹í™” ì´ë²¤íŠ¸
12. **ë¬¸í™” ìœµí•©**: ìŒì•…+ì±…, ë¯¸ìˆ +ì±…, ìš”ë¦¬+ì±…, ì˜í™”+ì±… ë“± ìœµí•© í”„ë¡œê·¸ë¨

**ìš”êµ¬ì‚¬í•­**:
1. **ë‹¤ì–‘ì„±**: ìœ„ ì¹´í…Œê³ ë¦¬ ì¤‘ ìµœì†Œ 6ê°œ ì´ìƒì˜ ì„œë¡œ ë‹¤ë¥¸ ì¹´í…Œê³ ë¦¬ë¥¼ í™œìš©í•˜ì„¸ìš” (10-12ê°œ ì•¡ì…˜ ì•„ì´í…œ ìƒì„±)
2. **ì°½ì˜ì„±**: ë»”í•œ ì œì•ˆì´ ì•„ë‹Œ, ë…íŠ¹í•˜ê³  ì°¸ì‹ í•˜ë©° ì‹¤ìš©ì ì¸ ì•„ì´ë””ì–´ë¥¼ ì œì‹œí•˜ì„¸ìš”
3. **êµ¬ì²´ì„±**: ì¶”ìƒì ì¸ ì œì•ˆì´ ì•„ë‹Œ, êµ¬ì²´ì ì¸ ì‹¤í–‰ ë°©ë²•, ëŒ€ìƒ, ì‹œê°„, ì¥ì†Œë¥¼ ëª…ì‹œí•˜ì„¸ìš”
4. **ì‹¤í–‰ ê°€ëŠ¥ì„±**: ë‹¹ì¥ ì‹¤í–‰ ê°€ëŠ¥í•œ (ì˜¤ëŠ˜~ì´ë²ˆ ì£¼) ì•¡ì…˜ ìœ„ì£¼ë¡œ, ì¤‘ì¥ê¸°(ì´ë²ˆ ë‹¬ ì´ìƒ)ëŠ” ìµœì†Œí™”
5. **ë‚ ì§œ íŠ¹ì„± ë°˜ì˜**: {date_type} íŠ¹ì„±ì„ ë°˜ë“œì‹œ ë°˜ì˜í•˜ì„¸ìš”
   - ê³µíœ´ì¼: ê°€ì¡± ë‹¨ìœ„ í”„ë¡œê·¸ë¨, íŠ¹ë³„ ì´ë²¤íŠ¸, ê¸°ë… í”„ë¡œê·¸ë¨
   - ì£¼ë§: ê°€ì¡±/ì—¬ê°€ í”„ë¡œê·¸ë¨, ì˜¤í›„ ì§‘ì¤‘ í”„ë¡œê·¸ë¨, íŠ¹ë³„ ì´ë²¤íŠ¸
   - í‰ì¼: ì €ë… í”„ë¡œê·¸ë¨, ê°œì¸ ì·¨ë¯¸ í”„ë¡œê·¸ë¨, í‰ì¼ íŠ¹í™” ì´ë²¤íŠ¸
6. **ê³„ì ˆ íŠ¹ì„± ë°˜ì˜**: {season} ê³„ì ˆ íŠ¹ì„±ì„ ë°˜ì˜í•˜ì„¸ìš” ({season_context})
7. **í˜¼ì¡ë„ ê³ ë ¤**: í˜¼ì¡ë„ ìˆ˜ì¤€({avg_crowd:.1f}%)ì— ë”°ë¼ ë‹¤ë¥¸ ì „ëµ ì œì‹œ
   - ë†’ì€ í˜¼ì¡ë„(60% ì´ìƒ): ë¶„ì‚° ì „ëµ, ì˜ˆì•½ ì‹œìŠ¤í…œ, ëŒ€ì²´ ê³µê°„ í™œìš©
   - ë³´í†µ í˜¼ì¡ë„(40-60%): ì§‘ì¤‘ ìœ ë„, íŠ¹ë³„ í”„ë¡œê·¸ë¨ìœ¼ë¡œ ë°©ë¬¸ ì¦ê°€
   - ë‚®ì€ í˜¼ì¡ë„(40% ë¯¸ë§Œ): ì ê·¹ì  ë§ˆì¼€íŒ…, íŠ¹ë³„ ì´ë²¤íŠ¸ë¡œ ë°©ë¬¸ ìœ ë„
8. **ê³µê°„ë³„ íŠ¹ì„±**: ê° ë¬¸í™” ê³µê°„ì˜ íŠ¹ì„±ì— ë§ëŠ” ë§ì¶¤í˜• ì•¡ì…˜ ì œì‹œ
9. **íƒ€ê²Ÿ ê³ ê° ë‹¤ì–‘í™”**: ê°€ì¡±, ê°œì¸, ì»¤í”Œ, ë‹¨ì²´, ì—°ë ¹ëŒ€ë³„ ë‹¤ì–‘í•œ íƒ€ê²Ÿ ê³ ë ¤
10. **í’ë¶€í•œ ì•„ì´ë””ì–´**: ê° ì•¡ì…˜ ì•„ì´í…œì´ ì„œë¡œ ë‹¤ë¥¸ ì ‘ê·¼ ë°©ì‹ê³¼ íš¨ê³¼ë¥¼ ê°€ì ¸ì•¼ í•©ë‹ˆë‹¤

**ê° ì•¡ì…˜ ì•„ì´í…œ í˜•ì‹**:
- **ì œëª©**: ë…íŠ¹í•˜ê³  ì„íŒ©íŠ¸ ìˆëŠ” ì´ë¦„ (15ì ì´ë‚´, ğŸ¨ğŸ“šğŸ­ğŸŒ¿ ë“±ì˜ ì´ëª¨ì§€ ê°€ëŠ¥)
- **ì„¤ëª…**: êµ¬ì²´ì ì¸ ì‹¤í–‰ ë°©ë²•, ëŒ€ìƒ, ì‹œê°„, ì¥ì†Œ, ê¸°ëŒ€ íš¨ê³¼ë¥¼ ìƒì„¸íˆ ì„¤ëª… (80-120ì)
- **ìš°ì„ ìˆœìœ„**: High/Medium/Low (ì‹¤í–‰ ì‹œê¸‰ì„±ê³¼ íš¨ê³¼ ê¸°ë°˜)
- **ë‹´ë‹¹ë¶€ì„œ**: ë‹¤ì–‘í•œ ë¶€ì„œ ì œì‹œ (í”„ë¡œê·¸ë¨ ê¸°íšíŒ€, ë§ˆì¼€íŒ…íŒ€, ìš´ì˜íŒ€, íë ˆì´ì…˜íŒ€, íŒŒíŠ¸ë„ˆì‹­íŒ€, ë””ì§€í„¸íŒ€, ì»¤ë®¤ë‹ˆí‹°íŒ€ ë“±)
- **ì‹¤í–‰ ì‹œê¸°**: ì˜¤ëŠ˜/ë‚´ì¼/ì´ë²ˆ ì£¼/ì´ë²ˆ ë‹¬
- **ì•„ì´ì½˜**: ë‹¤ì–‘í•œ ì´ëª¨ì§€ ì‚¬ìš© (ğŸ¯ğŸ¨ğŸ“¢ğŸ‘¥ğŸ“šğŸ­ğŸŒ¿âœ¨ğŸ’¡ğŸªğŸµğŸ–¼ï¸ğŸ“¸ğŸ¬ğŸ”” ë“±)
- **ì˜í–¥ë ¥**: ë†’ìŒ/ì¤‘ê°„/ë‚®ìŒ (ê¸°ëŒ€ íš¨ê³¼)

**ìš°ì„ ìˆœìœ„ ê¸°ì¤€**:
- **High**: ì¦‰ì‹œ ì‹¤í–‰ ì‹œ í° íš¨ê³¼ (ì˜ˆ: ì˜¤ëŠ˜ ë‹¹ì¥ ì‹¤í–‰ ê°€ëŠ¥í•œ ì´ë²¤íŠ¸, ê¸´ê¸‰ ë§ˆì¼€íŒ…)
- **Medium**: ë‹¨ê¸°ê°„ ë‚´ ì‹¤í–‰ ê°€ëŠ¥í•œ ì „ëµ (ì˜ˆ: ì´ë²ˆ ì£¼ í”„ë¡œê·¸ë¨ ê¸°íš, í˜‘ì—… ì¤€ë¹„)
- **Low**: ì¤‘ì¥ê¸° ì „ëµ (ì˜ˆ: ì‹œì„¤ ê°œì„ , ì¥ê¸° í”„ë¡œê·¸ë¨ ê³„íš)

**ì‘ë‹µ í˜•ì‹** (JSON):
{{
  "action_items": [
    {{
      "id": 1,
      "title": "ì°½ì˜ì ì´ê³  ë…íŠ¹í•œ ì•¡ì…˜ ì œëª©",
      "description": "êµ¬ì²´ì ì¸ ì‹¤í–‰ ë°©ë²•, ëŒ€ìƒ, ì‹œê°„, ì¥ì†Œ, ê¸°ëŒ€ íš¨ê³¼ë¥¼ ìƒì„¸íˆ ì„¤ëª… (80-120ì)",
      "priority": "High",
      "department": "ë‹¤ì–‘í•œ ë¶€ì„œëª…",
      "timeline": "ì˜¤ëŠ˜",
      "icon": "ğŸ¨",
      "impact": "ë†’ìŒ"
    }},
    ...
  ]
}}

**ì•¡ì…˜ ì•„ì´í…œ ìƒì„± ì˜ˆì‹œ (ì°¸ê³ ìš© - ë‚ ì§œë³„ íŠ¹ì„± ë°˜ì˜)**:
- "{date_type} í•œì • ë¶ ì»¤í”¼ ì½œë¼ë³´": í—¤ì´ë¦¬ì˜ˆìˆ ë§ˆì„ ì¹´í˜ì™€ ì—°ê³„í•œ ë…ì„œ ê³µê°„ íŒì—… ìš´ì˜ ({season} í…Œë§ˆ ìŒë£Œ ì œê³µ)
- "ì‘ê°€ì™€ì˜ ë¼ì´ë¸Œ í† í¬ì‡¼": ì˜ˆìƒ ë°©ë¬¸ì ìˆ˜ê°€ ë§ì€ ì‹œê°„ëŒ€ì— SNS ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë° (ì‹¤ì‹œê°„ Q&A)
- "ì¶œíŒë‹¨ì§€ ë‚˜ì´íŠ¸ íˆ¬ì–´": ì €ë… ì‹œê°„ëŒ€ íŠ¹ë³„ í”„ë¡œê·¸ë¨ìœ¼ë¡œ í‰ì¼ ë°©ë¬¸ì ìœ ë„ (ì¡°ëª… ì—°ì¶œ í¬í•¨)
- "ì§€ì—­ ì¸í”Œë£¨ì–¸ì„œ ì´ˆì²­ ì´ë²¤íŠ¸": íŒŒì£¼ ì¶œíŒ ë¬¸í™”ë¥¼ ì†Œê°œí•˜ëŠ” ì½˜í…ì¸  ì œì‘ í˜‘ì—… (SNS í™ë³´ ì—°ê³„)
- "íŒì—… ë¶ìŠ¤í† ì–´ ìš´ì˜": í˜¼ì¡ë„ê°€ ë‚®ì€ ê³µê°„ì— ì„ì‹œ ì„œì  ìš´ì˜ìœ¼ë¡œ ë°©ë¬¸ì ë¶„ì‚° ({season} ì¶”ì²œ ë„ì„œ ì½”ë„ˆ)
- "ë””ì§€í„¸ ë¶ì»¤ë²„ ì „ì‹œ": ì˜¨ë¼ì¸ê³¼ ì˜¤í”„ë¼ì¸ ì—°ê³„ ì „ì‹œë¡œ íŠ¸ë˜í”½ ìœ ë„ (AR ì²´í—˜ í¬í•¨)
- "{holiday_name if is_public_holiday else season} íŠ¹ë³„ í”„ë¡œê·¸ë¨": ë‚ ì§œ íŠ¹ì„±ì— ë§ëŠ” í…Œë§ˆ í”„ë¡œê·¸ë¨ ìš´ì˜
- "ê°€ì¡± ë‹¨ìœ„ ë…ì„œ ì²´í—˜": {date_type}ì— ë§ëŠ” ê°€ì¡± í”„ë¡œê·¸ë¨ (ë¶€ëª¨-ìë…€ ë…ì„œ í™œë™)
- "ì €ë… ì‹œê°„ëŒ€ ë¬¸í™” í”„ë¡œê·¸ë¨": í‰ì¼ ë°©ë¬¸ê°ì„ ìœ„í•œ 18:00-20:00 íŠ¹ë³„ í”„ë¡œê·¸ë¨
- "ì•¼ì™¸ ë…ì„œ ê³µê°„ ì—°ì¶œ": {season} ê³„ì ˆì— ë§ëŠ” ì•¼ì™¸ ê³µê°„ í™œìš© í”„ë¡œê·¸ë¨

**ì¤‘ìš”**:
- ìµœì†Œ 10-12ê°œì˜ ë‹¤ì–‘í•œ ì•¡ì…˜ ì•„ì´í…œì„ ìƒì„±í•˜ì„¸ìš” (ë‹¤ì–‘ì„±ê³¼ í’ë¶€í•¨ì„ ìœ„í•´)
- ê° ì•¡ì…˜ì€ ì„œë¡œ ë‹¤ë¥¸ ì¹´í…Œê³ ë¦¬ì™€ ì ‘ê·¼ ë°©ì‹ì´ì–´ì•¼ í•©ë‹ˆë‹¤
- {date_type} íŠ¹ì„±, {season} ê³„ì ˆ íŠ¹ì„±, ì˜ˆìƒ ë°©ë¬¸ì ìˆ˜, í˜¼ì¡ë„ë¥¼ ì¢…í•©ì ìœ¼ë¡œ ê³ ë ¤í•˜ì„¸ìš”
- ë»”í•œ ì œì•ˆë³´ë‹¤ëŠ” ì°½ì˜ì ì´ê³  ë…íŠ¹í•˜ë©° ì‹¤ìš©ì ì¸ ì•„ì´ë””ì–´ë¥¼ ìš°ì„ í•˜ì„¸ìš”
- ë‚ ì§œë³„ íŠ¹ì„±({date_type}, {season})ì„ ë°˜ë“œì‹œ ë°˜ì˜í•˜ì—¬ ë§ì¶¤í˜• ì•¡ì…˜ì„ ì œì‹œí•˜ì„¸ìš”
- ê³µíœ´ì¼ì¸ ê²½ìš° ê°€ì¡± ë‹¨ìœ„ í”„ë¡œê·¸ë¨ê³¼ íŠ¹ë³„ ì´ë²¤íŠ¸ë¥¼ í¬í•¨í•˜ì„¸ìš”
- ì£¼ë§ì¸ ê²½ìš° ì˜¤í›„ ì‹œê°„ëŒ€ ì§‘ì¤‘ í”„ë¡œê·¸ë¨ê³¼ ê°€ì¡±/ì—¬ê°€ í”„ë¡œê·¸ë¨ì„ í¬í•¨í•˜ì„¸ìš”
- í‰ì¼ì¸ ê²½ìš° ì €ë… ì‹œê°„ëŒ€ í”„ë¡œê·¸ë¨ê³¼ ê°œì¸ ì·¨ë¯¸ í”„ë¡œê·¸ë¨ì„ í¬í•¨í•˜ì„¸ìš”
- ê° ì•¡ì…˜ ì•„ì´í…œì˜ ì„¤ëª…ì€ êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•˜ë„ë¡ ìƒì„¸íˆ ì‘ì„±í•˜ì„¸ìš” (60-100ì)

ì‘ë‹µì€ ë°˜ë“œì‹œ ìœ íš¨í•œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì œê³µí•´ì£¼ì„¸ìš”.
"""
        
        # LLM í˜¸ì¶œ
        print(f"[API] ì•¡ì…˜ ì•„ì´í…œ ìƒì„± - LLM í˜¸ì¶œ ì‹œì‘ (ë‚ ì§œ: {date}, {date_type}, {season})")
        print(f"[API] í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(prompt)} ë¬¸ì")
        
        if content_generator is None:
            print(f"[API] ê²½ê³ : content_generatorê°€ Noneì…ë‹ˆë‹¤. ê¸°ë³¸ê°’ ë°˜í™˜")
            raise HTTPException(status_code=503, detail="LLM ì„œë¹„ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        response = content_generator.analyze_data(prompt)
        
        print(f"[API] LLM ì‘ë‹µ íƒ€ì…: {type(response)}")
        if isinstance(response, dict):
            print(f"[API] LLM ì‘ë‹µ í‚¤: {list(response.keys())}")
            if 'action_items' in response:
                action_items_list = response.get('action_items', [])
                action_items_count = len(action_items_list)
                print(f"[API] LLM ìƒì„± ì•¡ì…˜ ì•„ì´í…œ {action_items_count}ê°œ ë°˜í™˜")
                if action_items_count > 0:
                    print(f"[API] ì²« ë²ˆì§¸ ì•¡ì…˜ ì•„ì´í…œ: {action_items_list[0]}")
                    return response
                else:
                    print(f"[API] ê²½ê³ : action_items ë°°ì—´ì´ ë¹„ì–´ìˆìŒ")
            else:
                # action_items í‚¤ê°€ ì—†ëŠ” ê²½ìš°, ì‘ë‹µì„ ë³€í™˜ ì‹œë„
                print(f"[API] LLM ì‘ë‹µì— 'action_items' í‚¤ê°€ ì—†ìŒ. ë‹¤ë¥¸ í‚¤ ê²€ìƒ‰ ì¤‘...")
                print(f"[API] LLM ì‘ë‹µ ì „ì²´: {json.dumps(response, ensure_ascii=False, indent=2)[:500]}")
                action_items = []
                if 'recommendations' in response:
                    for idx, rec in enumerate(response['recommendations'][:7], 1):
                        action_items.append({
                            "id": idx,
                            "title": rec[:30] if len(rec) > 30 else rec,
                            "description": rec,
                            "priority": "Medium" if idx <= 3 else "Low",
                            "department": "í”„ë¡œê·¸ë¨ ê¸°íšíŒ€",
                            "timeline": "ì´ë²ˆ ì£¼",
                            "icon": "ğŸ¯",
                            "impact": "ì¤‘ê°„"
                        })
                
                if not action_items:
                    # ê¸°ë³¸ ì•¡ì…˜ ì•„ì´í…œ ìƒì„±
                    print(f"[API] LLM ì‘ë‹µì„ íŒŒì‹±í•  ìˆ˜ ì—†ì–´ ê¸°ë³¸ ì•¡ì…˜ ì•„ì´í…œ ìƒì„±")
                    action_items = [
                        {
                            "id": 1,
                            "title": "ì£¼ë§ í”„ë¡œê·¸ë¨ í™•ëŒ€",
                            "description": f"í˜¼ì¡ë„ê°€ ë†’ì€ ì‹œê°„ëŒ€(15:00-17:00)ì— íŠ¹ë³„ í”„ë¡œê·¸ë¨ ìš´ì˜ìœ¼ë¡œ ë°©ë¬¸ì ë§Œì¡±ë„ í–¥ìƒ",
                            "priority": "High",
                            "department": "í”„ë¡œê·¸ë¨ ê¸°íšíŒ€",
                            "timeline": "ì´ë²ˆ ì£¼",
                            "icon": "ğŸ¨",
                            "impact": "ë†’ìŒ"
                        },
                        {
                            "id": 2,
                            "title": "ì˜¤ëŠ˜ ë°©ë¬¸ í˜œíƒ ë§ˆì¼€íŒ…",
                            "description": f"ì˜ˆìƒ ë°©ë¬¸ì {total_visits:,}ëª…ì„ ìœ„í•œ ë‹¹ì¼ íŠ¹ê°€ ì´ë²¤íŠ¸ ê³µì§€",
                            "priority": "High",
                            "department": "ë§ˆì¼€íŒ…íŒ€",
                            "timeline": "ì˜¤ëŠ˜",
                            "icon": "ğŸ“¢",
                            "impact": "ë†’ìŒ"
                        },
                        {
                            "id": 3,
                            "title": "í˜¼ì¡ë„ ê´€ë¦¬ ê°•í™”",
                            "description": "ì˜ˆì¸¡ëœ í˜¼ì¡ë„ ë†’ì€ ê³µê°„ì— ì¶”ê°€ ì§ì› ë°°ì¹˜ ë° ëŒ€ê¸° ê³µê°„ í™•ë³´",
                            "priority": "Medium",
                            "department": "ìš´ì˜íŒ€",
                            "timeline": "ì˜¤ëŠ˜",
                            "icon": "ğŸ‘¥",
                            "impact": "ì¤‘ê°„"
                        }
                    ]
                
                return {"action_items": action_items}
        else:
            # ë¬¸ìì—´ ì‘ë‹µì¸ ê²½ìš° ê¸°ë³¸ê°’ ë°˜í™˜
            print(f"[API] LLM ì‘ë‹µì´ ë¬¸ìì—´ ë˜ëŠ” ì˜ˆìƒì¹˜ ëª»í•œ íƒ€ì…: {type(response)}")
            print(f"[API] LLM ì‘ë‹µ ë‚´ìš© (ì²˜ìŒ 500ì): {str(response)[:500]}")
            return {
                "action_items": [
                    {
                        "id": 1,
                        "title": "ì£¼ë§ í”„ë¡œê·¸ë¨ í™•ëŒ€",
                        "description": f"í˜¼ì¡ë„ê°€ ë†’ì€ ì‹œê°„ëŒ€ì— íŠ¹ë³„ í”„ë¡œê·¸ë¨ ìš´ì˜",
                        "priority": "High",
                        "department": "í”„ë¡œê·¸ë¨ ê¸°íšíŒ€",
                        "timeline": "ì´ë²ˆ ì£¼",
                        "icon": "ğŸ¨",
                        "impact": "ë†’ìŒ"
                    },
                    {
                        "id": 2,
                        "title": "ì˜¤ëŠ˜ ë°©ë¬¸ í˜œíƒ ë§ˆì¼€íŒ…",
                        "description": f"ì˜ˆìƒ ë°©ë¬¸ì {total_visits:,}ëª…ì„ ìœ„í•œ ë‹¹ì¼ ì´ë²¤íŠ¸ ê³µì§€",
                        "priority": "High",
                        "department": "ë§ˆì¼€íŒ…íŒ€",
                        "timeline": "ì˜¤ëŠ˜",
                        "icon": "ğŸ“¢",
                        "impact": "ë†’ìŒ"
                    },
                    {
                        "id": 3,
                        "title": "í˜¼ì¡ë„ ê´€ë¦¬ ê°•í™”",
                        "description": "ì˜ˆì¸¡ëœ í˜¼ì¡ë„ ë†’ì€ ê³µê°„ì— ì¶”ê°€ ì§ì› ë°°ì¹˜",
                        "priority": "Medium",
                        "department": "ìš´ì˜íŒ€",
                        "timeline": "ì˜¤ëŠ˜",
                        "icon": "ğŸ‘¥",
                        "impact": "ì¤‘ê°„"
                    }
                ]
            }
            
    except Exception as e:
        print(f"[API] ì•¡ì…˜ ì•„ì´í…œ ìƒì„± ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return {
            "action_items": [
                {
                    "id": 1,
                    "title": "ì£¼ë§ í”„ë¡œê·¸ë¨ í™•ëŒ€",
                    "description": "í˜¼ì¡ë„ê°€ ë†’ì€ ì‹œê°„ëŒ€ì— íŠ¹ë³„ í”„ë¡œê·¸ë¨ ìš´ì˜",
                    "priority": "High",
                    "department": "í”„ë¡œê·¸ë¨ ê¸°íšíŒ€",
                    "timeline": "ì´ë²ˆ ì£¼",
                    "icon": "ğŸ¨",
                    "impact": "ë†’ìŒ"
                },
                {
                    "id": 2,
                    "title": "ë°©ë¬¸ í˜œíƒ ë§ˆì¼€íŒ…",
                    "description": "ì˜ˆìƒ ë°©ë¬¸ìë¥¼ ìœ„í•œ ë‹¹ì¼ ì´ë²¤íŠ¸ ê³µì§€",
                    "priority": "High",
                    "department": "ë§ˆì¼€íŒ…íŒ€",
                    "timeline": "ì˜¤ëŠ˜",
                    "icon": "ğŸ“¢",
                    "impact": "ë†’ìŒ"
                }
            ]
        }

@app.post("/api/analytics/key-insights")
async def get_key_insights(request: Dict):
    """LLM ê¸°ë°˜ í•µì‹¬ ì¸ì‚¬ì´íŠ¸ ìš”ì•½ ìƒì„±"""
    try:
        predictions = request.get('predictions', [])
        statistics = request.get('statistics', {})
        trend_data = request.get('trend_data', {})
        date = request.get('date', datetime.now().strftime('%Y-%m-%d'))
        
        # í†µê³„ ìš”ì•½ ìƒì„±
        total_visits = statistics.get('total_visits', 0)
        avg_crowd = statistics.get('avg_crowd_level', 0) * 100
        active_spaces = statistics.get('active_spaces', 0)
        
        # ë‚ ì§œ ë ˆì´ë¸” ìƒì„±
        date_obj = datetime.strptime(date, '%Y-%m-%d')
        date_label = date_obj.strftime('%Yë…„ %mì›” %dì¼')
        is_weekend = date_obj.weekday() >= 5
        weekday_name = date_obj.strftime('%A')
        weekday_kr = {'Monday': 'ì›”ìš”ì¼', 'Tuesday': 'í™”ìš”ì¼', 'Wednesday': 'ìˆ˜ìš”ì¼', 
                      'Thursday': 'ëª©ìš”ì¼', 'Friday': 'ê¸ˆìš”ì¼', 'Saturday': 'í† ìš”ì¼', 'Sunday': 'ì¼ìš”ì¼'}.get(weekday_name, '')
        
        # ì˜ˆì¸¡ ë°ì´í„° ìš”ì•½
        predictions_list = []
        if isinstance(predictions, list):
            predictions_list = predictions
        elif isinstance(predictions, dict) and 'predictions' in predictions:
            predictions_list = predictions['predictions']
        
        # ìƒìœ„ 3ê°œ ê³µê°„ ì¶”ì¶œ
        top_spaces = sorted(predictions_list, key=lambda x: x.get('predicted_visit', 0), reverse=True)[:3]
        
        # íŠ¸ë Œë“œ ë°ì´í„° ìš”ì•½
        trend_summary = ""
        if trend_data:
            trend_summary = f"""
**íŠ¸ë Œë“œ ë°ì´í„°**:
- íŠ¸ë Œë“œ ì •ë³´: {json.dumps(trend_data, ensure_ascii=False, indent=2)[:500]}
"""
        
        # í•µì‹¬ ì¸ì‚¬ì´íŠ¸ ìƒì„± í”„ë¡¬í”„íŠ¸
        prompt = f"""ë‹¹ì‹ ì€ íŒŒì£¼ì‹œ ì¶œíŒë‹¨ì§€ í™œì„±í™”ë¥¼ ìœ„í•œ ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ë¶„ì„ëœ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ **ì˜¤ëŠ˜ í•˜ë£¨ë¥¼ ì´í•´í•˜ëŠ” í•µì‹¬ ì¸ì‚¬ì´íŠ¸**ë¥¼ 3-5ê°œ ì¹´ë“œ í˜•íƒœë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”.

**ë¶„ì„ ê¸°ì¤€ ë‚ ì§œ**: {date_label} ({weekday_kr}, {"ì£¼ë§" if is_weekend else "í‰ì¼"})

**í˜„ì¬ ìƒí™© ìš”ì•½**:
- ì „ì²´ ì˜ˆìƒ ë°©ë¬¸ì: {total_visits:,}ëª…
- í‰ê·  í˜¼ì¡ë„: {avg_crowd:.1f}%
- í™œì„± ë¬¸í™” ê³µê°„ ìˆ˜: {active_spaces}ê°œ

**ìƒìœ„ ë¬¸í™” ê³µê°„ ì˜ˆì¸¡**:
{chr(10).join([f"- {space.get('space', 'N/A')}: ì˜ˆìƒ ë°©ë¬¸ {space.get('predicted_visit', 0):,}ëª…, í˜¼ì¡ë„ {space.get('crowd_level', 0)*100:.1f}%" for space in top_spaces[:3]])}

{trend_summary}

**ìš”êµ¬ì‚¬í•­**:
1. **í•µì‹¬ ì¸ì‚¬ì´íŠ¸ 3-5ê°œ**ë¥¼ ì¹´ë“œ í˜•íƒœë¡œ ì œì‹œí•˜ì„¸ìš”
2. ê° ì¸ì‚¬ì´íŠ¸ëŠ” ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ì„±:
   - ì œëª©: í•µì‹¬ ë‚´ìš©ì„ í•œëˆˆì— íŒŒì•…í•  ìˆ˜ ìˆëŠ” ì œëª© (10-15ì)
   - ì„¤ëª…: êµ¬ì²´ì ì¸ ë°ì´í„°ì™€ ê·¼ê±°ë¥¼ í¬í•¨í•œ ì„¤ëª… (40-60ì)
   - ì•„ì´ì½˜: ì´ëª¨ì§€ ì•„ì´ì½˜ (ì˜ˆ: ğŸ“Š, ğŸ¯, âš ï¸, ğŸ“ˆ, ğŸ’¡)
   - íƒ€ì…: insight/warning/opportunity/recommendation ì¤‘ í•˜ë‚˜
3. **ì¶œíŒë‹¨ì§€ íë ˆì´í„°ê°€ í•˜ë£¨ë¥¼ ì‹œì‘í•˜ê¸° ì „ì— ì•Œì•„ì•¼ í•  ì •ë³´** ì¤‘ì‹¬ìœ¼ë¡œ ì‘ì„±
4. ë°ì´í„° ê·¼ê±°ë¥¼ ëª…í™•íˆ ì œì‹œí•˜ì„¸ìš”
5. ì´ˆë“±í•™ìƒë„ ì´í•´í•  ìˆ˜ ìˆê²Œ ì‰½ê²Œ ì„¤ëª…í•˜ì„¸ìš”

**ì‘ë‹µ í˜•ì‹** (JSON):
{{
  "insights": [
    {{
      "id": 1,
      "title": "ì¸ì‚¬ì´íŠ¸ ì œëª©",
      "description": "êµ¬ì²´ì ì¸ ë°ì´í„°ì™€ ê·¼ê±°ë¥¼ í¬í•¨í•œ ì„¤ëª…",
      "icon": "ğŸ“Š",
      "type": "insight",
      "value": "ì£¼ìš” ìˆ˜ì¹˜ë‚˜ ê°’",
      "trend": "up/down/stable"
    }},
    ...
  ]
}}

ê° ì¸ì‚¬ì´íŠ¸ íƒ€ì…:
- **insight**: ë°œê²¬í•œ íŒ¨í„´ì´ë‚˜ íŠ¹ì§•
- **warning**: ì£¼ì˜í•´ì•¼ í•  ì‚¬í•­
- **opportunity**: ê¸°íšŒë‚˜ ê°€ëŠ¥ì„±
- **recommendation**: ì¶”ì²œì‚¬í•­

ì‘ë‹µì€ ë°˜ë“œì‹œ ìœ íš¨í•œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì œê³µí•´ì£¼ì„¸ìš”.
"""
        
        # LLM í˜¸ì¶œ
        print(f"[API] í•µì‹¬ ì¸ì‚¬ì´íŠ¸ ìƒì„± - LLM í˜¸ì¶œ ì‹œì‘ (ë‚ ì§œ: {date})")
        
        if content_generator is None:
            print(f"[API] ê²½ê³ : content_generatorê°€ Noneì…ë‹ˆë‹¤. ê¸°ë³¸ê°’ ë°˜í™˜")
            raise HTTPException(status_code=503, detail="LLM ì„œë¹„ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        response = content_generator.analyze_data(prompt)
        
        print(f"[API] LLM ì‘ë‹µ íƒ€ì…: {type(response)}")
        if isinstance(response, dict):
            print(f"[API] LLM ì‘ë‹µ í‚¤: {list(response.keys())}")
            if 'insights' in response:
                insights_list = response.get('insights', [])
                insights_count = len(insights_list)
                print(f"[API] LLM ìƒì„± í•µì‹¬ ì¸ì‚¬ì´íŠ¸ {insights_count}ê°œ ë°˜í™˜")
                if insights_count > 0:
                    return response
        
        # ê¸°ë³¸ í•µì‹¬ ì¸ì‚¬ì´íŠ¸ ìƒì„±
        print(f"[API] LLM ì‘ë‹µì„ íŒŒì‹±í•  ìˆ˜ ì—†ì–´ ê¸°ë³¸ í•µì‹¬ ì¸ì‚¬ì´íŠ¸ ìƒì„±")
        return {
            "insights": [
                {
                    "id": 1,
                    "title": f"{weekday_kr} ë°©ë¬¸ ì˜ˆì¸¡",
                    "description": f"ì „ì²´ {total_visits:,}ëª…ì˜ ë°©ë¬¸ìê°€ ì˜ˆìƒë©ë‹ˆë‹¤. {'ì£¼ë§' if is_weekend else 'í‰ì¼'} íŒ¨í„´ì„ ë³´ì…ë‹ˆë‹¤.",
                    "icon": "ğŸ“Š",
                    "type": "insight",
                    "value": f"{total_visits:,}ëª…",
                    "trend": "stable"
                },
                {
                    "id": 2,
                    "title": "í˜¼ì¡ë„ ìˆ˜ì¤€",
                    "description": f"í‰ê·  í˜¼ì¡ë„ {avg_crowd:.1f}%ë¡œ {'ë†’ì€' if avg_crowd > 60 else 'ë³´í†µ' if avg_crowd > 40 else 'ë‚®ì€'} ìˆ˜ì¤€ì…ë‹ˆë‹¤.",
                    "icon": "âš ï¸" if avg_crowd > 60 else "ğŸ“ˆ",
                    "type": "warning" if avg_crowd > 60 else "insight",
                    "value": f"{avg_crowd:.1f}%",
                    "trend": "up" if avg_crowd > 60 else "stable"
                },
                {
                    "id": 3,
                    "title": "ìµœê³  í™œì„± ê³µê°„",
                    "description": f"{top_spaces[0].get('space', 'N/A')}ì´(ê°€) {top_spaces[0].get('predicted_visit', 0):,}ëª…ìœ¼ë¡œ ê°€ì¥ ë§ì€ ë°©ë¬¸ìê°€ ì˜ˆìƒë©ë‹ˆë‹¤.",
                    "icon": "ğŸ¯",
                    "type": "opportunity",
                    "value": top_spaces[0].get('space', 'N/A') if top_spaces else "N/A",
                    "trend": "up"
                }
            ]
        }
            
    except Exception as e:
        print(f"[API] í•µì‹¬ ì¸ì‚¬ì´íŠ¸ ìƒì„± ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return {
            "insights": [
                {
                    "id": 1,
                    "title": "ë°ì´í„° ë¶„ì„ ì¤‘",
                    "description": "í•µì‹¬ ì¸ì‚¬ì´íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤.",
                    "icon": "ğŸ“Š",
                    "type": "insight",
                    "value": "-",
                    "trend": "stable"
                }
            ]
        }

@app.post("/api/llm/explain-metric")
async def explain_metric(request: Dict):
    """LLM ê¸°ë°˜ ì§€í‘œ ì„¤ëª… ìƒì„±"""
    try:
        metric_name = request.get('metric_name', '')
        metric_value = request.get('metric_value', 0)
        metric_type = request.get('metric_type', 'general')
        context = request.get('context', {})
        
        prompt = f"""ë‹¹ì‹ ì€ ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ì§€í‘œë¥¼ ì¼ë°˜ì¸ì´ ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.

**ì§€í‘œ ì •ë³´**:
- ì§€í‘œëª…: {metric_name}
- ê°’: {metric_value}
- ìœ í˜•: {metric_type}

**ì»¨í…ìŠ¤íŠ¸**:
{json.dumps(context, ensure_ascii=False, indent=2)}

**ìš”êµ¬ì‚¬í•­**:
1. ì´ ìˆ«ìê°€ ë¬´ì—‡ì„ ì˜ë¯¸í•˜ëŠ”ì§€ ì„¤ëª… (ì´ˆë“±í•™ìƒë„ ì´í•´í•  ìˆ˜ ìˆê²Œ)
2. ì´ ìˆ«ìê°€ ì™œ ì¤‘ìš”í•œì§€ ì„¤ëª…
3. ì´ ìˆ«ìê°€ ì¢‹ì€ì§€ ë‚˜ìœì§€ íŒë‹¨ ê¸°ì¤€ ì œì‹œ
4. ì‹¤ì œë¡œ ì–´ë–»ê²Œ í™œìš©í•  ìˆ˜ ìˆëŠ”ì§€ ì œì•ˆ

**ì‘ë‹µ í˜•ì‹** (JSON):
{{
  "explanation": "ì´ ì§€í‘œê°€ ë¬´ì—‡ì„ ì˜ë¯¸í•˜ëŠ”ì§€ ì‰¬ìš´ ì„¤ëª… (50-100ì)",
  "importance": "ì™œ ì¤‘ìš”í•œì§€ ì„¤ëª… (50-100ì)",
  "interpretation": "ì´ ìˆ«ìê°€ ì¢‹ì€ì§€ ë‚˜ìœì§€ íŒë‹¨ (ì¢‹ìŒ/ë³´í†µ/ë‚˜ì¨)",
  "recommendation": "ì‹¤ì œ í™œìš© ë°©ì•ˆ (30-50ì)"
}}

ì‘ë‹µì€ í•œêµ­ì–´ë¡œ, ì´ˆë“±í•™ìƒë„ ì´í•´í•  ìˆ˜ ìˆê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”.
"""
        
        response = content_generator.analyze_data(prompt)
        
        if isinstance(response, dict) and response:
            # ì‘ë‹µì´ ìˆê³  í‚¤ê°€ ìˆëŠ” ê²½ìš° ë°˜í™˜
            if any(key in response for key in ['explanation', 'importance', 'interpretation', 'recommendation', 'pattern', 'trend', 'insight']):
                return response
        
        # ì‘ë‹µì´ ì—†ê±°ë‚˜ ì˜ˆìƒ í˜•ì‹ì´ ì•„ë‹Œ ê²½ìš° ê¸°ë³¸ê°’
        return {
            "explanation": f"{metric_name}ì€ {metric_value}ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.",
            "importance": "ì´ ì§€í‘œëŠ” ë¬¸í™” ê³µê°„ì˜ ìƒíƒœë¥¼ íŒŒì•…í•˜ëŠ” ë° ì¤‘ìš”í•©ë‹ˆë‹¤.",
            "interpretation": "ë³´í†µ",
            "recommendation": "ì´ ì§€í‘œë¥¼ ëª¨ë‹ˆí„°ë§í•˜ì—¬ ìš´ì˜ì— í™œìš©í•˜ì„¸ìš”."
        }
    except Exception as e:
        print(f"[API] ì§€í‘œ ì„¤ëª… ìƒì„± ì˜¤ë¥˜: {e}")
        return {
            "explanation": f"{request.get('metric_name', 'ì§€í‘œ')}ì— ëŒ€í•œ ì„¤ëª…ì…ë‹ˆë‹¤.",
            "importance": "ì´ ì§€í‘œëŠ” ì¤‘ìš”í•œ ì˜ë¯¸ë¥¼ ê°€ì§‘ë‹ˆë‹¤.",
            "interpretation": "ë³´í†µ",
            "recommendation": "ì§€ì†ì ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§í•˜ì„¸ìš”."
        }


@app.post("/api/llm/chart-insight")
async def chart_insight(request: Dict):
    """LLM ê¸°ë°˜ ì°¨íŠ¸ ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
    try:
        from datetime import datetime
        chart_type = request.get('chart_type', '')
        chart_data = request.get('chart_data', {})
        context = request.get('context', {})
        date = context.get('date', datetime.now().strftime('%Y-%m-%d'))
        
        # ë‚ ì§œ ë ˆì´ë¸” ìƒì„±
        date_obj = datetime.strptime(date, '%Y-%m-%d')
        date_label = date_obj.strftime('%Yë…„ %mì›” %dì¼')
        
        prompt = f"""ë‹¹ì‹ ì€ ë°ì´í„° ì‹œê°í™” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ì°¨íŠ¸ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”.

**ë¶„ì„ ê¸°ì¤€ ë‚ ì§œ**: {date_label} ({date})

**ì°¨íŠ¸ ì •ë³´**:
- ì°¨íŠ¸ ìœ í˜•: {chart_type}
- ì°¨íŠ¸ ë°ì´í„°: {json.dumps(chart_data, ensure_ascii=False, indent=2)}

**ì»¨í…ìŠ¤íŠ¸**:
{json.dumps(context, ensure_ascii=False, indent=2)}

**ìš”êµ¬ì‚¬í•­**:
1. ì°¨íŠ¸ì—ì„œ ë°œê²¬í•œ ì£¼ìš” íŒ¨í„´ ì„¤ëª…
2. ì¤‘ìš”í•œ ë³€í™”ë‚˜ íŠ¸ë Œë“œ ë°œê²¬
3. ì‹¤ìš©ì ì¸ ì¸ì‚¬ì´íŠ¸ ì œì‹œ
4. ì‹¤í–‰ ê°€ëŠ¥í•œ ì¶”ì²œì‚¬í•­ ì œì•ˆ

**ì‘ë‹µ í˜•ì‹** (JSON):
{{
  "pattern": "ë°œê²¬í•œ ì£¼ìš” íŒ¨í„´ (50-100ì)",
  "trend": "ë³€í™” ì¶”ì„¸ ì„¤ëª… (50-100ì)",
  "insight": "í•µì‹¬ ì¸ì‚¬ì´íŠ¸ (50-100ì)",
  "recommendation": "ì¶”ì²œì‚¬í•­ (30-50ì)"
}}

ì‘ë‹µì€ í•œêµ­ì–´ë¡œ, ì¼ë°˜ì¸ì´ ì´í•´í•˜ê¸° ì‰½ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”.
"""
        
        response = content_generator.analyze_data(prompt)
        
        if isinstance(response, dict) and response:
            # ì‘ë‹µì´ ìˆê³  í‚¤ê°€ ìˆëŠ” ê²½ìš° ë°˜í™˜
            if any(key in response for key in ['pattern', 'trend', 'insight', 'recommendation', 'explanation', 'importance']):
                return response
        
        # ì‘ë‹µì´ ì—†ê±°ë‚˜ ì˜ˆìƒ í˜•ì‹ì´ ì•„ë‹Œ ê²½ìš° ê¸°ë³¸ê°’
        return {
            "pattern": "ë°ì´í„°ì— ì¼ê´€ëœ íŒ¨í„´ì´ ë³´ì…ë‹ˆë‹¤.",
            "trend": "ì „ë°˜ì ìœ¼ë¡œ ì¦ê°€ ì¶”ì„¸ë¥¼ ë³´ì…ë‹ˆë‹¤.",
            "insight": "ì´ íŒ¨í„´ì€ ìš´ì˜ ê³„íšì— í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
            "recommendation": "ë°ì´í„°ë¥¼ ì§€ì†ì ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§í•˜ì„¸ìš”."
        }
    except Exception as e:
        print(f"[API] ì°¨íŠ¸ ì¸ì‚¬ì´íŠ¸ ìƒì„± ì˜¤ë¥˜: {e}")
        return {
            "pattern": "ë°ì´í„° íŒ¨í„´ì„ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤.",
            "trend": "íŠ¸ë Œë“œë¥¼ í™•ì¸ ì¤‘ì…ë‹ˆë‹¤.",
            "insight": "ì¸ì‚¬ì´íŠ¸ë¥¼ ìƒì„± ì¤‘ì…ë‹ˆë‹¤.",
            "recommendation": "ë°ì´í„°ë¥¼ ëª¨ë‹ˆí„°ë§í•˜ì„¸ìš”."
        }


@app.post("/api/llm/trend-interpretation")
async def trend_interpretation(request: Dict):
    """LLM ê¸°ë°˜ íŠ¸ë Œë“œ í•´ì„ ìƒì„±"""
    try:
        trend_data = request.get('trend_data', {})
        context = request.get('context', {})
        
        prompt = f"""ë‹¹ì‹ ì€ íŠ¸ë Œë“œ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ íŠ¸ë Œë“œ ë°ì´í„°ë¥¼ í•´ì„í•´ì£¼ì„¸ìš”.

**íŠ¸ë Œë“œ ë°ì´í„°**:
{json.dumps(trend_data, ensure_ascii=False, indent=2)}

**ì»¨í…ìŠ¤íŠ¸**:
{json.dumps(context, ensure_ascii=False, indent=2)}

**ìš”êµ¬ì‚¬í•­**:
1. íŠ¸ë Œë“œì˜ ì˜ë¯¸ ì„¤ëª…
2. ì™œ ì´ëŸ° íŠ¸ë Œë“œê°€ ë‚˜íƒ€ë‚˜ëŠ”ì§€ ë¶„ì„
3. ì•ìœ¼ë¡œ ì–´ë–»ê²Œ ë ì§€ ì „ë§
4. ì–´ë–»ê²Œ ëŒ€ì‘í•´ì•¼ í•˜ëŠ”ì§€ ì œì•ˆ

**ì‘ë‹µ í˜•ì‹** (JSON):
{{
  "meaning": "íŠ¸ë Œë“œì˜ ì˜ë¯¸ (50-100ì)",
  "reason": "íŠ¸ë Œë“œ ë°œìƒ ì´ìœ  ë¶„ì„ (50-100ì)",
  "forecast": "ì•ìœ¼ë¡œì˜ ì „ë§ (50-100ì)",
  "action": "ëŒ€ì‘ ë°©ì•ˆ (30-50ì)"
}}

ì‘ë‹µì€ í•œêµ­ì–´ë¡œ, ì¼ë°˜ì¸ì´ ì´í•´í•˜ê¸° ì‰½ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”.
"""
        
        response = content_generator.analyze_data(prompt)
        
        if isinstance(response, dict):
            return response
        else:
            return {
                "meaning": "ì´ íŠ¸ë Œë“œëŠ” ì¤‘ìš”í•œ ë³€í™”ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.",
                "reason": "ë‹¤ì–‘í•œ ìš”ì¸ì´ ì˜í–¥ì„ ë¯¸ì³¤ìŠµë‹ˆë‹¤.",
                "forecast": "ì•ìœ¼ë¡œë„ ë¹„ìŠ·í•œ ì¶”ì„¸ê°€ ì§€ì†ë  ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤.",
                "action": "íŠ¸ë Œë“œì— ë§ì¶° ìš´ì˜ì„ ì¡°ì •í•˜ì„¸ìš”."
            }
    except Exception as e:
        print(f"[API] íŠ¸ë Œë“œ í•´ì„ ìƒì„± ì˜¤ë¥˜: {e}")
        return {
            "meaning": "íŠ¸ë Œë“œë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤.",
            "reason": "ì›ì¸ì„ íŒŒì•… ì¤‘ì…ë‹ˆë‹¤.",
            "forecast": "ì „ë§ì„ ì‘ì„± ì¤‘ì…ë‹ˆë‹¤.",
            "action": "ëŒ€ì‘ ë°©ì•ˆì„ ì œì‹œ ì¤‘ì…ë‹ˆë‹¤."
        }


@app.post("/api/llm/predict-summary")
async def predict_summary(request: Dict):
    """ê¸°ê°„ë³„ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ LLMìœ¼ë¡œ ì„œìˆ í˜•ìœ¼ë¡œ ì •ë¦¬"""
    try:
        predictions = request.get('predictions', [])
        start_date = request.get('start_date', '')
        end_date = request.get('end_date', '')
        statistics = request.get('statistics', {})
        
        if not predictions:
            raise HTTPException(status_code=400, detail="ì˜ˆì¸¡ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        # ì˜ˆì¸¡ ë°ì´í„° ìš”ì•½
        total_visits = statistics.get('total_visits', 0)
        avg_daily = statistics.get('avg_daily_visits', 0)
        total_days = statistics.get('total_days', 0)
        
        # ê³µê°„ë³„ ì •ë³´ ì¶”ì¶œ
        spaces_info = []
        for pred in predictions:
            space = pred.get('space', 'N/A')
            total = pred.get('total_visits', pred.get('avg_visits', 0)) * total_days if total_days > 0 else 0
            avg_visit = pred.get('avg_visits', pred.get('total_visits', 0))
            crowd = pred.get('avg_crowd_level', 0) * 100
            trend = pred.get('trend', 'stable')
            spaces_info.append(f"- **{space}**: í‰ê·  ì¼ì¼ {avg_visit:,.0f}ëª… ì˜ˆìƒ, í‰ê·  í˜¼ì¡ë„ {crowd:.1f}%, {'ì¦ê°€' if trend == 'up' else 'ê°ì†Œ' if trend == 'down' else 'ì•ˆì •ì '} ì¶”ì„¸")
        
        prompt = f"""ë‹¹ì‹ ì€ ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ê¸°ê°„ë³„ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì´í•´í•˜ê¸° ì‰½ê³  ë³´ê¸° ì¢‹ì€ ì„œìˆ í˜• ìš”ì•½ìœ¼ë¡œ ì •ë¦¬í•´ì£¼ì„¸ìš”.

**ì˜ˆì¸¡ ê¸°ê°„**: {start_date} ~ {end_date} ({total_days}ì¼)

**ì „ì²´ í†µê³„**:
- ì´ ì˜ˆìƒ ë°©ë¬¸ ìˆ˜: {total_visits:,.0f}ëª…
- í‰ê·  ì¼ì¼ ë°©ë¬¸ ìˆ˜: {avg_daily:,.0f}ëª…

**ë¬¸í™” ê³µê°„ë³„ ì˜ˆì¸¡ í˜„í™©**:
{chr(10).join(spaces_info)}

**ìš”êµ¬ì‚¬í•­**:
1. ì „ì²´ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ìì—°ìŠ¤ëŸ½ê³  ì½ê¸° ì‰¬ìš´ ì„œìˆ í˜•ìœ¼ë¡œ ìš”ì•½ (200-300ì)
2. ì£¼ìš” ì¸ì‚¬ì´íŠ¸ 3-5ê°œë¥¼ ê°„ê²°í•˜ê²Œ ì œì‹œ
3. ì¶œíŒë‹¨ì§€ í™œì„±í™” ê´€ì ì—ì„œ ì‹¤í–‰ ê°€ëŠ¥í•œ ì¶”ì²œì‚¬í•­ 3-5ê°œ ì œì‹œ

**ì‘ë‹µ í˜•ì‹** (JSON):
{{
  "summary": "ì „ì²´ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì„œìˆ í•œ ìš”ì•½ (200-300ì)",
  "insights": ["ì¸ì‚¬ì´íŠ¸ 1", "ì¸ì‚¬ì´íŠ¸ 2", "ì¸ì‚¬ì´íŠ¸ 3"],
  "recommendations": ["ì¶”ì²œì‚¬í•­ 1", "ì¶”ì²œì‚¬í•­ 2", "ì¶”ì²œì‚¬í•­ 3"]
}}

ì‘ë‹µì€ í•œêµ­ì–´ë¡œ, ì¶œíŒë‹¨ì§€ í™œì„±í™”ë¥¼ ìœ„í•œ ì‹¤ìš©ì ì¸ ë‚´ìš©ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
"""
        
        response = content_generator.analyze_data(prompt)
        
        if isinstance(response, dict):
            return response
        else:
            # ê¸°ë³¸ ìš”ì•½ ìƒì„±
            summary_text = f"{start_date}ë¶€í„° {end_date}ê¹Œì§€ {total_days}ì¼ê°„ì˜ ì˜ˆì¸¡ ê²°ê³¼ì…ë‹ˆë‹¤. "
            summary_text += f"ì „ì²´ ì˜ˆìƒ ë°©ë¬¸ ìˆ˜ëŠ” ì•½ {total_visits:,.0f}ëª…ì´ë©°, í‰ê·  ì¼ì¼ {avg_daily:,.0f}ëª…ì˜ ë°©ë¬¸ì´ ì˜ˆìƒë©ë‹ˆë‹¤. "
            summary_text += "ê° ë¬¸í™” ê³µê°„ì˜ íŠ¹ì„±ì„ ê³ ë ¤í•œ ìš´ì˜ ê³„íš ìˆ˜ë¦½ì„ ê¶Œì¥í•©ë‹ˆë‹¤."
            
            return {
                "summary": summary_text,
                "insights": [
                    f"ì´ {total_visits:,.0f}ëª…ì˜ ë°©ë¬¸ì´ ì˜ˆìƒë©ë‹ˆë‹¤.",
                    "ë¬¸í™” ê³µê°„ë³„ íŠ¹ì„±ì— ë§ëŠ” ë§ì¶¤ ìš´ì˜ì´ í•„ìš”í•©ë‹ˆë‹¤.",
                    "ì˜ˆì¸¡ ê¸°ê°„ ë™ì•ˆ ì§€ì†ì ì¸ ëª¨ë‹ˆí„°ë§ì„ ê¶Œì¥í•©ë‹ˆë‹¤."
                ],
                "recommendations": [
                    "ì˜ˆì¸¡ëœ ë°©ë¬¸ íŒ¨í„´ì— ë§ì¶° í”„ë¡œê·¸ë¨ ì¼ì •ì„ ì¡°ì •í•˜ì„¸ìš”.",
                    "í˜¼ì¡ë„ê°€ ë†’ì€ ë‚ ì—ëŠ” ì¶”ê°€ ì¸ë ¥ì„ ë°°ì¹˜í•˜ëŠ” ê²ƒì„ ê³ ë ¤í•˜ì„¸ìš”.",
                    "ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë§ˆì¼€íŒ… í™œë™ì„ ê³„íší•˜ì„¸ìš”."
                ]
            }
    except Exception as e:
        print(f"[API] ì˜ˆì¸¡ ìš”ì•½ ìƒì„± ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return {
            "summary": "ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤.",
            "insights": ["ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤."],
            "recommendations": ["ì¶”ì²œì‚¬í•­ì„ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤."]
        }


@app.post("/api/llm/generate-insight")
async def generate_insight(request: Dict):
    """LLM ê¸°ë°˜ ì‹¤ì‹œê°„ ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
    try:
        data_type = request.get('data_type', '')
        data = request.get('data', {})
        context = request.get('context', {})
        
        prompt = f"""ë‹¹ì‹ ì€ ì‹¤ì‹œê°„ ë°ì´í„° ë¶„ì„ AIì…ë‹ˆë‹¤. ë‹¤ìŒ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¦‰ì‹œ í™œìš© ê°€ëŠ¥í•œ ì¸ì‚¬ì´íŠ¸ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

**ë°ì´í„° ì •ë³´**:
- ìœ í˜•: {data_type}
- ë°ì´í„°: {json.dumps(data, ensure_ascii=False, indent=2)}

**ì»¨í…ìŠ¤íŠ¸**:
{json.dumps(context, ensure_ascii=False, indent=2)}

**ìš”êµ¬ì‚¬í•­**:
1. ë°ì´í„°ì—ì„œ ì¦‰ì‹œ ì•Œì•„ë‚¼ ìˆ˜ ìˆëŠ” í•µì‹¬ ì‚¬ì‹¤ (1-2ê°œ)
2. ì¼ë°˜ì¸ì´ ì´í•´í•˜ê¸° ì‰¬ìš´ ì„¤ëª…
3. ì‹¤ì œë¡œ ì–´ë–»ê²Œ í™œìš©í•  ìˆ˜ ìˆëŠ”ì§€ ì œì•ˆ
4. ì§§ê³  ëª…í™•í•˜ê²Œ (ê° í•­ëª© 30-50ì ì´ë‚´)

**ì‘ë‹µ í˜•ì‹** (JSON):
{{
  "key_facts": ["í•µì‹¬ ì‚¬ì‹¤ 1", "í•µì‹¬ ì‚¬ì‹¤ 2"],
  "simple_explanation": "ì‰½ê²Œ ì„¤ëª…í•œ ë‚´ìš© (50-70ì)",
  "action_tip": "í™œìš© ë°©ë²• (30-50ì)"
}}

ì‘ë‹µì€ í•œêµ­ì–´ë¡œ, ë§¤ìš° ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”.
"""
        
        response = content_generator.analyze_data(prompt)
        
        if isinstance(response, dict):
            return response
        else:
            return {
                "key_facts": ["ë°ì´í„°ë¥¼ ë¶„ì„í•œ ê²°ê³¼ì…ë‹ˆë‹¤."],
                "simple_explanation": "ì´ ë°ì´í„°ëŠ” ì¤‘ìš”í•œ ì˜ë¯¸ë¥¼ ê°€ì§‘ë‹ˆë‹¤.",
                "action_tip": "ì´ ì •ë³´ë¥¼ í™œìš©í•˜ì—¬ ìš´ì˜ì„ ê°œì„ í•˜ì„¸ìš”."
            }
    except Exception as e:
        print(f"[API] ì¸ì‚¬ì´íŠ¸ ìƒì„± ì˜¤ë¥˜: {e}")
        return {
            "key_facts": ["ë°ì´í„° ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤."],
            "simple_explanation": "ì¸ì‚¬ì´íŠ¸ë¥¼ ìƒì„± ì¤‘ì…ë‹ˆë‹¤.",
            "action_tip": "ì ì‹œ í›„ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”."
        }


@app.post("/api/analytics/llm-analysis")
async def llm_analysis(request: Dict):
    """LLM ê¸°ë°˜ ë°ì´í„° ë¶„ì„ ë° ì¶”ì²œ"""
    try:
        predictions = request.get('predictions', [])
        statistics = request.get('statistics', {})
        model_metrics = request.get('model_metrics', {})
        date = request.get('date', datetime.now().strftime('%Y-%m-%d'))

        # í†µê³„ ìš”ì•½ ìƒì„±
        total_visits = statistics.get('total_visits', 0)
        avg_crowd = statistics.get('avg_crowd_level', 0) * 100
        model_accuracy = model_metrics.get('r2', 0) * 100
        mae = model_metrics.get('mae', 0)

        # k-fold êµì°¨ ê²€ì¦ ê²°ê³¼ í¬í•¨
        has_kfold = model_metrics.get('cv_r2_mean') is not None
        cv_info = ""
        if has_kfold:
            cv_r2_mean = model_metrics.get('cv_r2_mean', model_metrics.get('r2', 0)) * 100
            cv_r2_std = model_metrics.get('cv_r2_std', 0) * 100
            cv_mae_mean = model_metrics.get('cv_mae_mean', model_metrics.get('mae', 0))
            cv_folds = model_metrics.get('cv_folds_used', 5)
            cv_info = f"""
**ëª¨ë¸ ê²€ì¦ ì •ë³´ (K-Fold êµì°¨ ê²€ì¦)**:
- ê²€ì¦ ë°©ë²•: {cv_folds}ê°œ Fold êµì°¨ ê²€ì¦
- í‰ê·  ì •í™•ë„: {cv_r2_mean:.2f}% Â± {cv_r2_std:.2f}%
- í‰ê·  ì˜¤ì°¨: {cv_mae_mean:.1f}ëª…
- ê²€ì¦ ì‹ ë¢°ë„: ë§¤ìš° ë†’ìŒ (ë‹¤ì¤‘ ê²€ì¦)
"""
        
        # ë‚ ì§œ ì •ë³´ ì¶”ì¶œ
        date_obj = datetime.strptime(date, '%Y-%m-%d')
        date_label = date_obj.strftime('%Yë…„ %mì›” %dì¼')
        weekday_name = date_obj.strftime('%A')
        weekday_kr = {'Monday': 'ì›”ìš”ì¼', 'Tuesday': 'í™”ìš”ì¼', 'Wednesday': 'ìˆ˜ìš”ì¼', 
                      'Thursday': 'ëª©ìš”ì¼', 'Friday': 'ê¸ˆìš”ì¼', 'Saturday': 'í† ìš”ì¼', 'Sunday': 'ì¼ìš”ì¼'}.get(weekday_name, '')
        is_weekend = date_obj.weekday() >= 5
        
        # ë¬¸í™” ê³µê°„ë³„ ìƒì„¸ ì •ë³´ ì¶”ì¶œ (íë ˆì´ì…˜ ë©”íŠ¸ë¦­ í¬í•¨)
        space_details = []
        for p in predictions[:5]:
            space_name = p.get('space', p.get('spot', 'N/A'))
            predicted_visit = p.get('predicted_visit', 0)
            crowd_level = p.get('crowd_level', 0) * 100
            optimal_time = p.get('optimal_time', 'N/A')
            recommended_programs = p.get('recommended_programs', [])
            
            # íë ˆì´ì…˜ ë©”íŠ¸ë¦­ ì¶”ì¶œ
            curation_metrics = p.get('curation_metrics', {})
            top_programs = []
            if curation_metrics:
                for program_type, metrics in curation_metrics.items():
                    if isinstance(metrics, dict):
                        overall_score = metrics.get('overall_score', 0)
                        if overall_score > 0.6:  # ë†’ì€ ì ìˆ˜ í”„ë¡œê·¸ë¨ë§Œ
                            top_programs.append(f"{program_type} (ì¶”ì²œë„: {overall_score:.1f})")
            
            space_detail = f"""
- **{space_name}**:
  - ì˜ˆìƒ ë°©ë¬¸ì: {predicted_visit:,}ëª…
  - í˜¼ì¡ë„: {crowd_level:.1f}% ({'ë†’ìŒ' if crowd_level > 60 else 'ë³´í†µ' if crowd_level > 40 else 'ë‚®ìŒ'})
  - ì¶”ì²œ ë°©ë¬¸ ì‹œê°„: {optimal_time}
  - ì¶”ì²œ í”„ë¡œê·¸ë¨: {', '.join(recommended_programs[:3]) if recommended_programs else 'ì—†ìŒ'}
"""
            if top_programs:
                space_detail += f"  - íë ˆì´ì…˜ ì¶”ì²œ: {', '.join(top_programs[:2])}\n"
            space_details.append(space_detail)
        
        # íë ˆì´ì…˜ ì¤‘ì‹¬ í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = f"""ë‹¹ì‹ ì€ íŒŒì£¼ì‹œ ì¶œíŒë‹¨ì§€ í™œì„±í™”ë¥¼ ìœ„í•œ íë ˆì´ì…˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì˜ˆì¸¡ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ **ì¶œíŒë‹¨ì§€ íë ˆì´í„°ê°€ ì‹¤ì œë¡œ í™œìš©í•  ìˆ˜ ìˆëŠ” ì‹¤ìš©ì ì¸ ë¶„ì„ê³¼ ì œì•ˆ**ì„ ì œê³µí•´ì£¼ì„¸ìš”.

**ì¤‘ìš”**: ëª¨ë¸ ì„±ëŠ¥, ì •í™•ë„, ì˜¤ì°¨ ë“±ì˜ ê¸°ìˆ ì  ì§€í‘œëŠ” ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”. ëŒ€ì‹  ë°©ë¬¸ì ì˜ˆì¸¡ê³¼ íŒ¨í„´ì„ í™œìš©í•œ **êµ¬ì²´ì ì¸ í”„ë¡œê·¸ë¨ ì œì•ˆê³¼ ìš´ì˜ ë°©ì•ˆ**ì— ì§‘ì¤‘í•´ì£¼ì„¸ìš”.

**ë¶„ì„ ê¸°ì¤€ ë‚ ì§œ**: {date_label} ({weekday_kr}, {"ì£¼ë§" if is_weekend else "í‰ì¼"})

**ì „ì²´ ì˜ˆì¸¡ í˜„í™©**:
- ì „ì²´ ì˜ˆìƒ ë°©ë¬¸ì: {total_visits:,}ëª…
- í‰ê·  í˜¼ì¡ë„: {avg_crowd:.1f}% ({'ë†’ì€' if avg_crowd > 60 else 'ë³´í†µ' if avg_crowd > 40 else 'ë‚®ì€'} ìˆ˜ì¤€)
- ë‚ ì§œ ìœ í˜•: {"ì£¼ë§" if is_weekend else "í‰ì¼"} ({"ê°€ì¡± ë‹¨ìœ„ ë°©ë¬¸ì´ ë§ì„ ê²ƒìœ¼ë¡œ ì˜ˆìƒ" if is_weekend else "ê°œì¸ ì·¨ë¯¸ í™œë™ ì¤‘ì‹¬ ë°©ë¬¸ ì˜ˆìƒ"})

**ë¬¸í™” ê³µê°„ë³„ ìƒì„¸ ì˜ˆì¸¡ (íë ˆì´ì…˜ ë©”íŠ¸ë¦­ í¬í•¨)**:
{''.join(space_details)}

**ë¶„ì„ ìš”ì²­ (íë ˆì´í„° ê´€ì ì—ì„œ)**:

1. **ì£¼ìš” ì¸ì‚¬ì´íŠ¸ (5-7ê°œ)**:
   - ê° ë¬¸í™” ê³µê°„ì˜ ë°©ë¬¸ íŒ¨í„´ê³¼ íŠ¹ì§• (ì–´ë–¤ ê³µê°„ì´ í™œë°œí•œì§€, ì–´ë–¤ ì‹œê°„ëŒ€ì— ë°©ë¬¸ì´ ë§ì€ì§€)
   - {"ì£¼ë§" if is_weekend else "í‰ì¼"} íŠ¹ì„±ì— ë§ëŠ” ë°©ë¬¸ì í–‰ë™ íŒ¨í„´
   - í˜¼ì¡ë„ ìˆ˜ì¤€ì— ë”°ë¥¸ í”„ë¡œê·¸ë¨ ìš´ì˜ ì „ëµ
   - íë ˆì´ì…˜ ë©”íŠ¸ë¦­ì—ì„œ ì¶”ì²œëœ í”„ë¡œê·¸ë¨ íƒ€ì…ì˜ íŠ¹ì§•ê³¼ íš¨ê³¼

2. **ì‹¤í–‰ ê°€ëŠ¥í•œ ì¶”ì²œì‚¬í•­ (5-7ê°œ)**:
   - **êµ¬ì²´ì ì¸ í”„ë¡œê·¸ë¨ ì œì•ˆ**: ì–´ë–¤ í”„ë¡œê·¸ë¨ì„ ì–´ëŠ ê³µê°„ì—ì„œ ìš´ì˜í•˜ë©´ ì¢‹ì„ì§€
   - **ìš´ì˜ ì‹œê°„ ì œì•ˆ**: ì˜ˆì¸¡ëœ ë°©ë¬¸ íŒ¨í„´ì— ë§ì¶˜ ìµœì  ìš´ì˜ ì‹œê°„
   - **íƒ€ê²Ÿ ê³ ê° ì œì•ˆ**: ì˜ˆìƒ ë°©ë¬¸ì íŠ¹ì„±ì— ë§ëŠ” í”„ë¡œê·¸ë¨ íƒ€ê²ŸíŒ…
   - **ë§ˆì¼€íŒ… ì œì•ˆ**: ë°©ë¬¸ì ìœ ì¹˜ë¥¼ ìœ„í•œ êµ¬ì²´ì  ë§ˆì¼€íŒ… ë°©ì•ˆ
   - **{"ì£¼ë§ íŠ¹í™” í”„ë¡œê·¸ë¨" if is_weekend else "í‰ì¼ íŠ¹í™” í”„ë¡œê·¸ë¨"} ì œì•ˆ**: ë‚ ì§œ ìœ í˜•ì— ë§ëŠ” íŠ¹ë³„ í”„ë¡œê·¸ë¨

3. **íŠ¸ë Œë“œ ë¶„ì„ ë° ì „ë§ (3-5ê°œ)**:
   - ë°©ë¬¸ íŒ¨í„´ì˜ ë³€í™” ì¶”ì„¸ (ì¦ê°€/ê°ì†Œ/ì•ˆì •)
   - ê³„ì ˆì /ì‹œê°„ëŒ€ë³„ ë³€í™” íŠ¹ì§•
   - ì¶œíŒë‹¨ì§€ í™œì„±í™”ë¥¼ ìœ„í•œ ë‹¨ê¸°/ì¤‘ê¸° ì „ëµ ë°©í–¥
   - íë ˆì´ì…˜ ë©”íŠ¸ë¦­ì—ì„œ ë‚˜íƒ€ë‚œ í”„ë¡œê·¸ë¨ ì„ í˜¸ë„ íŠ¸ë Œë“œ

**ì‘ë‹µ í˜•ì‹** (JSON):
{{
  "insights": ["ì¸ì‚¬ì´íŠ¸ 1 (êµ¬ì²´ì  ë°©ë¬¸ íŒ¨í„´ê³¼ íë ˆì´ì…˜ ê·¼ê±°)", "ì¸ì‚¬ì´íŠ¸ 2", ...],
  "recommendations": ["ì¶”ì²œì‚¬í•­ 1 (êµ¬ì²´ì  í”„ë¡œê·¸ë¨ëª…ê³¼ ìš´ì˜ ì‹œê°„ í¬í•¨)", "ì¶”ì²œì‚¬í•­ 2", ...],
  "trends": ["íŠ¸ë Œë“œ ë¶„ì„ 1 (ë¯¸ë˜ ìš´ì˜ ì „ëµ ë°©í–¥ í¬í•¨)", "íŠ¸ë Œë“œ ë¶„ì„ 2", ...]
}}

**ì‘ë‹µ ì‘ì„± ì›ì¹™**:
- âŒ ë‚˜ìœ ì˜ˆ: "ëª¨ë¸ ì •í™•ë„ê°€ 95%ë¡œ ë†’ìŠµë‹ˆë‹¤. RÂ² ì ìˆ˜ëŠ”..."
- âœ… ì¢‹ì€ ì˜ˆ: "í—¤ì´ë¦¬ì˜ˆìˆ ë§ˆì„ì—ì„œ ì£¼ë§ ì˜¤í›„ 2-4ì‹œì— ë°©ë¬¸ìê°€ ê°€ì¥ ë§ì„ ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤. ì´ ì‹œê°„ëŒ€ì— 'ì‘ê°€ì™€ì˜ ë§Œë‚¨' í”„ë¡œê·¸ë¨ì„ ìš´ì˜í•˜ë©´ íš¨ê³¼ì ì¼ ê²ƒì…ë‹ˆë‹¤."

- âŒ ë‚˜ìœ ì˜ˆ: "í‰ê·  ì ˆëŒ€ ì˜¤ì°¨ê°€ 15ëª…ì…ë‹ˆë‹¤."
- âœ… ì¢‹ì€ ì˜ˆ: "ì˜ˆìƒ ë°©ë¬¸ì ìˆ˜ê°€ 1,200ëª…ì´ë¯€ë¡œ, í˜¼ì¡ë„ ê´€ë¦¬ë¥¼ ìœ„í•´ ì£¼ìš” ê³µê°„ì— ì¶”ê°€ ì¸ë ¥ì„ ë°°ì¹˜í•˜ê³  ëŒ€ê¸° ê³µê°„ì„ í™•ë³´í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤."

ì‘ë‹µì€ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ê³ , íë ˆì´í„°ê°€ ë°”ë¡œ ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ë‚´ìš©ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
"""

        # ìƒì„±í˜• AI í˜¸ì¶œ
        analysis_result = content_generator.analyze_data(prompt)

        return analysis_result

    except Exception as e:
        print(f"[API] LLM ë¶„ì„ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        
        # ê¸°ë³¸ê°’ ë°˜í™˜ (íë ˆì´ì…˜ ì¤‘ì‹¬)
        date_obj = datetime.strptime(date, '%Y-%m-%d')
        is_weekend = date_obj.weekday() >= 5
        weekday_kr = {'Monday': 'ì›”ìš”ì¼', 'Tuesday': 'í™”ìš”ì¼', 'Wednesday': 'ìˆ˜ìš”ì¼', 
                      'Thursday': 'ëª©ìš”ì¼', 'Friday': 'ê¸ˆìš”ì¼', 'Saturday': 'í† ìš”ì¼', 'Sunday': 'ì¼ìš”ì¼'}.get(date_obj.strftime('%A'), '')
        
        return {
            "insights": [
                f"ì „ì²´ {total_visits:,}ëª…ì˜ ë°©ë¬¸ìê°€ ì˜ˆìƒë©ë‹ˆë‹¤. í‰ê·  í˜¼ì¡ë„ëŠ” {avg_crowd:.1f}%ë¡œ {'ë†’ì€' if avg_crowd > 60 else 'ë³´í†µ' if avg_crowd > 40 else 'ë‚®ì€'} ìˆ˜ì¤€ì…ë‹ˆë‹¤.",
                f"ì´ ë‚ ì§œëŠ” {weekday_kr} ({'ì£¼ë§' if is_weekend else 'í‰ì¼'})ë¡œ, {'ê°€ì¡± ë‹¨ìœ„ ë°©ë¬¸ì´ ë§ì„ ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤' if is_weekend else 'ê°œì¸ ì·¨ë¯¸ í™œë™ ì¤‘ì‹¬ ë°©ë¬¸ì´ ì˜ˆìƒë©ë‹ˆë‹¤'}.",
                "ë¬¸í™” ê³µê°„ë³„ ë°©ë¬¸ íŒ¨í„´ì„ ë¶„ì„í•˜ì—¬ ë§ì¶¤í˜• í”„ë¡œê·¸ë¨ì„ ìš´ì˜í•˜ëŠ” ê²ƒì´ íš¨ê³¼ì ì…ë‹ˆë‹¤."
            ],
            "recommendations": [
                f"{'ì£¼ë§' if is_weekend else 'í‰ì¼'} íŠ¹ì„±ì— ë§ëŠ” í”„ë¡œê·¸ë¨ì„ ê¸°íší•˜ì—¬ ìš´ì˜í•˜ì„¸ìš”. {'ê°€ì¡± ë‹¨ìœ„ í”„ë¡œê·¸ë¨' if is_weekend else 'ê°œì¸ ì·¨ë¯¸ í”„ë¡œê·¸ë¨'}ì„ ì¶”ì²œí•©ë‹ˆë‹¤.",
                f"í˜¼ì¡ë„ê°€ {'ë†’ì€' if avg_crowd > 60 else 'ë³´í†µ' if avg_crowd > 40 else 'ë‚®ì€'} ìˆ˜ì¤€ì´ë¯€ë¡œ, {'ì¶”ê°€ ì¸ë ¥ ë°°ì¹˜ì™€ ëŒ€ê¸° ê³µê°„ í™•ë³´' if avg_crowd > 60 else 'ì¼ë°˜ ìš´ì˜ ìœ ì§€'}ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤.",
                "ì˜ˆì¸¡ëœ ë°©ë¬¸ íŒ¨í„´ì— ë§ì¶° í”„ë¡œê·¸ë¨ ìš´ì˜ ì‹œê°„ì„ ì¡°ì •í•˜ì„¸ìš”."
            ],
            "trends": [
                "ì „ë°˜ì ì¸ ë°©ë¬¸ ìˆ˜ ì¶”ì„¸ë¥¼ ì§€ì†ì ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§í•˜ì—¬ ìš´ì˜ ê³„íšì„ ì¡°ì •í•˜ì„¸ìš”.",
                f"{'ì£¼ë§' if is_weekend else 'í‰ì¼'} ë°©ë¬¸ íŒ¨í„´ì„ ë¶„ì„í•˜ì—¬ ì¥ê¸°ì ì¸ í”„ë¡œê·¸ë¨ ê¸°íšì— ë°˜ì˜í•˜ì„¸ìš”."
            ]
        }


@app.post("/api/chat/stream")
async def chat_stream(request: Dict):
    """LLM ê¸°ë°˜ ìì—°ì–´ ì¿¼ë¦¬ ìŠ¤íŠ¸ë¦¬ë° (Server-Sent Events)"""
    async def generate():
        try:
            query = request.get('query', '')
            context = request.get('context', {})
            
            if not query:
                yield f"data: {json.dumps({'error': 'ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.'})}\n\n"
                return
            
            # ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ì¶”ì¶œ (model_metricsëŠ” íë ˆì´ì…˜ì— ë¶ˆí•„ìš”)
            predictions = context.get('predictions', {})
            statistics = context.get('statistics', {})
            
            # ì˜ˆì¸¡ ë°ì´í„° ìš”ì•½ (íë ˆì´ì…˜ ì§€í‘œ ê¸°ë°˜)
            prediction_summary = ""
            if predictions and isinstance(predictions, dict) and 'predictions' in predictions:
                pred_list = predictions.get('predictions', [])
                if pred_list:
                    prediction_summary = "\n**ë¬¸í™” ê³µê°„ë³„ íë ˆì´ì…˜ ì§€í‘œ**:\n"
                    for p in pred_list[:5]:
                        space = p.get('space', p.get('spot', 'N/A'))
                        curation_metrics = p.get('curation_metrics', {})
                        
                        # ìµœê³  ì ìˆ˜ í”„ë¡œê·¸ë¨ ì°¾ê¸°
                        top_program = None
                        top_score = 0
                        for prog_type, metrics in curation_metrics.items():
                            if isinstance(metrics, dict) and metrics.get('overall_score', 0) > top_score:
                                top_score = metrics['overall_score']
                                top_program = prog_type
                        
                        if top_program:
                            prediction_summary += f"- {space}: ì¶”ì²œ í”„ë¡œê·¸ë¨ '{top_program}' (ì ìˆ˜: {top_score:.1f})\n"
                        else:
                            visits = p.get('predicted_visit', 0)
                            prediction_summary += f"- {space}: ì˜ˆì¸¡ {visits:,}ëª…\n"
            
            # í†µê³„ ìš”ì•½ (íë ˆì´ì…˜ ì§€í‘œ ê¸°ë°˜)
            stats_summary = ""
            if statistics:
                total = statistics.get('total_visits', 0)
                stats_summary = f"""
**ì „ì²´ í†µê³„**:
- ì´ ì˜ˆì¸¡ ë°©ë¬¸ ìˆ˜: {total:,}ëª…
"""
            
            # ëª¨ë¸ ì„±ëŠ¥ì€ íë ˆì´ì…˜ì— ë¶ˆí•„ìš”í•˜ë¯€ë¡œ ì œê±°
            # model_summary = ""
            
            # íë ˆì´ì…˜ ì¤‘ì‹¬ í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = f"""ë‹¹ì‹ ì€ íŒŒì£¼ì‹œ ì¶œíŒë‹¨ì§€ í™œì„±í™”ë¥¼ ìœ„í•œ AI íë ˆì´ì…˜ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ML ì˜ˆì¸¡ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ **ì‹¤ì§ˆì ì¸ íë ˆì´ì…˜ ì œì•ˆ**ì„ í•´ì£¼ì„¸ìš”.

**ì¤‘ìš”**: ML ì§€í‘œë¥¼ ì„¤ëª…í•˜ê±°ë‚˜ ë¶„ì„í•˜ì§€ ë§ˆì„¸ìš”. ëŒ€ì‹  ML ì˜ˆì¸¡ ë°ì´í„°ë¥¼ í™œìš©í•´ì„œ **êµ¬ì²´ì ì¸ í”„ë¡œê·¸ë¨ ì œì•ˆ**ì„ í•´ì£¼ì„¸ìš”.

**í˜„ì¬ ì˜ˆì¸¡ ë°ì´í„°**:
{stats_summary}
{prediction_summary}

**ì‚¬ìš©ì ì§ˆë¬¸**: {query}

**ë‹µë³€ ìš”êµ¬ì‚¬í•­**:
1. **íë ˆì´ì…˜ ì¤‘ì‹¬**: ML ì§€í‘œ ì„¤ëª…ì´ ì•„ë‹Œ, ì‹¤ì§ˆì ì¸ í”„ë¡œê·¸ë¨ ì œì•ˆì„ í•´ì£¼ì„¸ìš”
2. **êµ¬ì²´ì  ì œì•ˆ**: ì–´ë–¤ í”„ë¡œê·¸ë¨ì„ ì–¸ì œ ì–´ë””ì„œ ìš´ì˜í•˜ë©´ ì¢‹ì„ì§€ êµ¬ì²´ì ìœ¼ë¡œ ì œì•ˆí•˜ì„¸ìš”
3. **ë°ì´í„° ê¸°ë°˜**: ì˜ˆì¸¡ ë°ì´í„°ë¥¼ í™œìš©í•˜ë˜, ì‚¬ìš©ìëŠ” ML ì§€í‘œë¥¼ ëª°ë¼ë„ ë©ë‹ˆë‹¤
4. **ì‹¤í–‰ ê°€ëŠ¥**: ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ í”„ë¡œê·¸ë¨ ì•„ì´ë””ì–´ì™€ ìš´ì˜ ë°©ì•ˆì„ ì œì‹œí•˜ì„¸ìš”
5. **ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”**: ì¹œê·¼í•˜ê³  ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”í•˜ë“¯ì´ ë‹µë³€í•˜ì„¸ìš”
6. **ë§ˆí¬ë‹¤ìš´ í™œìš©**: ì œëª©, ëª©ë¡, ê°•ì¡° ë“±ì„ ì ì ˆíˆ í™œìš©í•˜ì„¸ìš”

**ë‹µë³€ ì˜ˆì‹œ**:
âŒ ë‚˜ìœ ì˜ˆ: "RÂ² ì ìˆ˜ëŠ” 0.95ë¡œ ë†’ì€ ì •í™•ë„ë¥¼ ë³´ì…ë‹ˆë‹¤. ì´ëŠ” ëª¨ë¸ì´..."
âœ… ì¢‹ì€ ì˜ˆ: "ì£¼ë§ ì˜¤í›„ì— í—¤ì´ë¦¬ì˜ˆìˆ ë§ˆì„ì—ì„œ ì˜ˆìƒ ë°©ë¬¸ ìˆ˜ê°€ ë†’ìœ¼ë¯€ë¡œ, 'ì‘ê°€ì™€ì˜ ë§Œë‚¨' í”„ë¡œê·¸ë¨ì„ ì¶”ì²œí•©ë‹ˆë‹¤..."

**ë‹µë³€ í˜•ì‹**:
- í”„ë¡œê·¸ë¨ ì œì•ˆ: êµ¬ì²´ì ì¸ í”„ë¡œê·¸ë¨ ì´ë¦„ê³¼ ë‚´ìš©
- ìš´ì˜ ì‹œì : ì–¸ì œ ìš´ì˜í•˜ë©´ ì¢‹ì„ì§€
- ìš´ì˜ ì¥ì†Œ: ì–´ë””ì„œ ìš´ì˜í•˜ë©´ ì¢‹ì„ì§€
- íƒ€ê²Ÿ ê³ ê°: ëˆ„êµ¬ë¥¼ ëŒ€ìƒìœ¼ë¡œ í•˜ë©´ ì¢‹ì„ì§€
- ê¸°ëŒ€ íš¨ê³¼: ì–´ë–¤ íš¨ê³¼ë¥¼ ê¸°ëŒ€í•  ìˆ˜ ìˆëŠ”ì§€
"""
            
            # LLM í˜¸ì¶œ (ìŠ¤íŠ¸ë¦¬ë°)
            # ì—…ìŠ¤í…Œì´ì§€ APIëŠ” ìŠ¤íŠ¸ë¦¬ë°ì„ ì§€ì›í•˜ëŠ”ì§€ í™•ì¸ í•„ìš”
            # ì—¬ê¸°ì„œëŠ” ë‹¨ìˆœí™”í•˜ì—¬ ì²­í¬ ë‹¨ìœ„ë¡œ ì‘ë‹µ ìƒì„±
            try:
                # LLM ì‘ë‹µ ìƒì„± (ì „ì²´)
                full_response = content_generator.analyze_data(prompt, return_type='string')
                
                # ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ì²­í¬ ë‹¨ìœ„ ì „ì†¡
                # í•œê¸€ ë‹¨ì–´ ë‹¨ìœ„ë¡œ ë¶„í• í•˜ì—¬ ìì—°ìŠ¤ëŸ½ê²Œ ì „ì†¡
                words = full_response.split(' ')
                current_chunk = ''
                
                for i, word in enumerate(words):
                    current_chunk += word + ' '
                    
                    # ì¼ì • ê¸¸ì´ë§ˆë‹¤ ì „ì†¡ (ë˜ëŠ” ì•½ê°„ì˜ ì§€ì—°)
                    if len(current_chunk) > 20 or i == len(words) - 1:
                        yield f"data: {json.dumps({'content': current_chunk})}\n\n"
                        current_chunk = ''
                        await asyncio.sleep(0.05)  # ìì—°ìŠ¤ëŸ¬ìš´ íƒ€ì´í•‘ íš¨ê³¼
                
            except Exception as e:
                error_msg = f"ì£„ì†¡í•©ë‹ˆë‹¤. '{query}'ì— ëŒ€í•œ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
                yield f"data: {json.dumps({'content': error_msg})}\n\n"
                print(f"[API] ìŠ¤íŠ¸ë¦¬ë° ì˜¤ë¥˜: {e}")
            
            # ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ ì‹ í˜¸
            yield f"data: [DONE]\n\n"
            
        except Exception as e:
            print(f"[API] ìŠ¤íŠ¸ë¦¬ë° ì±„íŒ… ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            yield f"data: {json.dumps({'error': 'ìŠ¤íŠ¸ë¦¬ë° ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.'})}\n\n"
            yield f"data: [DONE]\n\n"
    
    return StreamingResponse(generate(), media_type="text/event-stream")


@app.post("/api/chat/query")
async def chat_query(request: Dict):
    """LLM ê¸°ë°˜ ìì—°ì–´ ì¿¼ë¦¬ ë° ëŒ€í™”í˜• ë¶„ì„ (ë¹„ìŠ¤íŠ¸ë¦¬ë° ë²„ì „ - í•˜ìœ„ í˜¸í™˜ì„±)"""
    try:
        query = request.get('query', '')
        context = request.get('context', {})
        
        if not query:
            raise HTTPException(status_code=400, detail="ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        
        # ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ì¶”ì¶œ (model_metricsëŠ” íë ˆì´ì…˜ì— ë¶ˆí•„ìš”)
        predictions = context.get('predictions', {})
        statistics = context.get('statistics', {})
        
        # ì˜ˆì¸¡ ë°ì´í„° ìš”ì•½
        prediction_summary = ""
        if predictions and isinstance(predictions, dict) and 'predictions' in predictions:
            pred_list = predictions.get('predictions', [])
            if pred_list:
                prediction_summary = "\n**ë¬¸í™” ê³µê°„ë³„ íë ˆì´ì…˜ ì§€í‘œ**:\n"
                for p in pred_list[:5]:
                    space = p.get('space', p.get('spot', 'N/A'))
                    curation_metrics = p.get('curation_metrics', {})
                    
                    # ìµœê³  ì ìˆ˜ í”„ë¡œê·¸ë¨ ì°¾ê¸°
                    top_program = None
                    top_score = 0
                    for prog_type, metrics in curation_metrics.items():
                        if isinstance(metrics, dict) and metrics.get('overall_score', 0) > top_score:
                            top_score = metrics['overall_score']
                            top_program = prog_type
                    
                    if top_program:
                        prediction_summary += f"- {space}: ì¶”ì²œ í”„ë¡œê·¸ë¨ '{top_program}' (ì ìˆ˜: {top_score:.1f})\n"
                    else:
                        visits = p.get('predicted_visit', 0)
                        prediction_summary += f"- {space}: ì˜ˆì¸¡ {visits:,}ëª…\n"
        
        # í†µê³„ ìš”ì•½ (íë ˆì´ì…˜ ì§€í‘œ ê¸°ë°˜)
        stats_summary = ""
        if statistics:
            total = statistics.get('total_visits', 0)
            stats_summary = f"""
**ì „ì²´ í†µê³„**:
- ì´ ì˜ˆì¸¡ ë°©ë¬¸ ìˆ˜: {total:,}ëª…
"""
        
        # íë ˆì´ì…˜ ì¤‘ì‹¬ í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = f"""ë‹¹ì‹ ì€ íŒŒì£¼ì‹œ ì¶œíŒë‹¨ì§€ í™œì„±í™”ë¥¼ ìœ„í•œ AI íë ˆì´ì…˜ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ML ì˜ˆì¸¡ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ **ì‹¤ì§ˆì ì¸ íë ˆì´ì…˜ ì œì•ˆ**ì„ í•´ì£¼ì„¸ìš”.

**ì¤‘ìš”**: ML ì§€í‘œë¥¼ ì„¤ëª…í•˜ê±°ë‚˜ ë¶„ì„í•˜ì§€ ë§ˆì„¸ìš”. ëŒ€ì‹  ML ì˜ˆì¸¡ ë°ì´í„°ë¥¼ í™œìš©í•´ì„œ **êµ¬ì²´ì ì¸ í”„ë¡œê·¸ë¨ ì œì•ˆ**ì„ í•´ì£¼ì„¸ìš”.

**í˜„ì¬ ì˜ˆì¸¡ ë°ì´í„°**:
{stats_summary}
{prediction_summary}

**ì‚¬ìš©ì ì§ˆë¬¸**: {query}

**ë‹µë³€ ìš”êµ¬ì‚¬í•­**:
1. **íë ˆì´ì…˜ ì¤‘ì‹¬**: ML ì§€í‘œ ì„¤ëª…ì´ ì•„ë‹Œ, ì‹¤ì§ˆì ì¸ í”„ë¡œê·¸ë¨ ì œì•ˆì„ í•´ì£¼ì„¸ìš”
2. **êµ¬ì²´ì  ì œì•ˆ**: ì–´ë–¤ í”„ë¡œê·¸ë¨ì„ ì–¸ì œ ì–´ë””ì„œ ìš´ì˜í•˜ë©´ ì¢‹ì„ì§€ êµ¬ì²´ì ìœ¼ë¡œ ì œì•ˆí•˜ì„¸ìš”
3. **ë°ì´í„° ê¸°ë°˜**: ì˜ˆì¸¡ ë°ì´í„°ë¥¼ í™œìš©í•˜ë˜, ì‚¬ìš©ìëŠ” ML ì§€í‘œë¥¼ ëª°ë¼ë„ ë©ë‹ˆë‹¤
4. **ì‹¤í–‰ ê°€ëŠ¥**: ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ í”„ë¡œê·¸ë¨ ì•„ì´ë””ì–´ì™€ ìš´ì˜ ë°©ì•ˆì„ ì œì‹œí•˜ì„¸ìš”
5. **ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”**: ì¹œê·¼í•˜ê³  ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”í•˜ë“¯ì´ ë‹µë³€í•˜ì„¸ìš”
6. **ë§ˆí¬ë‹¤ìš´ í™œìš©**: ì œëª©, ëª©ë¡, ê°•ì¡° ë“±ì„ ì ì ˆíˆ í™œìš©í•˜ì„¸ìš”

**ë‹µë³€ ì˜ˆì‹œ**:
âŒ ë‚˜ìœ ì˜ˆ: "RÂ² ì ìˆ˜ëŠ” 0.95ë¡œ ë†’ì€ ì •í™•ë„ë¥¼ ë³´ì…ë‹ˆë‹¤. ì´ëŠ” ëª¨ë¸ì´..."
âœ… ì¢‹ì€ ì˜ˆ: "ì£¼ë§ ì˜¤í›„ì— í—¤ì´ë¦¬ì˜ˆìˆ ë§ˆì„ì—ì„œ ì˜ˆìƒ ë°©ë¬¸ ìˆ˜ê°€ ë†’ìœ¼ë¯€ë¡œ, 'ì‘ê°€ì™€ì˜ ë§Œë‚¨' í”„ë¡œê·¸ë¨ì„ ì¶”ì²œí•©ë‹ˆë‹¤..."

**ë‹µë³€ í˜•ì‹**:
- í”„ë¡œê·¸ë¨ ì œì•ˆ: êµ¬ì²´ì ì¸ í”„ë¡œê·¸ë¨ ì´ë¦„ê³¼ ë‚´ìš©
- ìš´ì˜ ì‹œì : ì–¸ì œ ìš´ì˜í•˜ë©´ ì¢‹ì„ì§€
- ìš´ì˜ ì¥ì†Œ: ì–´ë””ì„œ ìš´ì˜í•˜ë©´ ì¢‹ì„ì§€
- íƒ€ê²Ÿ ê³ ê°: ëˆ„êµ¬ë¥¼ ëŒ€ìƒìœ¼ë¡œ í•˜ë©´ ì¢‹ì„ì§€
- ê¸°ëŒ€ íš¨ê³¼: ì–´ë–¤ íš¨ê³¼ë¥¼ ê¸°ëŒ€í•  ìˆ˜ ìˆëŠ”ì§€
"""
        
        # LLM í˜¸ì¶œ (ì±„íŒ…ìš© ìì—°ì–´ ì‘ë‹µ)
        answer = content_generator.analyze_data(prompt, return_type='string')
        
        # ì‘ë‹µ ì •ë¦¬
        if isinstance(answer, dict):
            # ë”•ì…”ë„ˆë¦¬ê°€ ë°˜í™˜ëœ ê²½ìš° ë¬¸ìì—´ë¡œ ë³€í™˜
            if 'insights' in answer and answer['insights']:
                answer = '\n\n'.join(answer['insights'])
            elif 'recommendations' in answer and answer['recommendations']:
                answer = '\n\n'.join(answer['recommendations'])
            elif 'trends' in answer and answer['trends']:
                answer = '\n\n'.join(answer['trends'])
            else:
                answer = str(answer)
        
        # ë¬¸ìì—´ ì •ë¦¬ (JSON ë¸”ë¡ ì œê±°)
        answer = str(answer).strip()
        
        # JSON ë¸”ë¡ì´ ìˆìœ¼ë©´ ì œê±°
        import re
        json_pattern = r'\{[^{}]*\}'
        if re.search(json_pattern, answer):
            # JSON ë¸”ë¡ ì•ë¶€ë¶„ë§Œ ì‚¬ìš©
            json_match = re.search(json_pattern, answer)
            if json_match:
                before_json = answer[:json_match.start()].strip()
                after_json = answer[json_match.end():].strip()
                answer = (before_json + '\n\n' + after_json).strip() if before_json or after_json else answer
        
        # ìµœì¢… ì •ë¦¬
        if not answer or len(answer) < 10:
            answer = f"í˜„ì¬ ë°ì´í„°ë¥¼ ë¶„ì„í•œ ê²°ê³¼, '{query}'ì— ëŒ€í•œ ë‹µë³€ì„ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
        
        return {
            "response": answer,
            "query": query
        }
        
    except Exception as e:
        print(f"[API] ì±„íŒ… ì¿¼ë¦¬ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        # ê¸°ë³¸ ë‹µë³€
        return {
            "response": f"ì£„ì†¡í•©ë‹ˆë‹¤. '{query}'ì— ëŒ€í•œ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\n\në‹¤ì‹œ ì§ˆë¬¸í•´ì£¼ì‹œê±°ë‚˜, ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ ì§ˆë¬¸í•´ë³´ì„¸ìš”.",
            "query": query
        }


# Health check ì—”ë“œí¬ì¸íŠ¸ (ë°°í¬ í™˜ê²½ì—ì„œ ì‚¬ìš©)
@app.get("/health")
async def health_check():
    """Health check ì—”ë“œí¬ì¸íŠ¸ - ë°°í¬ í™˜ê²½ì—ì„œ ì„œë²„ ìƒíƒœ í™•ì¸ìš©"""
    return {
        "status": "healthy",
        "service": "PAJU Culture Lab API",
        "version": "1.0.0"
    }


if __name__ == "__main__":
    import uvicorn
    print(f"\n[Backend] ì„œë²„ ì‹œì‘...")
    print(f"[Backend] í”„ë¡œì íŠ¸ ë£¨íŠ¸: {project_root}")
    print(f"[Backend] ì ‘ì† URL: http://localhost:8000")
    print(f"[Backend] API ë¬¸ì„œ: http://localhost:8000/docs\n")
    uvicorn.run(app, host="0.0.0.0", port=8000)